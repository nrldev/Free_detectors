2025/05/13 01:48:13 - mmengine - INFO - 
------------------------------------------------------------
System environment:
    sys.platform: linux
    Python: 3.11.11 (main, Dec 11 2024, 16:28:39) [GCC 11.2.0]
    CUDA available: True
    MUSA available: False
    numpy_random_seed: 1743584549
    GPU 0: NVIDIA GeForce RTX 4090
    CUDA_HOME: /usr
    NVCC: Cuda compilation tools, release 12.0, V12.0.140
    GCC: gcc (Ubuntu 13.3.0-6ubuntu2~24.04) 13.3.0
    PyTorch: 2.4.1+cu121
    PyTorch compiling details: PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v3.4.2 (Git Hash 1137e04ec0b5251ca2b4400a4fd3c667ce843d67)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX512
  - CUDA Runtime 12.1
  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 90.1  (built against CUDA 12.4)
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=12.1, CUDNN_VERSION=9.1.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wsuggest-override -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=2.4.1, USE_CUDA=ON, USE_CUDNN=ON, USE_CUSPARSELT=1, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_GLOO=ON, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, USE_ROCM_KERNEL_ASSERT=OFF, 

    TorchVision: 0.19.1+cu121
    OpenCV: 4.11.0
    MMEngine: 0.10.7

Runtime environment:
    cudnn_benchmark: False
    dist_cfg: {'backend': 'nccl'}
    mp_cfg: {'mp_start_method': 'fork', 'opencv_num_threads': 0}
    seed: 1743584549
    Distributed launcher: none
    Distributed training: False
    GPU number: 1
------------------------------------------------------------

2025/05/13 01:48:14 - mmengine - INFO - Config:
HOME = '/home/jaa/Work/Prog/BSU/Detectors'
MODEL_GROUP = 'yolo-like'
MODEL_TYPE = 'RTMDet'
WEIGHT_SIZE = 'm'
additions = 'new1'
auto_scale_lr = dict(base_batch_size=6, enable=False)
backend_args = None
base_lr = 0.004
batch_size = 6
checkpoint_config = dict(interval=1)
custom_hooks = [
    dict(type='CustomFreezeHook', unfreeze_epoch=5),
]
custom_imports = dict(
    allow_failed_imports=False, imports=[
        'custom_hooks',
    ])
data_root = '/home/jaa/Work/Prog/BSU/Detectors/mmdetection/data/Padded_GroundingDINO.v1i.yolov5pytorch/'
dataset_type = 'CocoDataset'
default_hooks = dict(
    checkpoint=dict(interval=1, max_keep_ckpts=7, type='CheckpointHook'),
    early_stopping=dict(
        min_delta=0.001,
        monitor='coco/bbox_mAP',
        patience=3,
        type='EarlyStoppingHook'),
    logger=dict(interval=50, log_metric_by_epoch=True, type='LoggerHook'),
    param_scheduler=dict(type='ParamSchedulerHook'),
    sampler_seed=dict(type='DistSamplerSeedHook'),
    timer=dict(type='IterTimerHook'),
    visualization=dict(type='DetVisualizationHook'))
default_scope = 'mmdet'
deterministic = True
env_cfg = dict(
    cudnn_benchmark=False,
    dist_cfg=dict(backend='nccl'),
    mp_cfg=dict(mp_start_method='fork', opencv_num_threads=0))
evaluation = dict(interval=1, metric='bbox')
experiment = 'RTMDet_m_30e_new1_custom'
img_scales = [
    (
        640,
        640,
    ),
    (
        320,
        320,
    ),
    (
        960,
        960,
    ),
]
interval = 10
launcher = 'none'
load_from = '/home/jaa/Work/Prog/BSU/Detectors/work_dirs/RTMDet/RTMDet_m_30e_new3_custom/epoch_5.pth'
log_level = 'INFO'
log_processor = dict(by_epoch=True, type='LogProcessor', window_size=50)
max_epochs = 300
metainfo = dict(
    classes=('cow', ), palette=[
        (
            220,
            20,
            60,
        ),
    ])
model = dict(
    backbone=dict(
        act_cfg=dict(inplace=True, type='SiLU'),
        arch='P5',
        channel_attention=True,
        deepen_factor=0.67,
        expand_ratio=0.5,
        norm_cfg=dict(type='SyncBN'),
        type='CSPNeXt',
        widen_factor=0.75),
    bbox_head=dict(
        act_cfg=dict(inplace=True, type='SiLU'),
        anchor_generator=dict(
            offset=0, strides=[
                8,
                16,
                32,
            ], type='MlvlPointGenerator'),
        bbox_coder=dict(type='DistancePointBBoxCoder'),
        exp_on_reg=True,
        feat_channels=192,
        in_channels=192,
        loss_bbox=dict(loss_weight=2.0, type='GIoULoss'),
        loss_cls=dict(
            beta=2.0,
            loss_weight=1.0,
            type='QualityFocalLoss',
            use_sigmoid=True),
        norm_cfg=dict(type='SyncBN'),
        num_classes=1,
        pred_kernel_size=1,
        share_conv=True,
        stacked_convs=2,
        type='RTMDetSepBNHead',
        with_objectness=False),
    data_preprocessor=dict(
        batch_augments=None,
        bgr_to_rgb=False,
        mean=[
            103.53,
            116.28,
            123.675,
        ],
        std=[
            57.375,
            57.12,
            58.395,
        ],
        type='DetDataPreprocessor'),
    neck=dict(
        act_cfg=dict(inplace=True, type='SiLU'),
        expand_ratio=0.5,
        in_channels=[
            192,
            384,
            768,
        ],
        norm_cfg=dict(type='SyncBN'),
        num_csp_blocks=2,
        out_channels=192,
        type='CSPNeXtPAFPN'),
    test_cfg=dict(
        max_per_img=300,
        min_bbox_size=0,
        nms=dict(iou_threshold=0.65, type='nms'),
        nms_pre=30000,
        score_thr=0.001),
    train_cfg=dict(
        allowed_border=-1,
        assigner=dict(topk=13, type='DynamicSoftLabelAssigner'),
        debug=False,
        pos_weight=-1),
    type='RTMDet')
num_classes = 1
num_epochs = 20
num_workers = 6
optim_wrapper = dict(
    optimizer=dict(lr=0.0025, momentum=0.9, type='SGD', weight_decay=0.0005),
    paramwise_cfg=dict(
        bias_decay_mult=0, bypass_duplicate=True, norm_decay_mult=0),
    type='OptimWrapper')
param_scheduler = [
    dict(
        begin=0, by_epoch=False, end=500, start_factor=0.001, type='LinearLR'),
    dict(
        begin=0,
        by_epoch=True,
        end=20,
        gamma=0.1,
        milestones=[
            7,
            14,
        ],
        type='MultiStepLR'),
    dict(T_max=20, begin=0, by_epoch=True, end=20, type='CosineAnnealingLR'),
]
resume = True
seed = 89
stage2_num_epochs = 20
test_cfg = dict(type='TestLoop')
test_dataloader = dict(
    batch_size=6,
    dataset=dict(
        ann_file=
        '/home/jaa/Work/Prog/BSU/Detectors/mmdetection/data/Padded_GroundingDINO.v1i.yolov5pytorch/test_coco.json',
        backend_args=None,
        data_prefix=dict(
            img=
            '/home/jaa/Work/Prog/BSU/Detectors/mmdetection/data/Padded_GroundingDINO.v1i.yolov5pytorch/test/images'
        ),
        data_root=
        '/home/jaa/Work/Prog/BSU/Detectors/mmdetection/data/Padded_GroundingDINO.v1i.yolov5pytorch/',
        pipeline=[
            dict(backend_args=None, type='LoadImageFromFile'),
            dict(type='LoadAnnotations', with_bbox=True),
            dict(
                keep_empty=False,
                min_gt_bbox_wh=(
                    16,
                    16,
                ),
                type='FilterAnnotations'),
            dict(keep_ratio=True, scale=(
                1280,
                1280,
            ), type='Resize'),
            dict(
                meta_keys=(
                    'img_id',
                    'img_path',
                    'ori_shape',
                    'img_shape',
                    'scale_factor',
                ),
                type='PackDetInputs'),
        ],
        test_mode=True,
        type='CocoDataset'),
    drop_last=False,
    num_workers=6,
    persistent_workers=True,
    sampler=dict(shuffle=False, type='DefaultSampler'))
test_evaluator = dict(
    ann_file=
    '/home/jaa/Work/Prog/BSU/Detectors/mmdetection/data/Padded_GroundingDINO.v1i.yolov5pytorch/test_coco.json',
    backend_args=None,
    format_only=True,
    metric='bbox',
    outfile_prefix=
    '/home/jaa/Work/Prog/BSU/Detectors/mmdetection/data/Padded_GroundingDINO.v1i.yolov5pytorch/test/images',
    proposal_nums=(
        100,
        1,
        10,
    ),
    type='CocoMetric')
test_pipeline = [
    dict(backend_args=None, type='LoadImageFromFile'),
    dict(type='LoadAnnotations', with_bbox=True),
    dict(
        keep_empty=False, min_gt_bbox_wh=(
            16,
            16,
        ), type='FilterAnnotations'),
    dict(keep_ratio=True, scale=(
        1280,
        1280,
    ), type='Resize'),
    dict(
        meta_keys=(
            'img_id',
            'img_path',
            'ori_shape',
            'img_shape',
            'scale_factor',
        ),
        type='PackDetInputs'),
]
train_cfg = dict(
    dynamic_intervals=[
        (
            280,
            1,
        ),
    ],
    max_epochs=30,
    type='EpochBasedTrainLoop',
    val_interval=1)
train_dataloader = dict(
    batch_sampler=None,
    batch_size=6,
    dataset=dict(
        ann_file=
        '/home/jaa/Work/Prog/BSU/Detectors/mmdetection/data/Padded_GroundingDINO.v1i.yolov5pytorch/train_coco.json',
        backend_args=None,
        data_prefix=dict(
            img=
            '/home/jaa/Work/Prog/BSU/Detectors/mmdetection/data/Padded_GroundingDINO.v1i.yolov5pytorch/train/images'
        ),
        data_root=
        '/home/jaa/Work/Prog/BSU/Detectors/mmdetection/data/Padded_GroundingDINO.v1i.yolov5pytorch/',
        filter_cfg=dict(filter_empty_gt=True, min_size=32),
        metainfo=dict(classes=('cow', ), palette=[
            (
                220,
                20,
                60,
            ),
        ]),
        pipeline=[
            dict(backend_args=None, type='LoadImageFromFile'),
            dict(type='LoadAnnotations', with_bbox=True),
            dict(prob=0.5, type='RandomFlip'),
            dict(level=2, prob=0.3, type='Rotate'),
            dict(
                keep_empty=False,
                min_gt_bbox_wh=(
                    16,
                    16,
                ),
                type='FilterAnnotations'),
            dict(keep_ratio=True, scale=(
                1280,
                1280,
            ), type='Resize'),
            dict(type='PackDetInputs'),
        ],
        type='CocoDataset'),
    num_workers=6,
    persistent_workers=True,
    pin_memory=True,
    sampler=dict(shuffle=True, type='DefaultSampler'))
train_pipeline = [
    dict(backend_args=None, type='LoadImageFromFile'),
    dict(type='LoadAnnotations', with_bbox=True),
    dict(prob=0.5, type='RandomFlip'),
    dict(level=2, prob=0.3, type='Rotate'),
    dict(
        keep_empty=False, min_gt_bbox_wh=(
            16,
            16,
        ), type='FilterAnnotations'),
    dict(keep_ratio=True, scale=(
        1280,
        1280,
    ), type='Resize'),
    dict(type='PackDetInputs'),
]
train_pipeline_stage2 = [
    dict(backend_args=None, type='LoadImageFromFile'),
    dict(type='LoadAnnotations', with_bbox=True),
    dict(
        keep_ratio=True,
        ratio_range=(
            0.1,
            2.0,
        ),
        scale=(
            640,
            640,
        ),
        type='RandomResize'),
    dict(crop_size=(
        640,
        640,
    ), type='RandomCrop'),
    dict(type='YOLOXHSVRandomAug'),
    dict(prob=0.5, type='RandomFlip'),
    dict(pad_val=dict(img=(
        114,
        114,
        114,
    )), size=(
        640,
        640,
    ), type='Pad'),
    dict(type='PackDetInputs'),
]
val_cfg = dict(type='ValLoop')
val_dataloader = dict(
    batch_size=5,
    dataset=dict(
        ann_file=
        '/home/jaa/Work/Prog/BSU/Detectors/mmdetection/data/Padded_GroundingDINO.v1i.yolov5pytorch/valid_coco.json',
        backend_args=None,
        data_prefix=dict(
            img=
            '/home/jaa/Work/Prog/BSU/Detectors/mmdetection/data/Padded_GroundingDINO.v1i.yolov5pytorch/valid/images'
        ),
        data_root=
        '/home/jaa/Work/Prog/BSU/Detectors/mmdetection/data/Padded_GroundingDINO.v1i.yolov5pytorch/',
        metainfo=dict(classes=('cow', ), palette=[
            (
                220,
                20,
                60,
            ),
        ]),
        pipeline=[
            dict(backend_args=None, type='LoadImageFromFile'),
            dict(type='LoadAnnotations', with_bbox=True),
            dict(
                keep_empty=False,
                min_gt_bbox_wh=(
                    16,
                    16,
                ),
                type='FilterAnnotations'),
            dict(keep_ratio=True, scale=(
                1280,
                1280,
            ), type='Resize'),
            dict(
                meta_keys=(
                    'img_id',
                    'img_path',
                    'ori_shape',
                    'img_shape',
                    'scale_factor',
                ),
                type='PackDetInputs'),
        ],
        test_mode=True,
        type='CocoDataset'),
    drop_last=False,
    num_workers=6,
    persistent_workers=True,
    sampler=dict(shuffle=False, type='DefaultSampler'))
val_evaluator = dict(
    ann_file=
    '/home/jaa/Work/Prog/BSU/Detectors/mmdetection/data/Padded_GroundingDINO.v1i.yolov5pytorch//valid_coco.json',
    backend_args=None,
    format_only=False,
    metric='bbox',
    proposal_nums=(
        100,
        1,
        10,
    ),
    type='CocoMetric')
vis_backends = [
    dict(
        init_kwargs=dict(
            group='yolo-like',
            name='RTMDet_m_30e_6b_new1',
            project='Сomparison of detectors'),
        type='WandbVisBackend'),
]
visualizer = dict(
    type='Visualizer',
    vis_backends=[
        dict(
            init_kwargs=dict(
                group='yolo-like',
                name='RTMDet_m_30e_6b_new1',
                project='Сomparison of detectors'),
            type='WandbVisBackend'),
    ])
weights = 'rtmdet_m_8xb32-300e_coco_20220719_112220-229f527c.pth'
work_dir = '/home/jaa/Work/Prog/BSU/Detectors/work_dirs/RTMDet/RTMDet_m_30e_new1_custom/'

2025/05/13 01:48:17 - mmengine - INFO - Distributed training is not used, all SyncBatchNorm (SyncBN) layers in the model will be automatically reverted to BatchNormXd layers if they are used.
2025/05/13 01:48:17 - mmengine - INFO - Hooks will be executed in the following order:
before_run:
(VERY_HIGH   ) RuntimeInfoHook                    
(BELOW_NORMAL) LoggerHook                         
(LOWEST      ) EarlyStoppingHook                  
 -------------------- 
before_train:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(NORMAL      ) CustomFreezeHook                   
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
before_train_epoch:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(NORMAL      ) DistSamplerSeedHook                
(NORMAL      ) CustomFreezeHook                   
 -------------------- 
before_train_iter:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
 -------------------- 
after_train_iter:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(BELOW_NORMAL) LoggerHook                         
(LOW         ) ParamSchedulerHook                 
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
after_train_epoch:
(NORMAL      ) IterTimerHook                      
(LOW         ) ParamSchedulerHook                 
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
before_val:
(VERY_HIGH   ) RuntimeInfoHook                    
 -------------------- 
before_val_epoch:
(NORMAL      ) IterTimerHook                      
 -------------------- 
before_val_iter:
(NORMAL      ) IterTimerHook                      
 -------------------- 
after_val_iter:
(NORMAL      ) IterTimerHook                      
(NORMAL      ) DetVisualizationHook               
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
after_val_epoch:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(BELOW_NORMAL) LoggerHook                         
(LOW         ) ParamSchedulerHook                 
(VERY_LOW    ) CheckpointHook                     
(LOWEST      ) EarlyStoppingHook                  
 -------------------- 
after_val:
(VERY_HIGH   ) RuntimeInfoHook                    
 -------------------- 
after_train:
(VERY_HIGH   ) RuntimeInfoHook                    
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
before_test:
(VERY_HIGH   ) RuntimeInfoHook                    
 -------------------- 
before_test_epoch:
(NORMAL      ) IterTimerHook                      
 -------------------- 
before_test_iter:
(NORMAL      ) IterTimerHook                      
 -------------------- 
after_test_iter:
(NORMAL      ) IterTimerHook                      
(NORMAL      ) DetVisualizationHook               
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
after_test_epoch:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
after_test:
(VERY_HIGH   ) RuntimeInfoHook                    
 -------------------- 
after_run:
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
2025/05/13 01:48:17 - mmengine - INFO - paramwise_options -- backbone.stem.0.bn.weight:weight_decay=0.0
2025/05/13 01:48:17 - mmengine - INFO - paramwise_options -- backbone.stem.0.bn.bias:weight_decay=0.0
2025/05/13 01:48:17 - mmengine - INFO - paramwise_options -- backbone.stem.1.bn.weight:weight_decay=0.0
2025/05/13 01:48:17 - mmengine - INFO - paramwise_options -- backbone.stem.1.bn.bias:weight_decay=0.0
2025/05/13 01:48:17 - mmengine - INFO - paramwise_options -- backbone.stem.2.bn.weight:weight_decay=0.0
2025/05/13 01:48:17 - mmengine - INFO - paramwise_options -- backbone.stem.2.bn.bias:weight_decay=0.0
2025/05/13 01:48:17 - mmengine - INFO - paramwise_options -- backbone.stage1.0.bn.weight:weight_decay=0.0
2025/05/13 01:48:17 - mmengine - INFO - paramwise_options -- backbone.stage1.0.bn.bias:weight_decay=0.0
2025/05/13 01:48:17 - mmengine - INFO - paramwise_options -- backbone.stage1.1.main_conv.bn.weight:weight_decay=0.0
2025/05/13 01:48:17 - mmengine - INFO - paramwise_options -- backbone.stage1.1.main_conv.bn.bias:weight_decay=0.0
2025/05/13 01:48:17 - mmengine - INFO - paramwise_options -- backbone.stage1.1.short_conv.bn.weight:weight_decay=0.0
2025/05/13 01:48:17 - mmengine - INFO - paramwise_options -- backbone.stage1.1.short_conv.bn.bias:weight_decay=0.0
2025/05/13 01:48:17 - mmengine - INFO - paramwise_options -- backbone.stage1.1.final_conv.bn.weight:weight_decay=0.0
2025/05/13 01:48:17 - mmengine - INFO - paramwise_options -- backbone.stage1.1.final_conv.bn.bias:weight_decay=0.0
2025/05/13 01:48:17 - mmengine - INFO - paramwise_options -- backbone.stage1.1.blocks.0.conv1.bn.weight:weight_decay=0.0
2025/05/13 01:48:17 - mmengine - INFO - paramwise_options -- backbone.stage1.1.blocks.0.conv1.bn.bias:weight_decay=0.0
2025/05/13 01:48:17 - mmengine - INFO - paramwise_options -- backbone.stage1.1.blocks.0.conv2.depthwise_conv.bn.weight:weight_decay=0.0
2025/05/13 01:48:17 - mmengine - INFO - paramwise_options -- backbone.stage1.1.blocks.0.conv2.depthwise_conv.bn.bias:weight_decay=0.0
2025/05/13 01:48:17 - mmengine - INFO - paramwise_options -- backbone.stage1.1.blocks.0.conv2.pointwise_conv.bn.weight:weight_decay=0.0
2025/05/13 01:48:17 - mmengine - INFO - paramwise_options -- backbone.stage1.1.blocks.0.conv2.pointwise_conv.bn.bias:weight_decay=0.0
2025/05/13 01:48:17 - mmengine - INFO - paramwise_options -- backbone.stage1.1.blocks.1.conv1.bn.weight:weight_decay=0.0
2025/05/13 01:48:17 - mmengine - INFO - paramwise_options -- backbone.stage1.1.blocks.1.conv1.bn.bias:weight_decay=0.0
2025/05/13 01:48:17 - mmengine - INFO - paramwise_options -- backbone.stage1.1.blocks.1.conv2.depthwise_conv.bn.weight:weight_decay=0.0
2025/05/13 01:48:17 - mmengine - INFO - paramwise_options -- backbone.stage1.1.blocks.1.conv2.depthwise_conv.bn.bias:weight_decay=0.0
2025/05/13 01:48:17 - mmengine - INFO - paramwise_options -- backbone.stage1.1.blocks.1.conv2.pointwise_conv.bn.weight:weight_decay=0.0
2025/05/13 01:48:17 - mmengine - INFO - paramwise_options -- backbone.stage1.1.blocks.1.conv2.pointwise_conv.bn.bias:weight_decay=0.0
2025/05/13 01:48:17 - mmengine - INFO - paramwise_options -- backbone.stage1.1.attention.fc.bias:weight_decay=0.0
2025/05/13 01:48:17 - mmengine - INFO - paramwise_options -- backbone.stage2.0.bn.weight:weight_decay=0.0
2025/05/13 01:48:17 - mmengine - INFO - paramwise_options -- backbone.stage2.0.bn.bias:weight_decay=0.0
2025/05/13 01:48:17 - mmengine - INFO - paramwise_options -- backbone.stage2.1.main_conv.bn.weight:weight_decay=0.0
2025/05/13 01:48:17 - mmengine - INFO - paramwise_options -- backbone.stage2.1.main_conv.bn.bias:weight_decay=0.0
2025/05/13 01:48:17 - mmengine - INFO - paramwise_options -- backbone.stage2.1.short_conv.bn.weight:weight_decay=0.0
2025/05/13 01:48:17 - mmengine - INFO - paramwise_options -- backbone.stage2.1.short_conv.bn.bias:weight_decay=0.0
2025/05/13 01:48:17 - mmengine - INFO - paramwise_options -- backbone.stage2.1.final_conv.bn.weight:weight_decay=0.0
2025/05/13 01:48:17 - mmengine - INFO - paramwise_options -- backbone.stage2.1.final_conv.bn.bias:weight_decay=0.0
2025/05/13 01:48:17 - mmengine - INFO - paramwise_options -- backbone.stage2.1.blocks.0.conv1.bn.weight:weight_decay=0.0
2025/05/13 01:48:17 - mmengine - INFO - paramwise_options -- backbone.stage2.1.blocks.0.conv1.bn.bias:weight_decay=0.0
2025/05/13 01:48:17 - mmengine - INFO - paramwise_options -- backbone.stage2.1.blocks.0.conv2.depthwise_conv.bn.weight:weight_decay=0.0
2025/05/13 01:48:17 - mmengine - INFO - paramwise_options -- backbone.stage2.1.blocks.0.conv2.depthwise_conv.bn.bias:weight_decay=0.0
2025/05/13 01:48:17 - mmengine - INFO - paramwise_options -- backbone.stage2.1.blocks.0.conv2.pointwise_conv.bn.weight:weight_decay=0.0
2025/05/13 01:48:17 - mmengine - INFO - paramwise_options -- backbone.stage2.1.blocks.0.conv2.pointwise_conv.bn.bias:weight_decay=0.0
2025/05/13 01:48:17 - mmengine - INFO - paramwise_options -- backbone.stage2.1.blocks.1.conv1.bn.weight:weight_decay=0.0
2025/05/13 01:48:17 - mmengine - INFO - paramwise_options -- backbone.stage2.1.blocks.1.conv1.bn.bias:weight_decay=0.0
2025/05/13 01:48:17 - mmengine - INFO - paramwise_options -- backbone.stage2.1.blocks.1.conv2.depthwise_conv.bn.weight:weight_decay=0.0
2025/05/13 01:48:17 - mmengine - INFO - paramwise_options -- backbone.stage2.1.blocks.1.conv2.depthwise_conv.bn.bias:weight_decay=0.0
2025/05/13 01:48:17 - mmengine - INFO - paramwise_options -- backbone.stage2.1.blocks.1.conv2.pointwise_conv.bn.weight:weight_decay=0.0
2025/05/13 01:48:17 - mmengine - INFO - paramwise_options -- backbone.stage2.1.blocks.1.conv2.pointwise_conv.bn.bias:weight_decay=0.0
2025/05/13 01:48:17 - mmengine - INFO - paramwise_options -- backbone.stage2.1.blocks.2.conv1.bn.weight:weight_decay=0.0
2025/05/13 01:48:17 - mmengine - INFO - paramwise_options -- backbone.stage2.1.blocks.2.conv1.bn.bias:weight_decay=0.0
2025/05/13 01:48:17 - mmengine - INFO - paramwise_options -- backbone.stage2.1.blocks.2.conv2.depthwise_conv.bn.weight:weight_decay=0.0
2025/05/13 01:48:17 - mmengine - INFO - paramwise_options -- backbone.stage2.1.blocks.2.conv2.depthwise_conv.bn.bias:weight_decay=0.0
2025/05/13 01:48:17 - mmengine - INFO - paramwise_options -- backbone.stage2.1.blocks.2.conv2.pointwise_conv.bn.weight:weight_decay=0.0
2025/05/13 01:48:17 - mmengine - INFO - paramwise_options -- backbone.stage2.1.blocks.2.conv2.pointwise_conv.bn.bias:weight_decay=0.0
2025/05/13 01:48:17 - mmengine - INFO - paramwise_options -- backbone.stage2.1.blocks.3.conv1.bn.weight:weight_decay=0.0
2025/05/13 01:48:17 - mmengine - INFO - paramwise_options -- backbone.stage2.1.blocks.3.conv1.bn.bias:weight_decay=0.0
2025/05/13 01:48:17 - mmengine - INFO - paramwise_options -- backbone.stage2.1.blocks.3.conv2.depthwise_conv.bn.weight:weight_decay=0.0
2025/05/13 01:48:17 - mmengine - INFO - paramwise_options -- backbone.stage2.1.blocks.3.conv2.depthwise_conv.bn.bias:weight_decay=0.0
2025/05/13 01:48:17 - mmengine - INFO - paramwise_options -- backbone.stage2.1.blocks.3.conv2.pointwise_conv.bn.weight:weight_decay=0.0
2025/05/13 01:48:17 - mmengine - INFO - paramwise_options -- backbone.stage2.1.blocks.3.conv2.pointwise_conv.bn.bias:weight_decay=0.0
2025/05/13 01:48:17 - mmengine - INFO - paramwise_options -- backbone.stage2.1.attention.fc.bias:weight_decay=0.0
2025/05/13 01:48:17 - mmengine - INFO - paramwise_options -- backbone.stage3.0.bn.weight:weight_decay=0.0
2025/05/13 01:48:17 - mmengine - INFO - paramwise_options -- backbone.stage3.0.bn.bias:weight_decay=0.0
2025/05/13 01:48:17 - mmengine - INFO - paramwise_options -- backbone.stage3.1.main_conv.bn.weight:weight_decay=0.0
2025/05/13 01:48:17 - mmengine - INFO - paramwise_options -- backbone.stage3.1.main_conv.bn.bias:weight_decay=0.0
2025/05/13 01:48:17 - mmengine - INFO - paramwise_options -- backbone.stage3.1.short_conv.bn.weight:weight_decay=0.0
2025/05/13 01:48:17 - mmengine - INFO - paramwise_options -- backbone.stage3.1.short_conv.bn.bias:weight_decay=0.0
2025/05/13 01:48:17 - mmengine - INFO - paramwise_options -- backbone.stage3.1.final_conv.bn.weight:weight_decay=0.0
2025/05/13 01:48:17 - mmengine - INFO - paramwise_options -- backbone.stage3.1.final_conv.bn.bias:weight_decay=0.0
2025/05/13 01:48:17 - mmengine - INFO - paramwise_options -- backbone.stage3.1.blocks.0.conv1.bn.weight:weight_decay=0.0
2025/05/13 01:48:17 - mmengine - INFO - paramwise_options -- backbone.stage3.1.blocks.0.conv1.bn.bias:weight_decay=0.0
2025/05/13 01:48:17 - mmengine - INFO - paramwise_options -- backbone.stage3.1.blocks.0.conv2.depthwise_conv.bn.weight:weight_decay=0.0
2025/05/13 01:48:17 - mmengine - INFO - paramwise_options -- backbone.stage3.1.blocks.0.conv2.depthwise_conv.bn.bias:weight_decay=0.0
2025/05/13 01:48:17 - mmengine - INFO - paramwise_options -- backbone.stage3.1.blocks.0.conv2.pointwise_conv.bn.weight:weight_decay=0.0
2025/05/13 01:48:17 - mmengine - INFO - paramwise_options -- backbone.stage3.1.blocks.0.conv2.pointwise_conv.bn.bias:weight_decay=0.0
2025/05/13 01:48:17 - mmengine - INFO - paramwise_options -- backbone.stage3.1.blocks.1.conv1.bn.weight:weight_decay=0.0
2025/05/13 01:48:17 - mmengine - INFO - paramwise_options -- backbone.stage3.1.blocks.1.conv1.bn.bias:weight_decay=0.0
2025/05/13 01:48:17 - mmengine - INFO - paramwise_options -- backbone.stage3.1.blocks.1.conv2.depthwise_conv.bn.weight:weight_decay=0.0
2025/05/13 01:48:17 - mmengine - INFO - paramwise_options -- backbone.stage3.1.blocks.1.conv2.depthwise_conv.bn.bias:weight_decay=0.0
2025/05/13 01:48:17 - mmengine - INFO - paramwise_options -- backbone.stage3.1.blocks.1.conv2.pointwise_conv.bn.weight:weight_decay=0.0
2025/05/13 01:48:17 - mmengine - INFO - paramwise_options -- backbone.stage3.1.blocks.1.conv2.pointwise_conv.bn.bias:weight_decay=0.0
2025/05/13 01:48:17 - mmengine - INFO - paramwise_options -- backbone.stage3.1.blocks.2.conv1.bn.weight:weight_decay=0.0
2025/05/13 01:48:17 - mmengine - INFO - paramwise_options -- backbone.stage3.1.blocks.2.conv1.bn.bias:weight_decay=0.0
2025/05/13 01:48:17 - mmengine - INFO - paramwise_options -- backbone.stage3.1.blocks.2.conv2.depthwise_conv.bn.weight:weight_decay=0.0
2025/05/13 01:48:17 - mmengine - INFO - paramwise_options -- backbone.stage3.1.blocks.2.conv2.depthwise_conv.bn.bias:weight_decay=0.0
2025/05/13 01:48:17 - mmengine - INFO - paramwise_options -- backbone.stage3.1.blocks.2.conv2.pointwise_conv.bn.weight:weight_decay=0.0
2025/05/13 01:48:17 - mmengine - INFO - paramwise_options -- backbone.stage3.1.blocks.2.conv2.pointwise_conv.bn.bias:weight_decay=0.0
2025/05/13 01:48:17 - mmengine - INFO - paramwise_options -- backbone.stage3.1.blocks.3.conv1.bn.weight:weight_decay=0.0
2025/05/13 01:48:17 - mmengine - INFO - paramwise_options -- backbone.stage3.1.blocks.3.conv1.bn.bias:weight_decay=0.0
2025/05/13 01:48:17 - mmengine - INFO - paramwise_options -- backbone.stage3.1.blocks.3.conv2.depthwise_conv.bn.weight:weight_decay=0.0
2025/05/13 01:48:17 - mmengine - INFO - paramwise_options -- backbone.stage3.1.blocks.3.conv2.depthwise_conv.bn.bias:weight_decay=0.0
2025/05/13 01:48:17 - mmengine - INFO - paramwise_options -- backbone.stage3.1.blocks.3.conv2.pointwise_conv.bn.weight:weight_decay=0.0
2025/05/13 01:48:17 - mmengine - INFO - paramwise_options -- backbone.stage3.1.blocks.3.conv2.pointwise_conv.bn.bias:weight_decay=0.0
2025/05/13 01:48:17 - mmengine - INFO - paramwise_options -- backbone.stage3.1.attention.fc.bias:weight_decay=0.0
2025/05/13 01:48:17 - mmengine - INFO - paramwise_options -- backbone.stage4.0.bn.weight:weight_decay=0.0
2025/05/13 01:48:17 - mmengine - INFO - paramwise_options -- backbone.stage4.0.bn.bias:weight_decay=0.0
2025/05/13 01:48:17 - mmengine - INFO - paramwise_options -- backbone.stage4.1.conv1.bn.weight:weight_decay=0.0
2025/05/13 01:48:17 - mmengine - INFO - paramwise_options -- backbone.stage4.1.conv1.bn.bias:weight_decay=0.0
2025/05/13 01:48:17 - mmengine - INFO - paramwise_options -- backbone.stage4.1.conv2.bn.weight:weight_decay=0.0
2025/05/13 01:48:17 - mmengine - INFO - paramwise_options -- backbone.stage4.1.conv2.bn.bias:weight_decay=0.0
2025/05/13 01:48:17 - mmengine - INFO - paramwise_options -- backbone.stage4.2.main_conv.bn.weight:weight_decay=0.0
2025/05/13 01:48:17 - mmengine - INFO - paramwise_options -- backbone.stage4.2.main_conv.bn.bias:weight_decay=0.0
2025/05/13 01:48:17 - mmengine - INFO - paramwise_options -- backbone.stage4.2.short_conv.bn.weight:weight_decay=0.0
2025/05/13 01:48:17 - mmengine - INFO - paramwise_options -- backbone.stage4.2.short_conv.bn.bias:weight_decay=0.0
2025/05/13 01:48:17 - mmengine - INFO - paramwise_options -- backbone.stage4.2.final_conv.bn.weight:weight_decay=0.0
2025/05/13 01:48:17 - mmengine - INFO - paramwise_options -- backbone.stage4.2.final_conv.bn.bias:weight_decay=0.0
2025/05/13 01:48:17 - mmengine - INFO - paramwise_options -- backbone.stage4.2.blocks.0.conv1.bn.weight:weight_decay=0.0
2025/05/13 01:48:17 - mmengine - INFO - paramwise_options -- backbone.stage4.2.blocks.0.conv1.bn.bias:weight_decay=0.0
2025/05/13 01:48:17 - mmengine - INFO - paramwise_options -- backbone.stage4.2.blocks.0.conv2.depthwise_conv.bn.weight:weight_decay=0.0
2025/05/13 01:48:17 - mmengine - INFO - paramwise_options -- backbone.stage4.2.blocks.0.conv2.depthwise_conv.bn.bias:weight_decay=0.0
2025/05/13 01:48:17 - mmengine - INFO - paramwise_options -- backbone.stage4.2.blocks.0.conv2.pointwise_conv.bn.weight:weight_decay=0.0
2025/05/13 01:48:17 - mmengine - INFO - paramwise_options -- backbone.stage4.2.blocks.0.conv2.pointwise_conv.bn.bias:weight_decay=0.0
2025/05/13 01:48:17 - mmengine - INFO - paramwise_options -- backbone.stage4.2.blocks.1.conv1.bn.weight:weight_decay=0.0
2025/05/13 01:48:17 - mmengine - INFO - paramwise_options -- backbone.stage4.2.blocks.1.conv1.bn.bias:weight_decay=0.0
2025/05/13 01:48:17 - mmengine - INFO - paramwise_options -- backbone.stage4.2.blocks.1.conv2.depthwise_conv.bn.weight:weight_decay=0.0
2025/05/13 01:48:17 - mmengine - INFO - paramwise_options -- backbone.stage4.2.blocks.1.conv2.depthwise_conv.bn.bias:weight_decay=0.0
2025/05/13 01:48:17 - mmengine - INFO - paramwise_options -- backbone.stage4.2.blocks.1.conv2.pointwise_conv.bn.weight:weight_decay=0.0
2025/05/13 01:48:17 - mmengine - INFO - paramwise_options -- backbone.stage4.2.blocks.1.conv2.pointwise_conv.bn.bias:weight_decay=0.0
2025/05/13 01:48:17 - mmengine - INFO - paramwise_options -- backbone.stage4.2.attention.fc.bias:weight_decay=0.0
2025/05/13 01:48:17 - mmengine - INFO - paramwise_options -- neck.reduce_layers.0.bn.weight:weight_decay=0.0
2025/05/13 01:48:17 - mmengine - INFO - paramwise_options -- neck.reduce_layers.0.bn.bias:weight_decay=0.0
2025/05/13 01:48:17 - mmengine - INFO - paramwise_options -- neck.reduce_layers.1.bn.weight:weight_decay=0.0
2025/05/13 01:48:17 - mmengine - INFO - paramwise_options -- neck.reduce_layers.1.bn.bias:weight_decay=0.0
2025/05/13 01:48:17 - mmengine - INFO - paramwise_options -- neck.top_down_blocks.0.main_conv.bn.weight:weight_decay=0.0
2025/05/13 01:48:17 - mmengine - INFO - paramwise_options -- neck.top_down_blocks.0.main_conv.bn.bias:weight_decay=0.0
2025/05/13 01:48:17 - mmengine - INFO - paramwise_options -- neck.top_down_blocks.0.short_conv.bn.weight:weight_decay=0.0
2025/05/13 01:48:17 - mmengine - INFO - paramwise_options -- neck.top_down_blocks.0.short_conv.bn.bias:weight_decay=0.0
2025/05/13 01:48:17 - mmengine - INFO - paramwise_options -- neck.top_down_blocks.0.final_conv.bn.weight:weight_decay=0.0
2025/05/13 01:48:17 - mmengine - INFO - paramwise_options -- neck.top_down_blocks.0.final_conv.bn.bias:weight_decay=0.0
2025/05/13 01:48:17 - mmengine - INFO - paramwise_options -- neck.top_down_blocks.0.blocks.0.conv1.bn.weight:weight_decay=0.0
2025/05/13 01:48:17 - mmengine - INFO - paramwise_options -- neck.top_down_blocks.0.blocks.0.conv1.bn.bias:weight_decay=0.0
2025/05/13 01:48:17 - mmengine - INFO - paramwise_options -- neck.top_down_blocks.0.blocks.0.conv2.depthwise_conv.bn.weight:weight_decay=0.0
2025/05/13 01:48:17 - mmengine - INFO - paramwise_options -- neck.top_down_blocks.0.blocks.0.conv2.depthwise_conv.bn.bias:weight_decay=0.0
2025/05/13 01:48:17 - mmengine - INFO - paramwise_options -- neck.top_down_blocks.0.blocks.0.conv2.pointwise_conv.bn.weight:weight_decay=0.0
2025/05/13 01:48:17 - mmengine - INFO - paramwise_options -- neck.top_down_blocks.0.blocks.0.conv2.pointwise_conv.bn.bias:weight_decay=0.0
2025/05/13 01:48:17 - mmengine - INFO - paramwise_options -- neck.top_down_blocks.0.blocks.1.conv1.bn.weight:weight_decay=0.0
2025/05/13 01:48:17 - mmengine - INFO - paramwise_options -- neck.top_down_blocks.0.blocks.1.conv1.bn.bias:weight_decay=0.0
2025/05/13 01:48:17 - mmengine - INFO - paramwise_options -- neck.top_down_blocks.0.blocks.1.conv2.depthwise_conv.bn.weight:weight_decay=0.0
2025/05/13 01:48:17 - mmengine - INFO - paramwise_options -- neck.top_down_blocks.0.blocks.1.conv2.depthwise_conv.bn.bias:weight_decay=0.0
2025/05/13 01:48:17 - mmengine - INFO - paramwise_options -- neck.top_down_blocks.0.blocks.1.conv2.pointwise_conv.bn.weight:weight_decay=0.0
2025/05/13 01:48:17 - mmengine - INFO - paramwise_options -- neck.top_down_blocks.0.blocks.1.conv2.pointwise_conv.bn.bias:weight_decay=0.0
2025/05/13 01:48:17 - mmengine - INFO - paramwise_options -- neck.top_down_blocks.1.main_conv.bn.weight:weight_decay=0.0
2025/05/13 01:48:17 - mmengine - INFO - paramwise_options -- neck.top_down_blocks.1.main_conv.bn.bias:weight_decay=0.0
2025/05/13 01:48:17 - mmengine - INFO - paramwise_options -- neck.top_down_blocks.1.short_conv.bn.weight:weight_decay=0.0
2025/05/13 01:48:17 - mmengine - INFO - paramwise_options -- neck.top_down_blocks.1.short_conv.bn.bias:weight_decay=0.0
2025/05/13 01:48:17 - mmengine - INFO - paramwise_options -- neck.top_down_blocks.1.final_conv.bn.weight:weight_decay=0.0
2025/05/13 01:48:17 - mmengine - INFO - paramwise_options -- neck.top_down_blocks.1.final_conv.bn.bias:weight_decay=0.0
2025/05/13 01:48:17 - mmengine - INFO - paramwise_options -- neck.top_down_blocks.1.blocks.0.conv1.bn.weight:weight_decay=0.0
2025/05/13 01:48:17 - mmengine - INFO - paramwise_options -- neck.top_down_blocks.1.blocks.0.conv1.bn.bias:weight_decay=0.0
2025/05/13 01:48:17 - mmengine - INFO - paramwise_options -- neck.top_down_blocks.1.blocks.0.conv2.depthwise_conv.bn.weight:weight_decay=0.0
2025/05/13 01:48:17 - mmengine - INFO - paramwise_options -- neck.top_down_blocks.1.blocks.0.conv2.depthwise_conv.bn.bias:weight_decay=0.0
2025/05/13 01:48:17 - mmengine - INFO - paramwise_options -- neck.top_down_blocks.1.blocks.0.conv2.pointwise_conv.bn.weight:weight_decay=0.0
2025/05/13 01:48:17 - mmengine - INFO - paramwise_options -- neck.top_down_blocks.1.blocks.0.conv2.pointwise_conv.bn.bias:weight_decay=0.0
2025/05/13 01:48:17 - mmengine - INFO - paramwise_options -- neck.top_down_blocks.1.blocks.1.conv1.bn.weight:weight_decay=0.0
2025/05/13 01:48:17 - mmengine - INFO - paramwise_options -- neck.top_down_blocks.1.blocks.1.conv1.bn.bias:weight_decay=0.0
2025/05/13 01:48:17 - mmengine - INFO - paramwise_options -- neck.top_down_blocks.1.blocks.1.conv2.depthwise_conv.bn.weight:weight_decay=0.0
2025/05/13 01:48:17 - mmengine - INFO - paramwise_options -- neck.top_down_blocks.1.blocks.1.conv2.depthwise_conv.bn.bias:weight_decay=0.0
2025/05/13 01:48:17 - mmengine - INFO - paramwise_options -- neck.top_down_blocks.1.blocks.1.conv2.pointwise_conv.bn.weight:weight_decay=0.0
2025/05/13 01:48:17 - mmengine - INFO - paramwise_options -- neck.top_down_blocks.1.blocks.1.conv2.pointwise_conv.bn.bias:weight_decay=0.0
2025/05/13 01:48:17 - mmengine - INFO - paramwise_options -- neck.downsamples.0.bn.weight:weight_decay=0.0
2025/05/13 01:48:17 - mmengine - INFO - paramwise_options -- neck.downsamples.0.bn.bias:weight_decay=0.0
2025/05/13 01:48:17 - mmengine - INFO - paramwise_options -- neck.downsamples.1.bn.weight:weight_decay=0.0
2025/05/13 01:48:17 - mmengine - INFO - paramwise_options -- neck.downsamples.1.bn.bias:weight_decay=0.0
2025/05/13 01:48:17 - mmengine - INFO - paramwise_options -- neck.bottom_up_blocks.0.main_conv.bn.weight:weight_decay=0.0
2025/05/13 01:48:17 - mmengine - INFO - paramwise_options -- neck.bottom_up_blocks.0.main_conv.bn.bias:weight_decay=0.0
2025/05/13 01:48:17 - mmengine - INFO - paramwise_options -- neck.bottom_up_blocks.0.short_conv.bn.weight:weight_decay=0.0
2025/05/13 01:48:17 - mmengine - INFO - paramwise_options -- neck.bottom_up_blocks.0.short_conv.bn.bias:weight_decay=0.0
2025/05/13 01:48:17 - mmengine - INFO - paramwise_options -- neck.bottom_up_blocks.0.final_conv.bn.weight:weight_decay=0.0
2025/05/13 01:48:17 - mmengine - INFO - paramwise_options -- neck.bottom_up_blocks.0.final_conv.bn.bias:weight_decay=0.0
2025/05/13 01:48:17 - mmengine - INFO - paramwise_options -- neck.bottom_up_blocks.0.blocks.0.conv1.bn.weight:weight_decay=0.0
2025/05/13 01:48:17 - mmengine - INFO - paramwise_options -- neck.bottom_up_blocks.0.blocks.0.conv1.bn.bias:weight_decay=0.0
2025/05/13 01:48:17 - mmengine - INFO - paramwise_options -- neck.bottom_up_blocks.0.blocks.0.conv2.depthwise_conv.bn.weight:weight_decay=0.0
2025/05/13 01:48:17 - mmengine - INFO - paramwise_options -- neck.bottom_up_blocks.0.blocks.0.conv2.depthwise_conv.bn.bias:weight_decay=0.0
2025/05/13 01:48:17 - mmengine - INFO - paramwise_options -- neck.bottom_up_blocks.0.blocks.0.conv2.pointwise_conv.bn.weight:weight_decay=0.0
2025/05/13 01:48:17 - mmengine - INFO - paramwise_options -- neck.bottom_up_blocks.0.blocks.0.conv2.pointwise_conv.bn.bias:weight_decay=0.0
2025/05/13 01:48:17 - mmengine - INFO - paramwise_options -- neck.bottom_up_blocks.0.blocks.1.conv1.bn.weight:weight_decay=0.0
2025/05/13 01:48:17 - mmengine - INFO - paramwise_options -- neck.bottom_up_blocks.0.blocks.1.conv1.bn.bias:weight_decay=0.0
2025/05/13 01:48:17 - mmengine - INFO - paramwise_options -- neck.bottom_up_blocks.0.blocks.1.conv2.depthwise_conv.bn.weight:weight_decay=0.0
2025/05/13 01:48:17 - mmengine - INFO - paramwise_options -- neck.bottom_up_blocks.0.blocks.1.conv2.depthwise_conv.bn.bias:weight_decay=0.0
2025/05/13 01:48:17 - mmengine - INFO - paramwise_options -- neck.bottom_up_blocks.0.blocks.1.conv2.pointwise_conv.bn.weight:weight_decay=0.0
2025/05/13 01:48:17 - mmengine - INFO - paramwise_options -- neck.bottom_up_blocks.0.blocks.1.conv2.pointwise_conv.bn.bias:weight_decay=0.0
2025/05/13 01:48:17 - mmengine - INFO - paramwise_options -- neck.bottom_up_blocks.1.main_conv.bn.weight:weight_decay=0.0
2025/05/13 01:48:17 - mmengine - INFO - paramwise_options -- neck.bottom_up_blocks.1.main_conv.bn.bias:weight_decay=0.0
2025/05/13 01:48:17 - mmengine - INFO - paramwise_options -- neck.bottom_up_blocks.1.short_conv.bn.weight:weight_decay=0.0
2025/05/13 01:48:17 - mmengine - INFO - paramwise_options -- neck.bottom_up_blocks.1.short_conv.bn.bias:weight_decay=0.0
2025/05/13 01:48:17 - mmengine - INFO - paramwise_options -- neck.bottom_up_blocks.1.final_conv.bn.weight:weight_decay=0.0
2025/05/13 01:48:17 - mmengine - INFO - paramwise_options -- neck.bottom_up_blocks.1.final_conv.bn.bias:weight_decay=0.0
2025/05/13 01:48:17 - mmengine - INFO - paramwise_options -- neck.bottom_up_blocks.1.blocks.0.conv1.bn.weight:weight_decay=0.0
2025/05/13 01:48:17 - mmengine - INFO - paramwise_options -- neck.bottom_up_blocks.1.blocks.0.conv1.bn.bias:weight_decay=0.0
2025/05/13 01:48:17 - mmengine - INFO - paramwise_options -- neck.bottom_up_blocks.1.blocks.0.conv2.depthwise_conv.bn.weight:weight_decay=0.0
2025/05/13 01:48:17 - mmengine - INFO - paramwise_options -- neck.bottom_up_blocks.1.blocks.0.conv2.depthwise_conv.bn.bias:weight_decay=0.0
2025/05/13 01:48:17 - mmengine - INFO - paramwise_options -- neck.bottom_up_blocks.1.blocks.0.conv2.pointwise_conv.bn.weight:weight_decay=0.0
2025/05/13 01:48:17 - mmengine - INFO - paramwise_options -- neck.bottom_up_blocks.1.blocks.0.conv2.pointwise_conv.bn.bias:weight_decay=0.0
2025/05/13 01:48:17 - mmengine - INFO - paramwise_options -- neck.bottom_up_blocks.1.blocks.1.conv1.bn.weight:weight_decay=0.0
2025/05/13 01:48:17 - mmengine - INFO - paramwise_options -- neck.bottom_up_blocks.1.blocks.1.conv1.bn.bias:weight_decay=0.0
2025/05/13 01:48:17 - mmengine - INFO - paramwise_options -- neck.bottom_up_blocks.1.blocks.1.conv2.depthwise_conv.bn.weight:weight_decay=0.0
2025/05/13 01:48:17 - mmengine - INFO - paramwise_options -- neck.bottom_up_blocks.1.blocks.1.conv2.depthwise_conv.bn.bias:weight_decay=0.0
2025/05/13 01:48:17 - mmengine - INFO - paramwise_options -- neck.bottom_up_blocks.1.blocks.1.conv2.pointwise_conv.bn.weight:weight_decay=0.0
2025/05/13 01:48:17 - mmengine - INFO - paramwise_options -- neck.bottom_up_blocks.1.blocks.1.conv2.pointwise_conv.bn.bias:weight_decay=0.0
2025/05/13 01:48:17 - mmengine - INFO - paramwise_options -- neck.out_convs.0.bn.weight:weight_decay=0.0
2025/05/13 01:48:17 - mmengine - INFO - paramwise_options -- neck.out_convs.0.bn.bias:weight_decay=0.0
2025/05/13 01:48:17 - mmengine - INFO - paramwise_options -- neck.out_convs.1.bn.weight:weight_decay=0.0
2025/05/13 01:48:17 - mmengine - INFO - paramwise_options -- neck.out_convs.1.bn.bias:weight_decay=0.0
2025/05/13 01:48:17 - mmengine - INFO - paramwise_options -- neck.out_convs.2.bn.weight:weight_decay=0.0
2025/05/13 01:48:17 - mmengine - INFO - paramwise_options -- neck.out_convs.2.bn.bias:weight_decay=0.0
2025/05/13 01:48:17 - mmengine - INFO - paramwise_options -- bbox_head.cls_convs.0.0.bn.weight:weight_decay=0.0
2025/05/13 01:48:17 - mmengine - INFO - paramwise_options -- bbox_head.cls_convs.0.0.bn.bias:weight_decay=0.0
2025/05/13 01:48:17 - mmengine - INFO - paramwise_options -- bbox_head.cls_convs.0.1.bn.weight:weight_decay=0.0
2025/05/13 01:48:17 - mmengine - INFO - paramwise_options -- bbox_head.cls_convs.0.1.bn.bias:weight_decay=0.0
2025/05/13 01:48:17 - mmengine - WARNING - bbox_head.cls_convs.1.0.conv is duplicate. It is skipped since bypass_duplicate=True
2025/05/13 01:48:17 - mmengine - INFO - paramwise_options -- bbox_head.cls_convs.1.0.bn.weight:weight_decay=0.0
2025/05/13 01:48:17 - mmengine - INFO - paramwise_options -- bbox_head.cls_convs.1.0.bn.bias:weight_decay=0.0
2025/05/13 01:48:17 - mmengine - WARNING - bbox_head.cls_convs.1.1.conv is duplicate. It is skipped since bypass_duplicate=True
2025/05/13 01:48:17 - mmengine - INFO - paramwise_options -- bbox_head.cls_convs.1.1.bn.weight:weight_decay=0.0
2025/05/13 01:48:17 - mmengine - INFO - paramwise_options -- bbox_head.cls_convs.1.1.bn.bias:weight_decay=0.0
2025/05/13 01:48:17 - mmengine - WARNING - bbox_head.cls_convs.2.0.conv is duplicate. It is skipped since bypass_duplicate=True
2025/05/13 01:48:17 - mmengine - INFO - paramwise_options -- bbox_head.cls_convs.2.0.bn.weight:weight_decay=0.0
2025/05/13 01:48:17 - mmengine - INFO - paramwise_options -- bbox_head.cls_convs.2.0.bn.bias:weight_decay=0.0
2025/05/13 01:48:17 - mmengine - WARNING - bbox_head.cls_convs.2.1.conv is duplicate. It is skipped since bypass_duplicate=True
2025/05/13 01:48:17 - mmengine - INFO - paramwise_options -- bbox_head.cls_convs.2.1.bn.weight:weight_decay=0.0
2025/05/13 01:48:17 - mmengine - INFO - paramwise_options -- bbox_head.cls_convs.2.1.bn.bias:weight_decay=0.0
2025/05/13 01:48:17 - mmengine - INFO - paramwise_options -- bbox_head.reg_convs.0.0.bn.weight:weight_decay=0.0
2025/05/13 01:48:17 - mmengine - INFO - paramwise_options -- bbox_head.reg_convs.0.0.bn.bias:weight_decay=0.0
2025/05/13 01:48:17 - mmengine - INFO - paramwise_options -- bbox_head.reg_convs.0.1.bn.weight:weight_decay=0.0
2025/05/13 01:48:17 - mmengine - INFO - paramwise_options -- bbox_head.reg_convs.0.1.bn.bias:weight_decay=0.0
2025/05/13 01:48:17 - mmengine - WARNING - bbox_head.reg_convs.1.0.conv is duplicate. It is skipped since bypass_duplicate=True
2025/05/13 01:48:17 - mmengine - INFO - paramwise_options -- bbox_head.reg_convs.1.0.bn.weight:weight_decay=0.0
2025/05/13 01:48:17 - mmengine - INFO - paramwise_options -- bbox_head.reg_convs.1.0.bn.bias:weight_decay=0.0
2025/05/13 01:48:17 - mmengine - WARNING - bbox_head.reg_convs.1.1.conv is duplicate. It is skipped since bypass_duplicate=True
2025/05/13 01:48:17 - mmengine - INFO - paramwise_options -- bbox_head.reg_convs.1.1.bn.weight:weight_decay=0.0
2025/05/13 01:48:17 - mmengine - INFO - paramwise_options -- bbox_head.reg_convs.1.1.bn.bias:weight_decay=0.0
2025/05/13 01:48:17 - mmengine - WARNING - bbox_head.reg_convs.2.0.conv is duplicate. It is skipped since bypass_duplicate=True
2025/05/13 01:48:17 - mmengine - INFO - paramwise_options -- bbox_head.reg_convs.2.0.bn.weight:weight_decay=0.0
2025/05/13 01:48:17 - mmengine - INFO - paramwise_options -- bbox_head.reg_convs.2.0.bn.bias:weight_decay=0.0
2025/05/13 01:48:17 - mmengine - WARNING - bbox_head.reg_convs.2.1.conv is duplicate. It is skipped since bypass_duplicate=True
2025/05/13 01:48:17 - mmengine - INFO - paramwise_options -- bbox_head.reg_convs.2.1.bn.weight:weight_decay=0.0
2025/05/13 01:48:17 - mmengine - INFO - paramwise_options -- bbox_head.reg_convs.2.1.bn.bias:weight_decay=0.0
2025/05/13 01:48:17 - mmengine - INFO - paramwise_options -- bbox_head.rtm_cls.0.bias:weight_decay=0.0
2025/05/13 01:48:17 - mmengine - INFO - paramwise_options -- bbox_head.rtm_cls.1.bias:weight_decay=0.0
2025/05/13 01:48:17 - mmengine - INFO - paramwise_options -- bbox_head.rtm_cls.2.bias:weight_decay=0.0
2025/05/13 01:48:17 - mmengine - INFO - paramwise_options -- bbox_head.rtm_reg.0.bias:weight_decay=0.0
2025/05/13 01:48:17 - mmengine - INFO - paramwise_options -- bbox_head.rtm_reg.1.bias:weight_decay=0.0
2025/05/13 01:48:17 - mmengine - INFO - paramwise_options -- bbox_head.rtm_reg.2.bias:weight_decay=0.0
Name of parameter - Initialization information

backbone.stem.0.conv.weight - torch.Size([24, 3, 3, 3]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stem.0.bn.weight - torch.Size([24]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stem.0.bn.bias - torch.Size([24]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stem.1.conv.weight - torch.Size([24, 24, 3, 3]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stem.1.bn.weight - torch.Size([24]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stem.1.bn.bias - torch.Size([24]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stem.2.conv.weight - torch.Size([48, 24, 3, 3]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stem.2.bn.weight - torch.Size([48]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stem.2.bn.bias - torch.Size([48]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage1.0.conv.weight - torch.Size([96, 48, 3, 3]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage1.0.bn.weight - torch.Size([96]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage1.0.bn.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage1.1.main_conv.conv.weight - torch.Size([48, 96, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage1.1.main_conv.bn.weight - torch.Size([48]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage1.1.main_conv.bn.bias - torch.Size([48]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage1.1.short_conv.conv.weight - torch.Size([48, 96, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage1.1.short_conv.bn.weight - torch.Size([48]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage1.1.short_conv.bn.bias - torch.Size([48]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage1.1.final_conv.conv.weight - torch.Size([96, 96, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage1.1.final_conv.bn.weight - torch.Size([96]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage1.1.final_conv.bn.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage1.1.blocks.0.conv1.conv.weight - torch.Size([48, 48, 3, 3]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage1.1.blocks.0.conv1.bn.weight - torch.Size([48]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage1.1.blocks.0.conv1.bn.bias - torch.Size([48]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage1.1.blocks.0.conv2.depthwise_conv.conv.weight - torch.Size([48, 1, 5, 5]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage1.1.blocks.0.conv2.depthwise_conv.bn.weight - torch.Size([48]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage1.1.blocks.0.conv2.depthwise_conv.bn.bias - torch.Size([48]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage1.1.blocks.0.conv2.pointwise_conv.conv.weight - torch.Size([48, 48, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage1.1.blocks.0.conv2.pointwise_conv.bn.weight - torch.Size([48]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage1.1.blocks.0.conv2.pointwise_conv.bn.bias - torch.Size([48]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage1.1.blocks.1.conv1.conv.weight - torch.Size([48, 48, 3, 3]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage1.1.blocks.1.conv1.bn.weight - torch.Size([48]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage1.1.blocks.1.conv1.bn.bias - torch.Size([48]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage1.1.blocks.1.conv2.depthwise_conv.conv.weight - torch.Size([48, 1, 5, 5]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage1.1.blocks.1.conv2.depthwise_conv.bn.weight - torch.Size([48]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage1.1.blocks.1.conv2.depthwise_conv.bn.bias - torch.Size([48]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage1.1.blocks.1.conv2.pointwise_conv.conv.weight - torch.Size([48, 48, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage1.1.blocks.1.conv2.pointwise_conv.bn.weight - torch.Size([48]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage1.1.blocks.1.conv2.pointwise_conv.bn.bias - torch.Size([48]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage1.1.attention.fc.weight - torch.Size([96, 96, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage1.1.attention.fc.bias - torch.Size([96]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage2.0.conv.weight - torch.Size([192, 96, 3, 3]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage2.0.bn.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage2.0.bn.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage2.1.main_conv.conv.weight - torch.Size([96, 192, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage2.1.main_conv.bn.weight - torch.Size([96]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage2.1.main_conv.bn.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage2.1.short_conv.conv.weight - torch.Size([96, 192, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage2.1.short_conv.bn.weight - torch.Size([96]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage2.1.short_conv.bn.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage2.1.final_conv.conv.weight - torch.Size([192, 192, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage2.1.final_conv.bn.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage2.1.final_conv.bn.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage2.1.blocks.0.conv1.conv.weight - torch.Size([96, 96, 3, 3]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage2.1.blocks.0.conv1.bn.weight - torch.Size([96]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage2.1.blocks.0.conv1.bn.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage2.1.blocks.0.conv2.depthwise_conv.conv.weight - torch.Size([96, 1, 5, 5]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage2.1.blocks.0.conv2.depthwise_conv.bn.weight - torch.Size([96]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage2.1.blocks.0.conv2.depthwise_conv.bn.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage2.1.blocks.0.conv2.pointwise_conv.conv.weight - torch.Size([96, 96, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage2.1.blocks.0.conv2.pointwise_conv.bn.weight - torch.Size([96]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage2.1.blocks.0.conv2.pointwise_conv.bn.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage2.1.blocks.1.conv1.conv.weight - torch.Size([96, 96, 3, 3]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage2.1.blocks.1.conv1.bn.weight - torch.Size([96]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage2.1.blocks.1.conv1.bn.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage2.1.blocks.1.conv2.depthwise_conv.conv.weight - torch.Size([96, 1, 5, 5]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage2.1.blocks.1.conv2.depthwise_conv.bn.weight - torch.Size([96]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage2.1.blocks.1.conv2.depthwise_conv.bn.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage2.1.blocks.1.conv2.pointwise_conv.conv.weight - torch.Size([96, 96, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage2.1.blocks.1.conv2.pointwise_conv.bn.weight - torch.Size([96]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage2.1.blocks.1.conv2.pointwise_conv.bn.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage2.1.blocks.2.conv1.conv.weight - torch.Size([96, 96, 3, 3]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage2.1.blocks.2.conv1.bn.weight - torch.Size([96]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage2.1.blocks.2.conv1.bn.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage2.1.blocks.2.conv2.depthwise_conv.conv.weight - torch.Size([96, 1, 5, 5]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage2.1.blocks.2.conv2.depthwise_conv.bn.weight - torch.Size([96]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage2.1.blocks.2.conv2.depthwise_conv.bn.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage2.1.blocks.2.conv2.pointwise_conv.conv.weight - torch.Size([96, 96, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage2.1.blocks.2.conv2.pointwise_conv.bn.weight - torch.Size([96]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage2.1.blocks.2.conv2.pointwise_conv.bn.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage2.1.blocks.3.conv1.conv.weight - torch.Size([96, 96, 3, 3]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage2.1.blocks.3.conv1.bn.weight - torch.Size([96]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage2.1.blocks.3.conv1.bn.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage2.1.blocks.3.conv2.depthwise_conv.conv.weight - torch.Size([96, 1, 5, 5]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage2.1.blocks.3.conv2.depthwise_conv.bn.weight - torch.Size([96]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage2.1.blocks.3.conv2.depthwise_conv.bn.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage2.1.blocks.3.conv2.pointwise_conv.conv.weight - torch.Size([96, 96, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage2.1.blocks.3.conv2.pointwise_conv.bn.weight - torch.Size([96]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage2.1.blocks.3.conv2.pointwise_conv.bn.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage2.1.attention.fc.weight - torch.Size([192, 192, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage2.1.attention.fc.bias - torch.Size([192]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage3.0.conv.weight - torch.Size([384, 192, 3, 3]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage3.0.bn.weight - torch.Size([384]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage3.0.bn.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage3.1.main_conv.conv.weight - torch.Size([192, 384, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage3.1.main_conv.bn.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage3.1.main_conv.bn.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage3.1.short_conv.conv.weight - torch.Size([192, 384, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage3.1.short_conv.bn.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage3.1.short_conv.bn.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage3.1.final_conv.conv.weight - torch.Size([384, 384, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage3.1.final_conv.bn.weight - torch.Size([384]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage3.1.final_conv.bn.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage3.1.blocks.0.conv1.conv.weight - torch.Size([192, 192, 3, 3]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage3.1.blocks.0.conv1.bn.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage3.1.blocks.0.conv1.bn.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage3.1.blocks.0.conv2.depthwise_conv.conv.weight - torch.Size([192, 1, 5, 5]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage3.1.blocks.0.conv2.depthwise_conv.bn.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage3.1.blocks.0.conv2.depthwise_conv.bn.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage3.1.blocks.0.conv2.pointwise_conv.conv.weight - torch.Size([192, 192, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage3.1.blocks.0.conv2.pointwise_conv.bn.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage3.1.blocks.0.conv2.pointwise_conv.bn.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage3.1.blocks.1.conv1.conv.weight - torch.Size([192, 192, 3, 3]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage3.1.blocks.1.conv1.bn.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage3.1.blocks.1.conv1.bn.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage3.1.blocks.1.conv2.depthwise_conv.conv.weight - torch.Size([192, 1, 5, 5]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage3.1.blocks.1.conv2.depthwise_conv.bn.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage3.1.blocks.1.conv2.depthwise_conv.bn.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage3.1.blocks.1.conv2.pointwise_conv.conv.weight - torch.Size([192, 192, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage3.1.blocks.1.conv2.pointwise_conv.bn.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage3.1.blocks.1.conv2.pointwise_conv.bn.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage3.1.blocks.2.conv1.conv.weight - torch.Size([192, 192, 3, 3]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage3.1.blocks.2.conv1.bn.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage3.1.blocks.2.conv1.bn.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage3.1.blocks.2.conv2.depthwise_conv.conv.weight - torch.Size([192, 1, 5, 5]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage3.1.blocks.2.conv2.depthwise_conv.bn.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage3.1.blocks.2.conv2.depthwise_conv.bn.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage3.1.blocks.2.conv2.pointwise_conv.conv.weight - torch.Size([192, 192, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage3.1.blocks.2.conv2.pointwise_conv.bn.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage3.1.blocks.2.conv2.pointwise_conv.bn.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage3.1.blocks.3.conv1.conv.weight - torch.Size([192, 192, 3, 3]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage3.1.blocks.3.conv1.bn.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage3.1.blocks.3.conv1.bn.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage3.1.blocks.3.conv2.depthwise_conv.conv.weight - torch.Size([192, 1, 5, 5]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage3.1.blocks.3.conv2.depthwise_conv.bn.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage3.1.blocks.3.conv2.depthwise_conv.bn.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage3.1.blocks.3.conv2.pointwise_conv.conv.weight - torch.Size([192, 192, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage3.1.blocks.3.conv2.pointwise_conv.bn.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage3.1.blocks.3.conv2.pointwise_conv.bn.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage3.1.attention.fc.weight - torch.Size([384, 384, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage3.1.attention.fc.bias - torch.Size([384]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage4.0.conv.weight - torch.Size([768, 384, 3, 3]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage4.0.bn.weight - torch.Size([768]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage4.0.bn.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage4.1.conv1.conv.weight - torch.Size([384, 768, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage4.1.conv1.bn.weight - torch.Size([384]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage4.1.conv1.bn.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage4.1.conv2.conv.weight - torch.Size([768, 1536, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage4.1.conv2.bn.weight - torch.Size([768]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage4.1.conv2.bn.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage4.2.main_conv.conv.weight - torch.Size([384, 768, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage4.2.main_conv.bn.weight - torch.Size([384]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage4.2.main_conv.bn.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage4.2.short_conv.conv.weight - torch.Size([384, 768, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage4.2.short_conv.bn.weight - torch.Size([384]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage4.2.short_conv.bn.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage4.2.final_conv.conv.weight - torch.Size([768, 768, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage4.2.final_conv.bn.weight - torch.Size([768]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage4.2.final_conv.bn.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage4.2.blocks.0.conv1.conv.weight - torch.Size([384, 384, 3, 3]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage4.2.blocks.0.conv1.bn.weight - torch.Size([384]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage4.2.blocks.0.conv1.bn.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage4.2.blocks.0.conv2.depthwise_conv.conv.weight - torch.Size([384, 1, 5, 5]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage4.2.blocks.0.conv2.depthwise_conv.bn.weight - torch.Size([384]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage4.2.blocks.0.conv2.depthwise_conv.bn.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage4.2.blocks.0.conv2.pointwise_conv.conv.weight - torch.Size([384, 384, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage4.2.blocks.0.conv2.pointwise_conv.bn.weight - torch.Size([384]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage4.2.blocks.0.conv2.pointwise_conv.bn.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage4.2.blocks.1.conv1.conv.weight - torch.Size([384, 384, 3, 3]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage4.2.blocks.1.conv1.bn.weight - torch.Size([384]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage4.2.blocks.1.conv1.bn.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage4.2.blocks.1.conv2.depthwise_conv.conv.weight - torch.Size([384, 1, 5, 5]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage4.2.blocks.1.conv2.depthwise_conv.bn.weight - torch.Size([384]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage4.2.blocks.1.conv2.depthwise_conv.bn.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage4.2.blocks.1.conv2.pointwise_conv.conv.weight - torch.Size([384, 384, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage4.2.blocks.1.conv2.pointwise_conv.bn.weight - torch.Size([384]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage4.2.blocks.1.conv2.pointwise_conv.bn.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage4.2.attention.fc.weight - torch.Size([768, 768, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage4.2.attention.fc.bias - torch.Size([768]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

neck.reduce_layers.0.conv.weight - torch.Size([384, 768, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

neck.reduce_layers.0.bn.weight - torch.Size([384]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.reduce_layers.0.bn.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.reduce_layers.1.conv.weight - torch.Size([192, 384, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

neck.reduce_layers.1.bn.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.reduce_layers.1.bn.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.top_down_blocks.0.main_conv.conv.weight - torch.Size([192, 768, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

neck.top_down_blocks.0.main_conv.bn.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.top_down_blocks.0.main_conv.bn.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.top_down_blocks.0.short_conv.conv.weight - torch.Size([192, 768, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

neck.top_down_blocks.0.short_conv.bn.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.top_down_blocks.0.short_conv.bn.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.top_down_blocks.0.final_conv.conv.weight - torch.Size([384, 384, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

neck.top_down_blocks.0.final_conv.bn.weight - torch.Size([384]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.top_down_blocks.0.final_conv.bn.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.top_down_blocks.0.blocks.0.conv1.conv.weight - torch.Size([192, 192, 3, 3]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

neck.top_down_blocks.0.blocks.0.conv1.bn.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.top_down_blocks.0.blocks.0.conv1.bn.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.top_down_blocks.0.blocks.0.conv2.depthwise_conv.conv.weight - torch.Size([192, 1, 5, 5]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

neck.top_down_blocks.0.blocks.0.conv2.depthwise_conv.bn.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.top_down_blocks.0.blocks.0.conv2.depthwise_conv.bn.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.top_down_blocks.0.blocks.0.conv2.pointwise_conv.conv.weight - torch.Size([192, 192, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

neck.top_down_blocks.0.blocks.0.conv2.pointwise_conv.bn.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.top_down_blocks.0.blocks.0.conv2.pointwise_conv.bn.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.top_down_blocks.0.blocks.1.conv1.conv.weight - torch.Size([192, 192, 3, 3]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

neck.top_down_blocks.0.blocks.1.conv1.bn.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.top_down_blocks.0.blocks.1.conv1.bn.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.top_down_blocks.0.blocks.1.conv2.depthwise_conv.conv.weight - torch.Size([192, 1, 5, 5]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

neck.top_down_blocks.0.blocks.1.conv2.depthwise_conv.bn.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.top_down_blocks.0.blocks.1.conv2.depthwise_conv.bn.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.top_down_blocks.0.blocks.1.conv2.pointwise_conv.conv.weight - torch.Size([192, 192, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

neck.top_down_blocks.0.blocks.1.conv2.pointwise_conv.bn.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.top_down_blocks.0.blocks.1.conv2.pointwise_conv.bn.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.top_down_blocks.1.main_conv.conv.weight - torch.Size([96, 384, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

neck.top_down_blocks.1.main_conv.bn.weight - torch.Size([96]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.top_down_blocks.1.main_conv.bn.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.top_down_blocks.1.short_conv.conv.weight - torch.Size([96, 384, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

neck.top_down_blocks.1.short_conv.bn.weight - torch.Size([96]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.top_down_blocks.1.short_conv.bn.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.top_down_blocks.1.final_conv.conv.weight - torch.Size([192, 192, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

neck.top_down_blocks.1.final_conv.bn.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.top_down_blocks.1.final_conv.bn.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.top_down_blocks.1.blocks.0.conv1.conv.weight - torch.Size([96, 96, 3, 3]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

neck.top_down_blocks.1.blocks.0.conv1.bn.weight - torch.Size([96]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.top_down_blocks.1.blocks.0.conv1.bn.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.top_down_blocks.1.blocks.0.conv2.depthwise_conv.conv.weight - torch.Size([96, 1, 5, 5]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

neck.top_down_blocks.1.blocks.0.conv2.depthwise_conv.bn.weight - torch.Size([96]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.top_down_blocks.1.blocks.0.conv2.depthwise_conv.bn.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.top_down_blocks.1.blocks.0.conv2.pointwise_conv.conv.weight - torch.Size([96, 96, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

neck.top_down_blocks.1.blocks.0.conv2.pointwise_conv.bn.weight - torch.Size([96]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.top_down_blocks.1.blocks.0.conv2.pointwise_conv.bn.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.top_down_blocks.1.blocks.1.conv1.conv.weight - torch.Size([96, 96, 3, 3]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

neck.top_down_blocks.1.blocks.1.conv1.bn.weight - torch.Size([96]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.top_down_blocks.1.blocks.1.conv1.bn.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.top_down_blocks.1.blocks.1.conv2.depthwise_conv.conv.weight - torch.Size([96, 1, 5, 5]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

neck.top_down_blocks.1.blocks.1.conv2.depthwise_conv.bn.weight - torch.Size([96]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.top_down_blocks.1.blocks.1.conv2.depthwise_conv.bn.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.top_down_blocks.1.blocks.1.conv2.pointwise_conv.conv.weight - torch.Size([96, 96, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

neck.top_down_blocks.1.blocks.1.conv2.pointwise_conv.bn.weight - torch.Size([96]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.top_down_blocks.1.blocks.1.conv2.pointwise_conv.bn.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.downsamples.0.conv.weight - torch.Size([192, 192, 3, 3]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

neck.downsamples.0.bn.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.downsamples.0.bn.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.downsamples.1.conv.weight - torch.Size([384, 384, 3, 3]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

neck.downsamples.1.bn.weight - torch.Size([384]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.downsamples.1.bn.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.bottom_up_blocks.0.main_conv.conv.weight - torch.Size([192, 384, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

neck.bottom_up_blocks.0.main_conv.bn.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.bottom_up_blocks.0.main_conv.bn.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.bottom_up_blocks.0.short_conv.conv.weight - torch.Size([192, 384, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

neck.bottom_up_blocks.0.short_conv.bn.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.bottom_up_blocks.0.short_conv.bn.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.bottom_up_blocks.0.final_conv.conv.weight - torch.Size([384, 384, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

neck.bottom_up_blocks.0.final_conv.bn.weight - torch.Size([384]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.bottom_up_blocks.0.final_conv.bn.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.bottom_up_blocks.0.blocks.0.conv1.conv.weight - torch.Size([192, 192, 3, 3]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

neck.bottom_up_blocks.0.blocks.0.conv1.bn.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.bottom_up_blocks.0.blocks.0.conv1.bn.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.bottom_up_blocks.0.blocks.0.conv2.depthwise_conv.conv.weight - torch.Size([192, 1, 5, 5]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

neck.bottom_up_blocks.0.blocks.0.conv2.depthwise_conv.bn.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.bottom_up_blocks.0.blocks.0.conv2.depthwise_conv.bn.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.bottom_up_blocks.0.blocks.0.conv2.pointwise_conv.conv.weight - torch.Size([192, 192, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

neck.bottom_up_blocks.0.blocks.0.conv2.pointwise_conv.bn.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.bottom_up_blocks.0.blocks.0.conv2.pointwise_conv.bn.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.bottom_up_blocks.0.blocks.1.conv1.conv.weight - torch.Size([192, 192, 3, 3]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

neck.bottom_up_blocks.0.blocks.1.conv1.bn.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.bottom_up_blocks.0.blocks.1.conv1.bn.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.bottom_up_blocks.0.blocks.1.conv2.depthwise_conv.conv.weight - torch.Size([192, 1, 5, 5]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

neck.bottom_up_blocks.0.blocks.1.conv2.depthwise_conv.bn.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.bottom_up_blocks.0.blocks.1.conv2.depthwise_conv.bn.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.bottom_up_blocks.0.blocks.1.conv2.pointwise_conv.conv.weight - torch.Size([192, 192, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

neck.bottom_up_blocks.0.blocks.1.conv2.pointwise_conv.bn.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.bottom_up_blocks.0.blocks.1.conv2.pointwise_conv.bn.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.bottom_up_blocks.1.main_conv.conv.weight - torch.Size([384, 768, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

neck.bottom_up_blocks.1.main_conv.bn.weight - torch.Size([384]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.bottom_up_blocks.1.main_conv.bn.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.bottom_up_blocks.1.short_conv.conv.weight - torch.Size([384, 768, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

neck.bottom_up_blocks.1.short_conv.bn.weight - torch.Size([384]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.bottom_up_blocks.1.short_conv.bn.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.bottom_up_blocks.1.final_conv.conv.weight - torch.Size([768, 768, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

neck.bottom_up_blocks.1.final_conv.bn.weight - torch.Size([768]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.bottom_up_blocks.1.final_conv.bn.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.bottom_up_blocks.1.blocks.0.conv1.conv.weight - torch.Size([384, 384, 3, 3]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

neck.bottom_up_blocks.1.blocks.0.conv1.bn.weight - torch.Size([384]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.bottom_up_blocks.1.blocks.0.conv1.bn.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.bottom_up_blocks.1.blocks.0.conv2.depthwise_conv.conv.weight - torch.Size([384, 1, 5, 5]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

neck.bottom_up_blocks.1.blocks.0.conv2.depthwise_conv.bn.weight - torch.Size([384]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.bottom_up_blocks.1.blocks.0.conv2.depthwise_conv.bn.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.bottom_up_blocks.1.blocks.0.conv2.pointwise_conv.conv.weight - torch.Size([384, 384, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

neck.bottom_up_blocks.1.blocks.0.conv2.pointwise_conv.bn.weight - torch.Size([384]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.bottom_up_blocks.1.blocks.0.conv2.pointwise_conv.bn.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.bottom_up_blocks.1.blocks.1.conv1.conv.weight - torch.Size([384, 384, 3, 3]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

neck.bottom_up_blocks.1.blocks.1.conv1.bn.weight - torch.Size([384]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.bottom_up_blocks.1.blocks.1.conv1.bn.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.bottom_up_blocks.1.blocks.1.conv2.depthwise_conv.conv.weight - torch.Size([384, 1, 5, 5]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

neck.bottom_up_blocks.1.blocks.1.conv2.depthwise_conv.bn.weight - torch.Size([384]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.bottom_up_blocks.1.blocks.1.conv2.depthwise_conv.bn.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.bottom_up_blocks.1.blocks.1.conv2.pointwise_conv.conv.weight - torch.Size([384, 384, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

neck.bottom_up_blocks.1.blocks.1.conv2.pointwise_conv.bn.weight - torch.Size([384]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.bottom_up_blocks.1.blocks.1.conv2.pointwise_conv.bn.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.out_convs.0.conv.weight - torch.Size([192, 192, 3, 3]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

neck.out_convs.0.bn.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.out_convs.0.bn.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.out_convs.1.conv.weight - torch.Size([192, 384, 3, 3]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

neck.out_convs.1.bn.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.out_convs.1.bn.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.out_convs.2.conv.weight - torch.Size([192, 768, 3, 3]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

neck.out_convs.2.bn.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.out_convs.2.bn.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

bbox_head.cls_convs.0.0.conv.weight - torch.Size([192, 192, 3, 3]): 
Initialized by user-defined `init_weights` in RTMDetSepBNHead  

bbox_head.cls_convs.0.0.bn.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

bbox_head.cls_convs.0.0.bn.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

bbox_head.cls_convs.0.1.conv.weight - torch.Size([192, 192, 3, 3]): 
Initialized by user-defined `init_weights` in RTMDetSepBNHead  

bbox_head.cls_convs.0.1.bn.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

bbox_head.cls_convs.0.1.bn.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

bbox_head.cls_convs.1.0.bn.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

bbox_head.cls_convs.1.0.bn.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

bbox_head.cls_convs.1.1.bn.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

bbox_head.cls_convs.1.1.bn.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

bbox_head.cls_convs.2.0.bn.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

bbox_head.cls_convs.2.0.bn.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

bbox_head.cls_convs.2.1.bn.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

bbox_head.cls_convs.2.1.bn.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

bbox_head.reg_convs.0.0.conv.weight - torch.Size([192, 192, 3, 3]): 
Initialized by user-defined `init_weights` in RTMDetSepBNHead  

bbox_head.reg_convs.0.0.bn.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

bbox_head.reg_convs.0.0.bn.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

bbox_head.reg_convs.0.1.conv.weight - torch.Size([192, 192, 3, 3]): 
Initialized by user-defined `init_weights` in RTMDetSepBNHead  

bbox_head.reg_convs.0.1.bn.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

bbox_head.reg_convs.0.1.bn.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

bbox_head.reg_convs.1.0.bn.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

bbox_head.reg_convs.1.0.bn.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

bbox_head.reg_convs.1.1.bn.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

bbox_head.reg_convs.1.1.bn.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

bbox_head.reg_convs.2.0.bn.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

bbox_head.reg_convs.2.0.bn.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

bbox_head.reg_convs.2.1.bn.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

bbox_head.reg_convs.2.1.bn.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

bbox_head.rtm_cls.0.weight - torch.Size([1, 192, 1, 1]): 
Initialized by user-defined `init_weights` in RTMDetSepBNHead  

bbox_head.rtm_cls.0.bias - torch.Size([1]): 
Initialized by user-defined `init_weights` in RTMDetSepBNHead  

bbox_head.rtm_cls.1.weight - torch.Size([1, 192, 1, 1]): 
Initialized by user-defined `init_weights` in RTMDetSepBNHead  

bbox_head.rtm_cls.1.bias - torch.Size([1]): 
Initialized by user-defined `init_weights` in RTMDetSepBNHead  

bbox_head.rtm_cls.2.weight - torch.Size([1, 192, 1, 1]): 
Initialized by user-defined `init_weights` in RTMDetSepBNHead  

bbox_head.rtm_cls.2.bias - torch.Size([1]): 
Initialized by user-defined `init_weights` in RTMDetSepBNHead  

bbox_head.rtm_reg.0.weight - torch.Size([4, 192, 1, 1]): 
Initialized by user-defined `init_weights` in RTMDetSepBNHead  

bbox_head.rtm_reg.0.bias - torch.Size([4]): 
Initialized by user-defined `init_weights` in RTMDetSepBNHead  

bbox_head.rtm_reg.1.weight - torch.Size([4, 192, 1, 1]): 
Initialized by user-defined `init_weights` in RTMDetSepBNHead  

bbox_head.rtm_reg.1.bias - torch.Size([4]): 
Initialized by user-defined `init_weights` in RTMDetSepBNHead  

bbox_head.rtm_reg.2.weight - torch.Size([4, 192, 1, 1]): 
Initialized by user-defined `init_weights` in RTMDetSepBNHead  

bbox_head.rtm_reg.2.bias - torch.Size([4]): 
Initialized by user-defined `init_weights` in RTMDetSepBNHead  
2025/05/13 01:48:18 - mmengine - INFO - Load checkpoint from /home/jaa/Work/Prog/BSU/Detectors/work_dirs/RTMDet/RTMDet_m_30e_new3_custom/epoch_5.pth
2025/05/13 01:48:18 - mmengine - INFO - resumed epoch: 5, iter: 6550
2025/05/13 01:48:18 - mmengine - INFO - Backbone frozen before training.
2025/05/13 01:48:18 - mmengine - WARNING - "FileClient" will be deprecated in future. Please use io functions in https://mmengine.readthedocs.io/en/latest/api/fileio.html#file-io
2025/05/13 01:48:18 - mmengine - WARNING - "HardDiskBackend" is the alias of "LocalBackend" and the former will be deprecated in future.
2025/05/13 01:48:18 - mmengine - INFO - Checkpoints will be saved to /home/jaa/Work/Prog/BSU/Detectors/work_dirs/RTMDet/RTMDet_m_30e_new1_custom.
2025/05/13 01:48:18 - mmengine - INFO - Backbone was unfrozen at epoch 5
2025/05/13 01:48:34 - mmengine - INFO - Epoch(train)  [6][  50/1528]  base_lr: 1.2500e-03 lr: 1.2500e-03  eta: 3:34:06  time: 0.3274  data_time: 0.0058  memory: 19489  loss: 0.6503  loss_cls: 0.3492  loss_bbox: 0.3012
2025/05/13 01:48:50 - mmengine - INFO - Epoch(train)  [6][ 100/1528]  base_lr: 1.2500e-03 lr: 1.2500e-03  eta: 3:26:50  time: 0.3060  data_time: 0.0006  memory: 19500  loss: 0.5988  loss_cls: 0.3109  loss_bbox: 0.2879
2025/05/13 01:49:05 - mmengine - INFO - Epoch(train)  [6][ 150/1528]  base_lr: 1.2500e-03 lr: 1.2500e-03  eta: 3:23:14  time: 0.3013  data_time: 0.0005  memory: 19485  loss: 0.6339  loss_cls: 0.3456  loss_bbox: 0.2882
2025/05/13 01:49:20 - mmengine - INFO - Epoch(train)  [6][ 200/1528]  base_lr: 1.2500e-03 lr: 1.2500e-03  eta: 3:22:02  time: 0.3058  data_time: 0.0005  memory: 19485  loss: 0.5775  loss_cls: 0.2992  loss_bbox: 0.2783
2025/05/13 01:49:35 - mmengine - INFO - Epoch(train)  [6][ 250/1528]  base_lr: 1.2500e-03 lr: 1.2500e-03  eta: 3:21:16  time: 0.3062  data_time: 0.0005  memory: 19517  loss: 0.5737  loss_cls: 0.2943  loss_bbox: 0.2794
2025/05/13 01:49:51 - mmengine - INFO - Epoch(train)  [6][ 300/1528]  base_lr: 1.2500e-03 lr: 1.2500e-03  eta: 3:20:38  time: 0.3060  data_time: 0.0006  memory: 19482  loss: 0.5415  loss_cls: 0.2838  loss_bbox: 0.2577
2025/05/13 01:50:06 - mmengine - INFO - Epoch(train)  [6][ 350/1528]  base_lr: 1.2500e-03 lr: 1.2500e-03  eta: 3:19:43  time: 0.3015  data_time: 0.0006  memory: 19502  loss: 0.5567  loss_cls: 0.2772  loss_bbox: 0.2795
2025/05/13 01:50:21 - mmengine - INFO - Epoch(train)  [6][ 400/1528]  base_lr: 1.2500e-03 lr: 1.2500e-03  eta: 3:19:22  time: 0.3067  data_time: 0.0005  memory: 19482  loss: 0.6046  loss_cls: 0.3079  loss_bbox: 0.2967
2025/05/13 01:50:36 - mmengine - INFO - Exp name: rtmdet_m_1x_custom_resume_20250513_014813
2025/05/13 01:50:36 - mmengine - INFO - Epoch(train)  [6][ 450/1528]  base_lr: 1.2500e-03 lr: 1.2500e-03  eta: 3:18:39  time: 0.3012  data_time: 0.0006  memory: 19485  loss: 0.5794  loss_cls: 0.3012  loss_bbox: 0.2783
2025/05/13 01:50:51 - mmengine - INFO - Epoch(train)  [6][ 500/1528]  base_lr: 1.2500e-03 lr: 1.2500e-03  eta: 3:18:22  time: 0.3065  data_time: 0.0005  memory: 19507  loss: 0.5381  loss_cls: 0.2636  loss_bbox: 0.2745
2025/05/13 01:51:07 - mmengine - INFO - Epoch(train)  [6][ 550/1528]  base_lr: 1.2500e-03 lr: 1.2500e-03  eta: 3:17:51  time: 0.3023  data_time: 0.0005  memory: 19500  loss: 0.5458  loss_cls: 0.2685  loss_bbox: 0.2774
2025/05/13 01:51:22 - mmengine - INFO - Epoch(train)  [6][ 600/1528]  base_lr: 1.2500e-03 lr: 1.2500e-03  eta: 3:17:35  time: 0.3062  data_time: 0.0005  memory: 19510  loss: 0.5792  loss_cls: 0.2957  loss_bbox: 0.2834
2025/05/13 01:51:37 - mmengine - INFO - Epoch(train)  [6][ 650/1528]  base_lr: 1.2500e-03 lr: 1.2500e-03  eta: 3:17:05  time: 0.3015  data_time: 0.0005  memory: 19507  loss: 0.5909  loss_cls: 0.3100  loss_bbox: 0.2809
2025/05/13 01:51:52 - mmengine - INFO - Epoch(train)  [6][ 700/1528]  base_lr: 1.2500e-03 lr: 1.2500e-03  eta: 3:16:54  time: 0.3076  data_time: 0.0006  memory: 19506  loss: 0.5345  loss_cls: 0.2719  loss_bbox: 0.2627
2025/05/13 01:52:07 - mmengine - INFO - Epoch(train)  [6][ 750/1528]  base_lr: 1.2500e-03 lr: 1.2500e-03  eta: 3:16:29  time: 0.3024  data_time: 0.0005  memory: 19484  loss: 0.5130  loss_cls: 0.2532  loss_bbox: 0.2597
2025/05/13 01:52:23 - mmengine - INFO - Epoch(train)  [6][ 800/1528]  base_lr: 1.2500e-03 lr: 1.2500e-03  eta: 3:16:17  time: 0.3071  data_time: 0.0005  memory: 19483  loss: 0.5338  loss_cls: 0.2626  loss_bbox: 0.2713
2025/05/13 01:52:38 - mmengine - INFO - Epoch(train)  [6][ 850/1528]  base_lr: 1.2500e-03 lr: 1.2500e-03  eta: 3:15:53  time: 0.3023  data_time: 0.0005  memory: 19500  loss: 0.4975  loss_cls: 0.2349  loss_bbox: 0.2627
2025/05/13 01:52:53 - mmengine - INFO - Epoch(train)  [6][ 900/1528]  base_lr: 1.2500e-03 lr: 1.2500e-03  eta: 3:15:39  time: 0.3065  data_time: 0.0005  memory: 19507  loss: 0.5142  loss_cls: 0.2507  loss_bbox: 0.2635
2025/05/13 01:53:08 - mmengine - INFO - Epoch(train)  [6][ 950/1528]  base_lr: 1.2500e-03 lr: 1.2500e-03  eta: 3:15:17  time: 0.3025  data_time: 0.0005  memory: 19478  loss: 0.5046  loss_cls: 0.2454  loss_bbox: 0.2592
2025/05/13 01:53:24 - mmengine - INFO - Epoch(train)  [6][1000/1528]  base_lr: 1.2500e-03 lr: 1.2500e-03  eta: 3:14:58  time: 0.3033  data_time: 0.0005  memory: 19504  loss: 0.5044  loss_cls: 0.2429  loss_bbox: 0.2615
2025/05/13 01:53:39 - mmengine - INFO - Epoch(train)  [6][1050/1528]  base_lr: 1.2500e-03 lr: 1.2500e-03  eta: 3:14:47  time: 0.3078  data_time: 0.0005  memory: 19503  loss: 0.5028  loss_cls: 0.2404  loss_bbox: 0.2624
2025/05/13 01:53:54 - mmengine - INFO - Epoch(train)  [6][1100/1528]  base_lr: 1.2500e-03 lr: 1.2500e-03  eta: 3:14:20  time: 0.2989  data_time: 0.0005  memory: 19481  loss: 0.5104  loss_cls: 0.2571  loss_bbox: 0.2532
2025/05/13 01:54:09 - mmengine - INFO - Epoch(train)  [6][1150/1528]  base_lr: 1.2500e-03 lr: 1.2500e-03  eta: 3:13:55  time: 0.2999  data_time: 0.0006  memory: 19498  loss: 0.5098  loss_cls: 0.2432  loss_bbox: 0.2666
2025/05/13 01:54:24 - mmengine - INFO - Epoch(train)  [6][1200/1528]  base_lr: 1.2500e-03 lr: 1.2500e-03  eta: 3:13:30  time: 0.2987  data_time: 0.0006  memory: 19511  loss: 0.5239  loss_cls: 0.2515  loss_bbox: 0.2724
2025/05/13 01:54:39 - mmengine - INFO - Epoch(train)  [6][1250/1528]  base_lr: 1.2500e-03 lr: 1.2500e-03  eta: 3:13:07  time: 0.2999  data_time: 0.0005  memory: 19515  loss: 0.4936  loss_cls: 0.2345  loss_bbox: 0.2591
2025/05/13 01:54:54 - mmengine - INFO - Epoch(train)  [6][1300/1528]  base_lr: 1.2500e-03 lr: 1.2500e-03  eta: 3:12:44  time: 0.2990  data_time: 0.0005  memory: 19502  loss: 0.4680  loss_cls: 0.2242  loss_bbox: 0.2438
2025/05/13 01:55:09 - mmengine - INFO - Epoch(train)  [6][1350/1528]  base_lr: 1.2500e-03 lr: 1.2500e-03  eta: 3:12:22  time: 0.2998  data_time: 0.0006  memory: 19486  loss: 0.5052  loss_cls: 0.2470  loss_bbox: 0.2582
2025/05/13 01:55:24 - mmengine - INFO - Epoch(train)  [6][1400/1528]  base_lr: 1.2500e-03 lr: 1.2500e-03  eta: 3:11:59  time: 0.2987  data_time: 0.0006  memory: 19496  loss: 0.4703  loss_cls: 0.2263  loss_bbox: 0.2440
2025/05/13 01:55:39 - mmengine - INFO - Exp name: rtmdet_m_1x_custom_resume_20250513_014813
2025/05/13 01:55:39 - mmengine - INFO - Epoch(train)  [6][1450/1528]  base_lr: 1.2500e-03 lr: 1.2500e-03  eta: 3:11:39  time: 0.3004  data_time: 0.0005  memory: 19487  loss: 0.4863  loss_cls: 0.2314  loss_bbox: 0.2549
2025/05/13 01:55:54 - mmengine - INFO - Epoch(train)  [6][1500/1528]  base_lr: 1.2500e-03 lr: 1.2500e-03  eta: 3:11:17  time: 0.2982  data_time: 0.0005  memory: 19483  loss: 0.4911  loss_cls: 0.2411  loss_bbox: 0.2500
2025/05/13 01:56:02 - mmengine - INFO - Exp name: rtmdet_m_1x_custom_resume_20250513_014813
2025/05/13 01:56:02 - mmengine - INFO - Saving checkpoint at 6 epochs
2025/05/13 01:56:07 - mmengine - INFO - Epoch(val)  [6][ 50/149]    eta: 0:00:08  time: 0.0861  data_time: 0.0053  memory: 19490  
2025/05/13 01:56:11 - mmengine - INFO - Epoch(val)  [6][100/149]    eta: 0:00:04  time: 0.0829  data_time: 0.0026  memory: 1598  
2025/05/13 01:56:16 - mmengine - INFO - Evaluating bbox...
2025/05/13 01:56:19 - mmengine - INFO - bbox_mAP_copypaste: 0.732 0.930 0.831 0.426 0.631 0.774
2025/05/13 01:56:19 - mmengine - INFO - Epoch(val) [6][149/149]    coco/bbox_mAP: 0.7320  coco/bbox_mAP_50: 0.9300  coco/bbox_mAP_75: 0.8310  coco/bbox_mAP_s: 0.4260  coco/bbox_mAP_m: 0.6310  coco/bbox_mAP_l: 0.7740  data_time: 0.0036  time: 0.0833
2025/05/13 01:56:34 - mmengine - INFO - Epoch(train)  [7][  50/1528]  base_lr: 8.6373e-04 lr: 8.6373e-04  eta: 3:10:45  time: 0.3017  data_time: 0.0030  memory: 19513  loss: 0.4826  loss_cls: 0.2262  loss_bbox: 0.2564
2025/05/13 01:56:49 - mmengine - INFO - Epoch(train)  [7][ 100/1528]  base_lr: 8.6373e-04 lr: 8.6373e-04  eta: 3:10:24  time: 0.2992  data_time: 0.0005  memory: 19511  loss: 0.4594  loss_cls: 0.2178  loss_bbox: 0.2416
2025/05/13 01:57:04 - mmengine - INFO - Epoch(train)  [7][ 150/1528]  base_lr: 8.6373e-04 lr: 8.6373e-04  eta: 3:10:04  time: 0.2987  data_time: 0.0005  memory: 19492  loss: 0.4305  loss_cls: 0.2014  loss_bbox: 0.2291
2025/05/13 01:57:19 - mmengine - INFO - Epoch(train)  [7][ 200/1528]  base_lr: 8.6373e-04 lr: 8.6373e-04  eta: 3:09:44  time: 0.2990  data_time: 0.0005  memory: 19494  loss: 0.4581  loss_cls: 0.2105  loss_bbox: 0.2476
2025/05/13 01:57:34 - mmengine - INFO - Epoch(train)  [7][ 250/1528]  base_lr: 8.6373e-04 lr: 8.6373e-04  eta: 3:09:29  time: 0.3032  data_time: 0.0005  memory: 19521  loss: 0.4715  loss_cls: 0.2184  loss_bbox: 0.2531
2025/05/13 01:57:49 - mmengine - INFO - Epoch(train)  [7][ 300/1528]  base_lr: 8.6373e-04 lr: 8.6373e-04  eta: 3:09:10  time: 0.2988  data_time: 0.0005  memory: 19508  loss: 0.4970  loss_cls: 0.2350  loss_bbox: 0.2620
2025/05/13 01:58:04 - mmengine - INFO - Epoch(train)  [7][ 350/1528]  base_lr: 8.6373e-04 lr: 8.6373e-04  eta: 3:08:51  time: 0.2991  data_time: 0.0005  memory: 19488  loss: 0.4386  loss_cls: 0.1991  loss_bbox: 0.2396
2025/05/13 01:58:19 - mmengine - INFO - Epoch(train)  [7][ 400/1528]  base_lr: 8.6373e-04 lr: 8.6373e-04  eta: 3:08:32  time: 0.2992  data_time: 0.0006  memory: 19474  loss: 0.4510  loss_cls: 0.2192  loss_bbox: 0.2319
2025/05/13 01:58:34 - mmengine - INFO - Epoch(train)  [7][ 450/1528]  base_lr: 8.6373e-04 lr: 8.6373e-04  eta: 3:08:13  time: 0.2987  data_time: 0.0005  memory: 19481  loss: 0.4382  loss_cls: 0.2079  loss_bbox: 0.2303
2025/05/13 01:58:49 - mmengine - INFO - Epoch(train)  [7][ 500/1528]  base_lr: 8.6373e-04 lr: 8.6373e-04  eta: 3:07:55  time: 0.2992  data_time: 0.0005  memory: 19479  loss: 0.4425  loss_cls: 0.2066  loss_bbox: 0.2359
2025/05/13 01:59:04 - mmengine - INFO - Epoch(train)  [7][ 550/1528]  base_lr: 8.6373e-04 lr: 8.6373e-04  eta: 3:07:36  time: 0.2986  data_time: 0.0005  memory: 19485  loss: 0.4589  loss_cls: 0.2159  loss_bbox: 0.2431
2025/05/13 01:59:19 - mmengine - INFO - Epoch(train)  [7][ 600/1528]  base_lr: 8.6373e-04 lr: 8.6373e-04  eta: 3:07:19  time: 0.3003  data_time: 0.0005  memory: 19496  loss: 0.4655  loss_cls: 0.2231  loss_bbox: 0.2424
2025/05/13 01:59:33 - mmengine - INFO - Epoch(train)  [7][ 650/1528]  base_lr: 8.6373e-04 lr: 8.6373e-04  eta: 3:07:00  time: 0.2978  data_time: 0.0005  memory: 19485  loss: 0.4866  loss_cls: 0.2337  loss_bbox: 0.2529
2025/05/13 01:59:48 - mmengine - INFO - Epoch(train)  [7][ 700/1528]  base_lr: 8.6373e-04 lr: 8.6373e-04  eta: 3:06:43  time: 0.2999  data_time: 0.0005  memory: 19488  loss: 0.4419  loss_cls: 0.2115  loss_bbox: 0.2304
2025/05/13 02:00:03 - mmengine - INFO - Epoch(train)  [7][ 750/1528]  base_lr: 8.6373e-04 lr: 8.6373e-04  eta: 3:06:25  time: 0.2987  data_time: 0.0005  memory: 19476  loss: 0.4289  loss_cls: 0.2007  loss_bbox: 0.2283
2025/05/13 02:00:18 - mmengine - INFO - Epoch(train)  [7][ 800/1528]  base_lr: 8.6373e-04 lr: 8.6373e-04  eta: 3:06:08  time: 0.2997  data_time: 0.0005  memory: 19485  loss: 0.4480  loss_cls: 0.2108  loss_bbox: 0.2371
2025/05/13 02:00:33 - mmengine - INFO - Epoch(train)  [7][ 850/1528]  base_lr: 8.6373e-04 lr: 8.6373e-04  eta: 3:05:50  time: 0.2986  data_time: 0.0005  memory: 19479  loss: 0.4501  loss_cls: 0.2095  loss_bbox: 0.2406
2025/05/13 02:00:48 - mmengine - INFO - Epoch(train)  [7][ 900/1528]  base_lr: 8.6373e-04 lr: 8.6373e-04  eta: 3:05:33  time: 0.2994  data_time: 0.0005  memory: 19512  loss: 0.4378  loss_cls: 0.1975  loss_bbox: 0.2403
2025/05/13 02:00:55 - mmengine - INFO - Exp name: rtmdet_m_1x_custom_resume_20250513_014813
2025/05/13 02:01:03 - mmengine - INFO - Epoch(train)  [7][ 950/1528]  base_lr: 8.6373e-04 lr: 8.6373e-04  eta: 3:05:15  time: 0.2991  data_time: 0.0005  memory: 19501  loss: 0.4655  loss_cls: 0.2207  loss_bbox: 0.2448
2025/05/13 02:01:18 - mmengine - INFO - Epoch(train)  [7][1000/1528]  base_lr: 8.6373e-04 lr: 8.6373e-04  eta: 3:04:58  time: 0.2993  data_time: 0.0005  memory: 19517  loss: 0.4521  loss_cls: 0.2107  loss_bbox: 0.2414
2025/05/13 02:01:33 - mmengine - INFO - Epoch(train)  [7][1050/1528]  base_lr: 8.6373e-04 lr: 8.6373e-04  eta: 3:04:44  time: 0.3033  data_time: 0.0005  memory: 19484  loss: 0.4488  loss_cls: 0.2069  loss_bbox: 0.2419
2025/05/13 02:01:48 - mmengine - INFO - Epoch(train)  [7][1100/1528]  base_lr: 8.6373e-04 lr: 8.6373e-04  eta: 3:04:27  time: 0.2988  data_time: 0.0005  memory: 19502  loss: 0.4468  loss_cls: 0.2092  loss_bbox: 0.2376
2025/05/13 02:02:03 - mmengine - INFO - Epoch(train)  [7][1150/1528]  base_lr: 8.6373e-04 lr: 8.6373e-04  eta: 3:04:10  time: 0.2990  data_time: 0.0005  memory: 19489  loss: 0.4409  loss_cls: 0.2056  loss_bbox: 0.2353
2025/05/13 02:02:18 - mmengine - INFO - Epoch(train)  [7][1200/1528]  base_lr: 8.6373e-04 lr: 8.6373e-04  eta: 3:03:53  time: 0.2989  data_time: 0.0005  memory: 19488  loss: 0.4389  loss_cls: 0.2043  loss_bbox: 0.2346
2025/05/13 02:02:33 - mmengine - INFO - Epoch(train)  [7][1250/1528]  base_lr: 8.6373e-04 lr: 8.6373e-04  eta: 3:03:36  time: 0.2994  data_time: 0.0005  memory: 19504  loss: 0.4777  loss_cls: 0.2275  loss_bbox: 0.2502
2025/05/13 02:02:48 - mmengine - INFO - Epoch(train)  [7][1300/1528]  base_lr: 8.6373e-04 lr: 8.6373e-04  eta: 3:03:20  time: 0.2997  data_time: 0.0005  memory: 19502  loss: 0.4401  loss_cls: 0.2096  loss_bbox: 0.2305
2025/05/13 02:03:03 - mmengine - INFO - Epoch(train)  [7][1350/1528]  base_lr: 8.6373e-04 lr: 8.6373e-04  eta: 3:03:03  time: 0.2994  data_time: 0.0005  memory: 19509  loss: 0.4518  loss_cls: 0.2170  loss_bbox: 0.2348
2025/05/13 02:03:18 - mmengine - INFO - Epoch(train)  [7][1400/1528]  base_lr: 8.6373e-04 lr: 8.6373e-04  eta: 3:02:47  time: 0.2995  data_time: 0.0005  memory: 19489  loss: 0.4485  loss_cls: 0.2162  loss_bbox: 0.2324
2025/05/13 02:03:33 - mmengine - INFO - Epoch(train)  [7][1450/1528]  base_lr: 8.6373e-04 lr: 8.6373e-04  eta: 3:02:30  time: 0.2990  data_time: 0.0005  memory: 19485  loss: 0.4704  loss_cls: 0.2187  loss_bbox: 0.2517
2025/05/13 02:03:48 - mmengine - INFO - Epoch(train)  [7][1500/1528]  base_lr: 8.6373e-04 lr: 8.6373e-04  eta: 3:02:14  time: 0.2995  data_time: 0.0005  memory: 19504  loss: 0.4550  loss_cls: 0.2158  loss_bbox: 0.2393
2025/05/13 02:03:56 - mmengine - INFO - Exp name: rtmdet_m_1x_custom_resume_20250513_014813
2025/05/13 02:03:56 - mmengine - INFO - Saving checkpoint at 7 epochs
2025/05/13 02:04:01 - mmengine - INFO - Epoch(val)  [7][ 50/149]    eta: 0:00:08  time: 0.0818  data_time: 0.0033  memory: 19475  
2025/05/13 02:04:05 - mmengine - INFO - Epoch(val)  [7][100/149]    eta: 0:00:03  time: 0.0808  data_time: 0.0026  memory: 1598  
2025/05/13 02:04:10 - mmengine - INFO - Evaluating bbox...
2025/05/13 02:04:13 - mmengine - INFO - bbox_mAP_copypaste: 0.762 0.941 0.859 0.445 0.653 0.805
2025/05/13 02:04:13 - mmengine - INFO - Epoch(val) [7][149/149]    coco/bbox_mAP: 0.7620  coco/bbox_mAP_50: 0.9410  coco/bbox_mAP_75: 0.8590  coco/bbox_mAP_s: 0.4450  coco/bbox_mAP_m: 0.6530  coco/bbox_mAP_l: 0.8050  data_time: 0.0028  time: 0.0806
2025/05/13 02:04:28 - mmengine - INFO - Epoch(train)  [8][  50/1528]  base_lr: 5.1527e-05 lr: 5.1527e-05  eta: 3:01:49  time: 0.3024  data_time: 0.0034  memory: 19491  loss: 0.4550  loss_cls: 0.2119  loss_bbox: 0.2430
2025/05/13 02:04:43 - mmengine - INFO - Epoch(train)  [8][ 100/1528]  base_lr: 5.1527e-05 lr: 5.1527e-05  eta: 3:01:32  time: 0.2994  data_time: 0.0006  memory: 19502  loss: 0.4338  loss_cls: 0.2081  loss_bbox: 0.2257
2025/05/13 02:04:58 - mmengine - INFO - Epoch(train)  [8][ 150/1528]  base_lr: 5.1527e-05 lr: 5.1527e-05  eta: 3:01:16  time: 0.2989  data_time: 0.0005  memory: 19509  loss: 0.4122  loss_cls: 0.1898  loss_bbox: 0.2224
2025/05/13 02:05:13 - mmengine - INFO - Epoch(train)  [8][ 200/1528]  base_lr: 5.1527e-05 lr: 5.1527e-05  eta: 3:00:59  time: 0.2986  data_time: 0.0005  memory: 19493  loss: 0.4432  loss_cls: 0.2066  loss_bbox: 0.2366
2025/05/13 02:05:28 - mmengine - INFO - Epoch(train)  [8][ 250/1528]  base_lr: 5.1527e-05 lr: 5.1527e-05  eta: 3:00:45  time: 0.3035  data_time: 0.0005  memory: 19490  loss: 0.4319  loss_cls: 0.2023  loss_bbox: 0.2296
2025/05/13 02:05:43 - mmengine - INFO - Epoch(train)  [8][ 300/1528]  base_lr: 5.1527e-05 lr: 5.1527e-05  eta: 3:00:29  time: 0.2988  data_time: 0.0005  memory: 19500  loss: 0.4298  loss_cls: 0.2098  loss_bbox: 0.2200
2025/05/13 02:05:58 - mmengine - INFO - Epoch(train)  [8][ 350/1528]  base_lr: 5.1527e-05 lr: 5.1527e-05  eta: 3:00:13  time: 0.2991  data_time: 0.0005  memory: 19521  loss: 0.4384  loss_cls: 0.2138  loss_bbox: 0.2246
2025/05/13 02:06:11 - mmengine - INFO - Exp name: rtmdet_m_1x_custom_resume_20250513_014813
2025/05/13 02:06:13 - mmengine - INFO - Epoch(train)  [8][ 400/1528]  base_lr: 5.1527e-05 lr: 5.1527e-05  eta: 2:59:57  time: 0.2997  data_time: 0.0006  memory: 19492  loss: 0.4496  loss_cls: 0.2179  loss_bbox: 0.2316
2025/05/13 02:06:28 - mmengine - INFO - Epoch(train)  [8][ 450/1528]  base_lr: 5.1527e-05 lr: 5.1527e-05  eta: 2:59:41  time: 0.2993  data_time: 0.0005  memory: 19484  loss: 0.4242  loss_cls: 0.1970  loss_bbox: 0.2273
2025/05/13 02:06:43 - mmengine - INFO - Epoch(train)  [8][ 500/1528]  base_lr: 5.1527e-05 lr: 5.1527e-05  eta: 2:59:25  time: 0.2998  data_time: 0.0006  memory: 19484  loss: 0.4121  loss_cls: 0.1958  loss_bbox: 0.2163
2025/05/13 02:06:58 - mmengine - INFO - Epoch(train)  [8][ 550/1528]  base_lr: 5.1527e-05 lr: 5.1527e-05  eta: 2:59:09  time: 0.2992  data_time: 0.0006  memory: 19488  loss: 0.4254  loss_cls: 0.1918  loss_bbox: 0.2336
2025/05/13 02:07:13 - mmengine - INFO - Epoch(train)  [8][ 600/1528]  base_lr: 5.1527e-05 lr: 5.1527e-05  eta: 2:58:53  time: 0.2994  data_time: 0.0006  memory: 19491  loss: 0.4105  loss_cls: 0.1913  loss_bbox: 0.2193
2025/05/13 02:07:28 - mmengine - INFO - Epoch(train)  [8][ 650/1528]  base_lr: 5.1527e-05 lr: 5.1527e-05  eta: 2:58:37  time: 0.2989  data_time: 0.0005  memory: 19479  loss: 0.4456  loss_cls: 0.2103  loss_bbox: 0.2354
2025/05/13 02:07:43 - mmengine - INFO - Epoch(train)  [8][ 700/1528]  base_lr: 5.1527e-05 lr: 5.1527e-05  eta: 2:58:20  time: 0.2983  data_time: 0.0005  memory: 19490  loss: 0.4172  loss_cls: 0.1946  loss_bbox: 0.2226
2025/05/13 02:07:57 - mmengine - INFO - Epoch(train)  [8][ 750/1528]  base_lr: 5.1527e-05 lr: 5.1527e-05  eta: 2:58:04  time: 0.2988  data_time: 0.0005  memory: 19509  loss: 0.4376  loss_cls: 0.2045  loss_bbox: 0.2331
2025/05/13 02:08:12 - mmengine - INFO - Epoch(train)  [8][ 800/1528]  base_lr: 5.1527e-05 lr: 5.1527e-05  eta: 2:57:48  time: 0.2991  data_time: 0.0005  memory: 19496  loss: 0.4193  loss_cls: 0.1900  loss_bbox: 0.2293
2025/05/13 02:08:27 - mmengine - INFO - Epoch(train)  [8][ 850/1528]  base_lr: 5.1527e-05 lr: 5.1527e-05  eta: 2:57:32  time: 0.2991  data_time: 0.0005  memory: 19490  loss: 0.4083  loss_cls: 0.1846  loss_bbox: 0.2237
2025/05/13 02:08:42 - mmengine - INFO - Epoch(train)  [8][ 900/1528]  base_lr: 5.1527e-05 lr: 5.1527e-05  eta: 2:57:16  time: 0.2994  data_time: 0.0005  memory: 19508  loss: 0.4160  loss_cls: 0.1983  loss_bbox: 0.2177
2025/05/13 02:08:57 - mmengine - INFO - Epoch(train)  [8][ 950/1528]  base_lr: 5.1527e-05 lr: 5.1527e-05  eta: 2:57:00  time: 0.2990  data_time: 0.0006  memory: 19481  loss: 0.4135  loss_cls: 0.1906  loss_bbox: 0.2229
2025/05/13 02:09:12 - mmengine - INFO - Epoch(train)  [8][1000/1528]  base_lr: 5.1527e-05 lr: 5.1527e-05  eta: 2:56:44  time: 0.2992  data_time: 0.0005  memory: 19504  loss: 0.4382  loss_cls: 0.2133  loss_bbox: 0.2249
2025/05/13 02:09:27 - mmengine - INFO - Epoch(train)  [8][1050/1528]  base_lr: 5.1527e-05 lr: 5.1527e-05  eta: 2:56:30  time: 0.3032  data_time: 0.0006  memory: 19479  loss: 0.4210  loss_cls: 0.1951  loss_bbox: 0.2259
2025/05/13 02:09:42 - mmengine - INFO - Epoch(train)  [8][1100/1528]  base_lr: 5.1527e-05 lr: 5.1527e-05  eta: 2:56:15  time: 0.3000  data_time: 0.0006  memory: 19485  loss: 0.4159  loss_cls: 0.1955  loss_bbox: 0.2205
2025/05/13 02:09:57 - mmengine - INFO - Epoch(train)  [8][1150/1528]  base_lr: 5.1527e-05 lr: 5.1527e-05  eta: 2:55:59  time: 0.2990  data_time: 0.0005  memory: 19506  loss: 0.4336  loss_cls: 0.2050  loss_bbox: 0.2286
2025/05/13 02:10:12 - mmengine - INFO - Epoch(train)  [8][1200/1528]  base_lr: 5.1527e-05 lr: 5.1527e-05  eta: 2:55:44  time: 0.3000  data_time: 0.0005  memory: 19499  loss: 0.4199  loss_cls: 0.1941  loss_bbox: 0.2258
2025/05/13 02:10:27 - mmengine - INFO - Epoch(train)  [8][1250/1528]  base_lr: 5.1527e-05 lr: 5.1527e-05  eta: 2:55:28  time: 0.2988  data_time: 0.0005  memory: 19487  loss: 0.4478  loss_cls: 0.2169  loss_bbox: 0.2309
2025/05/13 02:10:42 - mmengine - INFO - Epoch(train)  [8][1300/1528]  base_lr: 5.1527e-05 lr: 5.1527e-05  eta: 2:55:12  time: 0.2998  data_time: 0.0005  memory: 19510  loss: 0.4150  loss_cls: 0.1908  loss_bbox: 0.2242
2025/05/13 02:10:57 - mmengine - INFO - Epoch(train)  [8][1350/1528]  base_lr: 5.1527e-05 lr: 5.1527e-05  eta: 2:54:57  time: 0.3000  data_time: 0.0005  memory: 19509  loss: 0.4089  loss_cls: 0.1879  loss_bbox: 0.2210
2025/05/13 02:11:11 - mmengine - INFO - Exp name: rtmdet_m_1x_custom_resume_20250513_014813
2025/05/13 02:11:12 - mmengine - INFO - Epoch(train)  [8][1400/1528]  base_lr: 5.1527e-05 lr: 5.1527e-05  eta: 2:54:41  time: 0.3000  data_time: 0.0005  memory: 19513  loss: 0.4479  loss_cls: 0.2114  loss_bbox: 0.2365
2025/05/13 02:11:27 - mmengine - INFO - Epoch(train)  [8][1450/1528]  base_lr: 5.1527e-05 lr: 5.1527e-05  eta: 2:54:26  time: 0.2995  data_time: 0.0005  memory: 19507  loss: 0.3997  loss_cls: 0.1852  loss_bbox: 0.2145
2025/05/13 02:11:42 - mmengine - INFO - Epoch(train)  [8][1500/1528]  base_lr: 5.1527e-05 lr: 5.1527e-05  eta: 2:54:10  time: 0.2997  data_time: 0.0006  memory: 19508  loss: 0.4134  loss_cls: 0.1909  loss_bbox: 0.2225
2025/05/13 02:11:51 - mmengine - INFO - Exp name: rtmdet_m_1x_custom_resume_20250513_014813
2025/05/13 02:11:51 - mmengine - INFO - Saving checkpoint at 8 epochs
2025/05/13 02:11:55 - mmengine - INFO - Epoch(val)  [8][ 50/149]    eta: 0:00:08  time: 0.0820  data_time: 0.0033  memory: 19483  
2025/05/13 02:11:59 - mmengine - INFO - Epoch(val)  [8][100/149]    eta: 0:00:03  time: 0.0805  data_time: 0.0026  memory: 1598  
2025/05/13 02:12:04 - mmengine - INFO - Evaluating bbox...
2025/05/13 02:12:07 - mmengine - INFO - bbox_mAP_copypaste: 0.769 0.942 0.858 0.459 0.655 0.812
2025/05/13 02:12:07 - mmengine - INFO - Epoch(val) [8][149/149]    coco/bbox_mAP: 0.7690  coco/bbox_mAP_50: 0.9420  coco/bbox_mAP_75: 0.8580  coco/bbox_mAP_s: 0.4590  coco/bbox_mAP_m: 0.6550  coco/bbox_mAP_l: 0.8120  data_time: 0.0028  time: 0.0805
2025/05/13 02:12:22 - mmengine - INFO - Epoch(train)  [9][  50/1528]  base_lr: 2.3873e-05 lr: 2.3873e-05  eta: 2:53:47  time: 0.3067  data_time: 0.0022  memory: 19507  loss: 0.4456  loss_cls: 0.2111  loss_bbox: 0.2346
2025/05/13 02:12:37 - mmengine - INFO - Epoch(train)  [9][ 100/1528]  base_lr: 2.3873e-05 lr: 2.3873e-05  eta: 2:53:31  time: 0.2981  data_time: 0.0005  memory: 19485  loss: 0.4384  loss_cls: 0.2069  loss_bbox: 0.2315
2025/05/13 02:12:52 - mmengine - INFO - Epoch(train)  [9][ 150/1528]  base_lr: 2.3873e-05 lr: 2.3873e-05  eta: 2:53:16  time: 0.2999  data_time: 0.0005  memory: 19511  loss: 0.4068  loss_cls: 0.1856  loss_bbox: 0.2212
2025/05/13 02:13:07 - mmengine - INFO - Epoch(train)  [9][ 200/1528]  base_lr: 2.3873e-05 lr: 2.3873e-05  eta: 2:53:00  time: 0.2973  data_time: 0.0005  memory: 19486  loss: 0.4440  loss_cls: 0.2070  loss_bbox: 0.2370
2025/05/13 02:13:22 - mmengine - INFO - Epoch(train)  [9][ 250/1528]  base_lr: 2.3873e-05 lr: 2.3873e-05  eta: 2:52:44  time: 0.3003  data_time: 0.0005  memory: 19491  loss: 0.4273  loss_cls: 0.1989  loss_bbox: 0.2284
2025/05/13 02:13:37 - mmengine - INFO - Epoch(train)  [9][ 300/1528]  base_lr: 2.3873e-05 lr: 2.3873e-05  eta: 2:52:28  time: 0.2979  data_time: 0.0005  memory: 19505  loss: 0.3895  loss_cls: 0.1821  loss_bbox: 0.2074
2025/05/13 02:13:52 - mmengine - INFO - Epoch(train)  [9][ 350/1528]  base_lr: 2.3873e-05 lr: 2.3873e-05  eta: 2:52:14  time: 0.3015  data_time: 0.0007  memory: 19489  loss: 0.4218  loss_cls: 0.1976  loss_bbox: 0.2242
2025/05/13 02:14:07 - mmengine - INFO - Epoch(train)  [9][ 400/1528]  base_lr: 2.3873e-05 lr: 2.3873e-05  eta: 2:51:58  time: 0.2987  data_time: 0.0007  memory: 19500  loss: 0.4394  loss_cls: 0.2075  loss_bbox: 0.2319
2025/05/13 02:14:22 - mmengine - INFO - Epoch(train)  [9][ 450/1528]  base_lr: 2.3873e-05 lr: 2.3873e-05  eta: 2:51:43  time: 0.3006  data_time: 0.0006  memory: 19490  loss: 0.4092  loss_cls: 0.1863  loss_bbox: 0.2228
2025/05/13 02:14:37 - mmengine - INFO - Epoch(train)  [9][ 500/1528]  base_lr: 2.3873e-05 lr: 2.3873e-05  eta: 2:51:27  time: 0.2985  data_time: 0.0005  memory: 19507  loss: 0.4516  loss_cls: 0.2096  loss_bbox: 0.2420
2025/05/13 02:14:52 - mmengine - INFO - Epoch(train)  [9][ 550/1528]  base_lr: 2.3873e-05 lr: 2.3873e-05  eta: 2:51:12  time: 0.2998  data_time: 0.0005  memory: 19492  loss: 0.4014  loss_cls: 0.1846  loss_bbox: 0.2168
2025/05/13 02:15:07 - mmengine - INFO - Epoch(train)  [9][ 600/1528]  base_lr: 2.3873e-05 lr: 2.3873e-05  eta: 2:50:56  time: 0.2985  data_time: 0.0005  memory: 19504  loss: 0.4065  loss_cls: 0.1855  loss_bbox: 0.2211
2025/05/13 02:15:22 - mmengine - INFO - Epoch(train)  [9][ 650/1528]  base_lr: 2.3873e-05 lr: 2.3873e-05  eta: 2:50:40  time: 0.2995  data_time: 0.0006  memory: 19500  loss: 0.4098  loss_cls: 0.1875  loss_bbox: 0.2223
2025/05/13 02:15:37 - mmengine - INFO - Epoch(train)  [9][ 700/1528]  base_lr: 2.3873e-05 lr: 2.3873e-05  eta: 2:50:25  time: 0.2987  data_time: 0.0005  memory: 19500  loss: 0.4154  loss_cls: 0.1919  loss_bbox: 0.2235
2025/05/13 02:15:52 - mmengine - INFO - Epoch(train)  [9][ 750/1528]  base_lr: 2.3873e-05 lr: 2.3873e-05  eta: 2:50:09  time: 0.3000  data_time: 0.0006  memory: 19488  loss: 0.4095  loss_cls: 0.1863  loss_bbox: 0.2231
2025/05/13 02:16:07 - mmengine - INFO - Epoch(train)  [9][ 800/1528]  base_lr: 2.3873e-05 lr: 2.3873e-05  eta: 2:49:54  time: 0.2992  data_time: 0.0005  memory: 19504  loss: 0.4206  loss_cls: 0.2026  loss_bbox: 0.2180
2025/05/13 02:16:22 - mmengine - INFO - Epoch(train)  [9][ 850/1528]  base_lr: 2.3873e-05 lr: 2.3873e-05  eta: 2:49:40  time: 0.3036  data_time: 0.0006  memory: 19486  loss: 0.4304  loss_cls: 0.2063  loss_bbox: 0.2242
2025/05/13 02:16:27 - mmengine - INFO - Exp name: rtmdet_m_1x_custom_resume_20250513_014813
2025/05/13 02:16:37 - mmengine - INFO - Epoch(train)  [9][ 900/1528]  base_lr: 2.3873e-05 lr: 2.3873e-05  eta: 2:49:25  time: 0.3005  data_time: 0.0005  memory: 19519  loss: 0.4084  loss_cls: 0.1921  loss_bbox: 0.2163
2025/05/13 02:16:52 - mmengine - INFO - Epoch(train)  [9][ 950/1528]  base_lr: 2.3873e-05 lr: 2.3873e-05  eta: 2:49:09  time: 0.2982  data_time: 0.0005  memory: 19492  loss: 0.4445  loss_cls: 0.2021  loss_bbox: 0.2424
2025/05/13 02:17:07 - mmengine - INFO - Epoch(train)  [9][1000/1528]  base_lr: 2.3873e-05 lr: 2.3873e-05  eta: 2:48:54  time: 0.3011  data_time: 0.0005  memory: 19481  loss: 0.4349  loss_cls: 0.2020  loss_bbox: 0.2328
2025/05/13 02:17:22 - mmengine - INFO - Epoch(train)  [9][1050/1528]  base_lr: 2.3873e-05 lr: 2.3873e-05  eta: 2:48:38  time: 0.2986  data_time: 0.0005  memory: 19485  loss: 0.4104  loss_cls: 0.1926  loss_bbox: 0.2178
2025/05/13 02:17:37 - mmengine - INFO - Epoch(train)  [9][1100/1528]  base_lr: 2.3873e-05 lr: 2.3873e-05  eta: 2:48:23  time: 0.3002  data_time: 0.0005  memory: 19487  loss: 0.4171  loss_cls: 0.1933  loss_bbox: 0.2238
2025/05/13 02:17:52 - mmengine - INFO - Epoch(train)  [9][1150/1528]  base_lr: 2.3873e-05 lr: 2.3873e-05  eta: 2:48:08  time: 0.2986  data_time: 0.0005  memory: 19483  loss: 0.4284  loss_cls: 0.2010  loss_bbox: 0.2274
2025/05/13 02:18:07 - mmengine - INFO - Epoch(train)  [9][1200/1528]  base_lr: 2.3873e-05 lr: 2.3873e-05  eta: 2:47:53  time: 0.3009  data_time: 0.0006  memory: 19485  loss: 0.4194  loss_cls: 0.1908  loss_bbox: 0.2285
2025/05/13 02:18:22 - mmengine - INFO - Epoch(train)  [9][1250/1528]  base_lr: 2.3873e-05 lr: 2.3873e-05  eta: 2:47:37  time: 0.2991  data_time: 0.0005  memory: 19519  loss: 0.4092  loss_cls: 0.1846  loss_bbox: 0.2247
2025/05/13 02:18:37 - mmengine - INFO - Epoch(train)  [9][1300/1528]  base_lr: 2.3873e-05 lr: 2.3873e-05  eta: 2:47:22  time: 0.2997  data_time: 0.0005  memory: 19504  loss: 0.4032  loss_cls: 0.1834  loss_bbox: 0.2199
2025/05/13 02:18:52 - mmengine - INFO - Epoch(train)  [9][1350/1528]  base_lr: 2.3873e-05 lr: 2.3873e-05  eta: 2:47:06  time: 0.2983  data_time: 0.0005  memory: 19506  loss: 0.4239  loss_cls: 0.1963  loss_bbox: 0.2276
2025/05/13 02:19:06 - mmengine - INFO - Epoch(train)  [9][1400/1528]  base_lr: 2.3873e-05 lr: 2.3873e-05  eta: 2:46:51  time: 0.2986  data_time: 0.0005  memory: 19484  loss: 0.4025  loss_cls: 0.1924  loss_bbox: 0.2101
2025/05/13 02:19:21 - mmengine - INFO - Epoch(train)  [9][1450/1528]  base_lr: 2.3873e-05 lr: 2.3873e-05  eta: 2:46:35  time: 0.2983  data_time: 0.0005  memory: 19483  loss: 0.4216  loss_cls: 0.1959  loss_bbox: 0.2258
2025/05/13 02:19:36 - mmengine - INFO - Epoch(train)  [9][1500/1528]  base_lr: 2.3873e-05 lr: 2.3873e-05  eta: 2:46:19  time: 0.2982  data_time: 0.0005  memory: 19482  loss: 0.4355  loss_cls: 0.2093  loss_bbox: 0.2262
2025/05/13 02:19:45 - mmengine - INFO - Exp name: rtmdet_m_1x_custom_resume_20250513_014813
2025/05/13 02:19:45 - mmengine - INFO - Saving checkpoint at 9 epochs
2025/05/13 02:19:49 - mmengine - INFO - Epoch(val)  [9][ 50/149]    eta: 0:00:08  time: 0.0824  data_time: 0.0037  memory: 19488  
2025/05/13 02:19:53 - mmengine - INFO - Epoch(val)  [9][100/149]    eta: 0:00:04  time: 0.0813  data_time: 0.0029  memory: 1598  
2025/05/13 02:19:59 - mmengine - INFO - Evaluating bbox...
2025/05/13 02:20:01 - mmengine - INFO - bbox_mAP_copypaste: 0.770 0.942 0.860 0.449 0.657 0.813
2025/05/13 02:20:01 - mmengine - INFO - Epoch(val) [9][149/149]    coco/bbox_mAP: 0.7700  coco/bbox_mAP_50: 0.9420  coco/bbox_mAP_75: 0.8600  coco/bbox_mAP_s: 0.4490  coco/bbox_mAP_m: 0.6570  coco/bbox_mAP_l: 0.8130  data_time: 0.0032  time: 0.0814
2025/05/13 02:20:16 - mmengine - INFO - Epoch(train) [10][  50/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:45:55  time: 0.3004  data_time: 0.0024  memory: 19488  loss: 0.4140  loss_cls: 0.1923  loss_bbox: 0.2217
2025/05/13 02:20:31 - mmengine - INFO - Epoch(train) [10][ 100/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:45:39  time: 0.2979  data_time: 0.0005  memory: 19489  loss: 0.4261  loss_cls: 0.2008  loss_bbox: 0.2253
2025/05/13 02:20:46 - mmengine - INFO - Epoch(train) [10][ 150/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:45:23  time: 0.2982  data_time: 0.0005  memory: 19500  loss: 0.4395  loss_cls: 0.2121  loss_bbox: 0.2274
2025/05/13 02:21:01 - mmengine - INFO - Epoch(train) [10][ 200/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:45:08  time: 0.2980  data_time: 0.0005  memory: 19479  loss: 0.4064  loss_cls: 0.1951  loss_bbox: 0.2113
2025/05/13 02:21:16 - mmengine - INFO - Epoch(train) [10][ 250/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:44:52  time: 0.2980  data_time: 0.0005  memory: 19483  loss: 0.4105  loss_cls: 0.1907  loss_bbox: 0.2198
2025/05/13 02:21:31 - mmengine - INFO - Epoch(train) [10][ 300/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:44:36  time: 0.2985  data_time: 0.0005  memory: 19508  loss: 0.4299  loss_cls: 0.2066  loss_bbox: 0.2233
2025/05/13 02:21:42 - mmengine - INFO - Exp name: rtmdet_m_1x_custom_resume_20250513_014813
2025/05/13 02:21:46 - mmengine - INFO - Epoch(train) [10][ 350/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:44:21  time: 0.2992  data_time: 0.0006  memory: 19506  loss: 0.4417  loss_cls: 0.2072  loss_bbox: 0.2345
2025/05/13 02:22:01 - mmengine - INFO - Epoch(train) [10][ 400/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:44:05  time: 0.2980  data_time: 0.0005  memory: 19505  loss: 0.4291  loss_cls: 0.2002  loss_bbox: 0.2289
2025/05/13 02:22:16 - mmengine - INFO - Epoch(train) [10][ 450/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:43:50  time: 0.2974  data_time: 0.0005  memory: 19513  loss: 0.4161  loss_cls: 0.1936  loss_bbox: 0.2225
2025/05/13 02:22:30 - mmengine - INFO - Epoch(train) [10][ 500/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:43:34  time: 0.2984  data_time: 0.0005  memory: 19504  loss: 0.4152  loss_cls: 0.1975  loss_bbox: 0.2177
2025/05/13 02:22:45 - mmengine - INFO - Epoch(train) [10][ 550/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:43:19  time: 0.2980  data_time: 0.0005  memory: 19489  loss: 0.4270  loss_cls: 0.2025  loss_bbox: 0.2245
2025/05/13 02:23:00 - mmengine - INFO - Epoch(train) [10][ 600/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:43:03  time: 0.2983  data_time: 0.0005  memory: 19484  loss: 0.4323  loss_cls: 0.1993  loss_bbox: 0.2330
2025/05/13 02:23:15 - mmengine - INFO - Epoch(train) [10][ 650/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:42:48  time: 0.2985  data_time: 0.0005  memory: 19518  loss: 0.4152  loss_cls: 0.1872  loss_bbox: 0.2280
2025/05/13 02:23:30 - mmengine - INFO - Epoch(train) [10][ 700/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:42:32  time: 0.2986  data_time: 0.0005  memory: 19500  loss: 0.4333  loss_cls: 0.2111  loss_bbox: 0.2222
2025/05/13 02:23:45 - mmengine - INFO - Epoch(train) [10][ 750/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:42:17  time: 0.2984  data_time: 0.0005  memory: 19479  loss: 0.4065  loss_cls: 0.1868  loss_bbox: 0.2196
2025/05/13 02:24:00 - mmengine - INFO - Epoch(train) [10][ 800/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:42:01  time: 0.2985  data_time: 0.0005  memory: 19483  loss: 0.4361  loss_cls: 0.2043  loss_bbox: 0.2318
2025/05/13 02:24:15 - mmengine - INFO - Epoch(train) [10][ 850/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:41:46  time: 0.2981  data_time: 0.0005  memory: 19476  loss: 0.4130  loss_cls: 0.1976  loss_bbox: 0.2154
2025/05/13 02:24:30 - mmengine - INFO - Epoch(train) [10][ 900/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:41:30  time: 0.2987  data_time: 0.0005  memory: 19515  loss: 0.4268  loss_cls: 0.2041  loss_bbox: 0.2228
2025/05/13 02:24:45 - mmengine - INFO - Epoch(train) [10][ 950/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:41:15  time: 0.2982  data_time: 0.0005  memory: 19509  loss: 0.4291  loss_cls: 0.2010  loss_bbox: 0.2281
2025/05/13 02:25:00 - mmengine - INFO - Epoch(train) [10][1000/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:41:00  time: 0.3024  data_time: 0.0005  memory: 19488  loss: 0.4498  loss_cls: 0.2142  loss_bbox: 0.2355
2025/05/13 02:25:15 - mmengine - INFO - Epoch(train) [10][1050/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:40:45  time: 0.2977  data_time: 0.0005  memory: 19485  loss: 0.4292  loss_cls: 0.1969  loss_bbox: 0.2323
2025/05/13 02:25:30 - mmengine - INFO - Epoch(train) [10][1100/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:40:29  time: 0.2980  data_time: 0.0005  memory: 19492  loss: 0.4035  loss_cls: 0.1860  loss_bbox: 0.2176
2025/05/13 02:25:45 - mmengine - INFO - Epoch(train) [10][1150/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:40:14  time: 0.2979  data_time: 0.0005  memory: 19480  loss: 0.4186  loss_cls: 0.1935  loss_bbox: 0.2251
2025/05/13 02:25:59 - mmengine - INFO - Epoch(train) [10][1200/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:39:58  time: 0.2980  data_time: 0.0005  memory: 19492  loss: 0.4109  loss_cls: 0.1931  loss_bbox: 0.2178
2025/05/13 02:26:14 - mmengine - INFO - Epoch(train) [10][1250/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:39:43  time: 0.2983  data_time: 0.0005  memory: 19509  loss: 0.4444  loss_cls: 0.2204  loss_bbox: 0.2240
2025/05/13 02:26:29 - mmengine - INFO - Epoch(train) [10][1300/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:39:28  time: 0.2983  data_time: 0.0005  memory: 19506  loss: 0.4046  loss_cls: 0.1873  loss_bbox: 0.2172
2025/05/13 02:26:41 - mmengine - INFO - Exp name: rtmdet_m_1x_custom_resume_20250513_014813
2025/05/13 02:26:44 - mmengine - INFO - Epoch(train) [10][1350/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:39:12  time: 0.2978  data_time: 0.0005  memory: 19491  loss: 0.4046  loss_cls: 0.1869  loss_bbox: 0.2177
2025/05/13 02:26:59 - mmengine - INFO - Epoch(train) [10][1400/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:38:57  time: 0.2981  data_time: 0.0005  memory: 19489  loss: 0.4304  loss_cls: 0.2058  loss_bbox: 0.2246
2025/05/13 02:27:14 - mmengine - INFO - Epoch(train) [10][1450/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:38:41  time: 0.2981  data_time: 0.0005  memory: 19485  loss: 0.4118  loss_cls: 0.1874  loss_bbox: 0.2244
2025/05/13 02:27:29 - mmengine - INFO - Epoch(train) [10][1500/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:38:26  time: 0.2983  data_time: 0.0005  memory: 19502  loss: 0.4067  loss_cls: 0.1898  loss_bbox: 0.2169
2025/05/13 02:27:37 - mmengine - INFO - Exp name: rtmdet_m_1x_custom_resume_20250513_014813
2025/05/13 02:27:37 - mmengine - INFO - Saving checkpoint at 10 epochs
2025/05/13 02:27:42 - mmengine - INFO - Epoch(val) [10][ 50/149]    eta: 0:00:08  time: 0.0825  data_time: 0.0037  memory: 19472  
2025/05/13 02:27:46 - mmengine - INFO - Epoch(val) [10][100/149]    eta: 0:00:04  time: 0.0813  data_time: 0.0028  memory: 1598  
2025/05/13 02:27:51 - mmengine - INFO - Evaluating bbox...
2025/05/13 02:27:53 - mmengine - INFO - bbox_mAP_copypaste: 0.769 0.942 0.857 0.441 0.657 0.814
2025/05/13 02:27:53 - mmengine - INFO - Epoch(val) [10][149/149]    coco/bbox_mAP: 0.7690  coco/bbox_mAP_50: 0.9420  coco/bbox_mAP_75: 0.8570  coco/bbox_mAP_s: 0.4410  coco/bbox_mAP_m: 0.6570  coco/bbox_mAP_l: 0.8140  data_time: 0.0030  time: 0.0809
2025/05/13 02:28:08 - mmengine - INFO - Epoch(train) [11][  50/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:38:02  time: 0.3007  data_time: 0.0031  memory: 19485  loss: 0.4143  loss_cls: 0.1910  loss_bbox: 0.2233
2025/05/13 02:28:24 - mmengine - INFO - Epoch(train) [11][ 100/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:37:47  time: 0.3022  data_time: 0.0005  memory: 19479  loss: 0.4182  loss_cls: 0.1999  loss_bbox: 0.2183
2025/05/13 02:28:38 - mmengine - INFO - Epoch(train) [11][ 150/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:37:31  time: 0.2978  data_time: 0.0005  memory: 19474  loss: 0.4339  loss_cls: 0.2140  loss_bbox: 0.2199
2025/05/13 02:28:53 - mmengine - INFO - Epoch(train) [11][ 200/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:37:16  time: 0.2981  data_time: 0.0005  memory: 19488  loss: 0.4144  loss_cls: 0.1989  loss_bbox: 0.2155
2025/05/13 02:29:08 - mmengine - INFO - Epoch(train) [11][ 250/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:37:01  time: 0.2985  data_time: 0.0005  memory: 19503  loss: 0.4143  loss_cls: 0.1921  loss_bbox: 0.2222
2025/05/13 02:29:23 - mmengine - INFO - Epoch(train) [11][ 300/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:36:45  time: 0.2977  data_time: 0.0005  memory: 19495  loss: 0.4411  loss_cls: 0.2087  loss_bbox: 0.2324
2025/05/13 02:29:38 - mmengine - INFO - Epoch(train) [11][ 350/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:36:30  time: 0.2977  data_time: 0.0005  memory: 19486  loss: 0.4181  loss_cls: 0.2029  loss_bbox: 0.2152
2025/05/13 02:29:53 - mmengine - INFO - Epoch(train) [11][ 400/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:36:14  time: 0.2978  data_time: 0.0005  memory: 19520  loss: 0.4179  loss_cls: 0.1910  loss_bbox: 0.2269
2025/05/13 02:30:08 - mmengine - INFO - Epoch(train) [11][ 450/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:35:59  time: 0.2981  data_time: 0.0005  memory: 19515  loss: 0.4108  loss_cls: 0.1886  loss_bbox: 0.2222
2025/05/13 02:30:23 - mmengine - INFO - Epoch(train) [11][ 500/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:35:44  time: 0.2982  data_time: 0.0005  memory: 19509  loss: 0.4402  loss_cls: 0.2082  loss_bbox: 0.2320
2025/05/13 02:30:38 - mmengine - INFO - Epoch(train) [11][ 550/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:35:28  time: 0.2982  data_time: 0.0005  memory: 19491  loss: 0.4182  loss_cls: 0.1924  loss_bbox: 0.2258
2025/05/13 02:30:53 - mmengine - INFO - Epoch(train) [11][ 600/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:35:13  time: 0.2980  data_time: 0.0005  memory: 19521  loss: 0.4208  loss_cls: 0.1987  loss_bbox: 0.2221
2025/05/13 02:31:08 - mmengine - INFO - Epoch(train) [11][ 650/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:34:58  time: 0.2982  data_time: 0.0005  memory: 19515  loss: 0.4173  loss_cls: 0.1919  loss_bbox: 0.2254
2025/05/13 02:31:22 - mmengine - INFO - Epoch(train) [11][ 700/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:34:42  time: 0.2982  data_time: 0.0005  memory: 19502  loss: 0.4020  loss_cls: 0.1836  loss_bbox: 0.2184
2025/05/13 02:31:37 - mmengine - INFO - Epoch(train) [11][ 750/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:34:27  time: 0.2980  data_time: 0.0005  memory: 19488  loss: 0.4284  loss_cls: 0.1970  loss_bbox: 0.2314
2025/05/13 02:31:52 - mmengine - INFO - Epoch(train) [11][ 800/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:34:12  time: 0.2978  data_time: 0.0005  memory: 19502  loss: 0.4185  loss_cls: 0.1925  loss_bbox: 0.2260
2025/05/13 02:31:55 - mmengine - INFO - Exp name: rtmdet_m_1x_custom_resume_20250513_014813
2025/05/13 02:32:07 - mmengine - INFO - Epoch(train) [11][ 850/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:33:56  time: 0.2978  data_time: 0.0005  memory: 19493  loss: 0.4266  loss_cls: 0.2016  loss_bbox: 0.2251
2025/05/13 02:32:22 - mmengine - INFO - Epoch(train) [11][ 900/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:33:42  time: 0.3025  data_time: 0.0005  memory: 19489  loss: 0.4190  loss_cls: 0.1926  loss_bbox: 0.2264
2025/05/13 02:32:37 - mmengine - INFO - Epoch(train) [11][ 950/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:33:26  time: 0.2983  data_time: 0.0005  memory: 19492  loss: 0.3977  loss_cls: 0.1843  loss_bbox: 0.2133
2025/05/13 02:32:52 - mmengine - INFO - Epoch(train) [11][1000/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:33:11  time: 0.2981  data_time: 0.0005  memory: 19479  loss: 0.4308  loss_cls: 0.2020  loss_bbox: 0.2288
2025/05/13 02:33:07 - mmengine - INFO - Epoch(train) [11][1050/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:32:56  time: 0.2981  data_time: 0.0006  memory: 19501  loss: 0.4192  loss_cls: 0.1951  loss_bbox: 0.2242
2025/05/13 02:33:22 - mmengine - INFO - Epoch(train) [11][1100/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:32:41  time: 0.2983  data_time: 0.0005  memory: 19504  loss: 0.4292  loss_cls: 0.1975  loss_bbox: 0.2318
2025/05/13 02:33:37 - mmengine - INFO - Epoch(train) [11][1150/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:32:25  time: 0.2993  data_time: 0.0005  memory: 19511  loss: 0.4048  loss_cls: 0.1881  loss_bbox: 0.2167
2025/05/13 02:33:52 - mmengine - INFO - Epoch(train) [11][1200/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:32:10  time: 0.2983  data_time: 0.0005  memory: 19487  loss: 0.4259  loss_cls: 0.2000  loss_bbox: 0.2259
2025/05/13 02:34:07 - mmengine - INFO - Epoch(train) [11][1250/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:31:55  time: 0.2981  data_time: 0.0005  memory: 19484  loss: 0.3982  loss_cls: 0.1807  loss_bbox: 0.2175
2025/05/13 02:34:22 - mmengine - INFO - Epoch(train) [11][1300/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:31:40  time: 0.2980  data_time: 0.0005  memory: 19489  loss: 0.4165  loss_cls: 0.1950  loss_bbox: 0.2215
2025/05/13 02:34:36 - mmengine - INFO - Epoch(train) [11][1350/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:31:24  time: 0.2982  data_time: 0.0005  memory: 19484  loss: 0.4054  loss_cls: 0.1841  loss_bbox: 0.2213
2025/05/13 02:34:51 - mmengine - INFO - Epoch(train) [11][1400/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:31:09  time: 0.2982  data_time: 0.0005  memory: 19476  loss: 0.4262  loss_cls: 0.2054  loss_bbox: 0.2208
2025/05/13 02:35:06 - mmengine - INFO - Epoch(train) [11][1450/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:30:54  time: 0.2981  data_time: 0.0005  memory: 19509  loss: 0.4083  loss_cls: 0.1895  loss_bbox: 0.2188
2025/05/13 02:35:21 - mmengine - INFO - Epoch(train) [11][1500/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:30:39  time: 0.2985  data_time: 0.0006  memory: 19495  loss: 0.4272  loss_cls: 0.2036  loss_bbox: 0.2236
2025/05/13 02:35:29 - mmengine - INFO - Exp name: rtmdet_m_1x_custom_resume_20250513_014813
2025/05/13 02:35:29 - mmengine - INFO - Saving checkpoint at 11 epochs
2025/05/13 02:35:34 - mmengine - INFO - Epoch(val) [11][ 50/149]    eta: 0:00:08  time: 0.0825  data_time: 0.0039  memory: 19492  
2025/05/13 02:35:38 - mmengine - INFO - Epoch(val) [11][100/149]    eta: 0:00:04  time: 0.0809  data_time: 0.0027  memory: 1598  
2025/05/13 02:35:43 - mmengine - INFO - Evaluating bbox...
2025/05/13 02:35:46 - mmengine - INFO - bbox_mAP_copypaste: 0.768 0.943 0.864 0.457 0.655 0.812
2025/05/13 02:35:46 - mmengine - INFO - Epoch(val) [11][149/149]    coco/bbox_mAP: 0.7680  coco/bbox_mAP_50: 0.9430  coco/bbox_mAP_75: 0.8640  coco/bbox_mAP_s: 0.4570  coco/bbox_mAP_m: 0.6550  coco/bbox_mAP_l: 0.8120  data_time: 0.0030  time: 0.0808
2025/05/13 02:36:01 - mmengine - INFO - Epoch(train) [12][  50/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:30:15  time: 0.2998  data_time: 0.0029  memory: 19507  loss: 0.4210  loss_cls: 0.1977  loss_bbox: 0.2233
2025/05/13 02:36:16 - mmengine - INFO - Epoch(train) [12][ 100/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:29:59  time: 0.2980  data_time: 0.0006  memory: 19508  loss: 0.4042  loss_cls: 0.1830  loss_bbox: 0.2211
2025/05/13 02:36:31 - mmengine - INFO - Epoch(train) [12][ 150/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:29:44  time: 0.2978  data_time: 0.0005  memory: 19509  loss: 0.4074  loss_cls: 0.1830  loss_bbox: 0.2244
2025/05/13 02:36:46 - mmengine - INFO - Epoch(train) [12][ 200/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:29:29  time: 0.2976  data_time: 0.0005  memory: 19487  loss: 0.4260  loss_cls: 0.1972  loss_bbox: 0.2288
2025/05/13 02:37:01 - mmengine - INFO - Epoch(train) [12][ 250/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:29:13  time: 0.2977  data_time: 0.0005  memory: 19481  loss: 0.4094  loss_cls: 0.1912  loss_bbox: 0.2181
2025/05/13 02:37:10 - mmengine - INFO - Exp name: rtmdet_m_1x_custom_resume_20250513_014813
2025/05/13 02:37:15 - mmengine - INFO - Epoch(train) [12][ 300/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:28:58  time: 0.2983  data_time: 0.0005  memory: 19505  loss: 0.4225  loss_cls: 0.2010  loss_bbox: 0.2214
2025/05/13 02:37:30 - mmengine - INFO - Epoch(train) [12][ 350/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:28:43  time: 0.2979  data_time: 0.0005  memory: 19483  loss: 0.4123  loss_cls: 0.1911  loss_bbox: 0.2212
2025/05/13 02:37:45 - mmengine - INFO - Epoch(train) [12][ 400/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:28:28  time: 0.2981  data_time: 0.0005  memory: 19477  loss: 0.3980  loss_cls: 0.1771  loss_bbox: 0.2210
2025/05/13 02:38:00 - mmengine - INFO - Epoch(train) [12][ 450/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:28:12  time: 0.2986  data_time: 0.0005  memory: 19487  loss: 0.4060  loss_cls: 0.1983  loss_bbox: 0.2077
2025/05/13 02:38:15 - mmengine - INFO - Epoch(train) [12][ 500/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:27:57  time: 0.2981  data_time: 0.0005  memory: 19495  loss: 0.4122  loss_cls: 0.1871  loss_bbox: 0.2250
2025/05/13 02:38:30 - mmengine - INFO - Epoch(train) [12][ 550/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:27:42  time: 0.2979  data_time: 0.0005  memory: 19513  loss: 0.4243  loss_cls: 0.1956  loss_bbox: 0.2286
2025/05/13 02:38:45 - mmengine - INFO - Epoch(train) [12][ 600/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:27:27  time: 0.2971  data_time: 0.0005  memory: 19505  loss: 0.4012  loss_cls: 0.1894  loss_bbox: 0.2117
2025/05/13 02:39:00 - mmengine - INFO - Epoch(train) [12][ 650/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:27:11  time: 0.2969  data_time: 0.0005  memory: 19504  loss: 0.4275  loss_cls: 0.2002  loss_bbox: 0.2273
2025/05/13 02:39:15 - mmengine - INFO - Epoch(train) [12][ 700/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:26:56  time: 0.2984  data_time: 0.0006  memory: 19491  loss: 0.4247  loss_cls: 0.2054  loss_bbox: 0.2193
2025/05/13 02:39:29 - mmengine - INFO - Epoch(train) [12][ 750/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:26:41  time: 0.2972  data_time: 0.0005  memory: 19493  loss: 0.4395  loss_cls: 0.2127  loss_bbox: 0.2268
2025/05/13 02:39:44 - mmengine - INFO - Epoch(train) [12][ 800/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:26:25  time: 0.2970  data_time: 0.0005  memory: 19475  loss: 0.4392  loss_cls: 0.2110  loss_bbox: 0.2282
2025/05/13 02:39:59 - mmengine - INFO - Epoch(train) [12][ 850/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:26:10  time: 0.2981  data_time: 0.0005  memory: 19510  loss: 0.4453  loss_cls: 0.2062  loss_bbox: 0.2392
2025/05/13 02:40:14 - mmengine - INFO - Epoch(train) [12][ 900/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:25:55  time: 0.2978  data_time: 0.0005  memory: 19487  loss: 0.4329  loss_cls: 0.2038  loss_bbox: 0.2291
2025/05/13 02:40:29 - mmengine - INFO - Epoch(train) [12][ 950/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:25:40  time: 0.2974  data_time: 0.0005  memory: 19504  loss: 0.3942  loss_cls: 0.1804  loss_bbox: 0.2137
2025/05/13 02:40:44 - mmengine - INFO - Epoch(train) [12][1000/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:25:24  time: 0.2974  data_time: 0.0005  memory: 19476  loss: 0.4059  loss_cls: 0.1867  loss_bbox: 0.2192
2025/05/13 02:40:59 - mmengine - INFO - Epoch(train) [12][1050/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:25:09  time: 0.2979  data_time: 0.0005  memory: 19483  loss: 0.4114  loss_cls: 0.1847  loss_bbox: 0.2267
2025/05/13 02:41:14 - mmengine - INFO - Epoch(train) [12][1100/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:24:54  time: 0.2974  data_time: 0.0006  memory: 19484  loss: 0.4382  loss_cls: 0.2146  loss_bbox: 0.2236
2025/05/13 02:41:29 - mmengine - INFO - Epoch(train) [12][1150/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:24:38  time: 0.2980  data_time: 0.0005  memory: 19509  loss: 0.4005  loss_cls: 0.1797  loss_bbox: 0.2208
2025/05/13 02:41:43 - mmengine - INFO - Epoch(train) [12][1200/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:24:23  time: 0.2978  data_time: 0.0005  memory: 19481  loss: 0.4259  loss_cls: 0.2046  loss_bbox: 0.2213
2025/05/13 02:41:58 - mmengine - INFO - Epoch(train) [12][1250/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:24:08  time: 0.2976  data_time: 0.0005  memory: 19515  loss: 0.4367  loss_cls: 0.2088  loss_bbox: 0.2279
2025/05/13 02:42:08 - mmengine - INFO - Exp name: rtmdet_m_1x_custom_resume_20250513_014813
2025/05/13 02:42:13 - mmengine - INFO - Epoch(train) [12][1300/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:23:53  time: 0.2979  data_time: 0.0005  memory: 19503  loss: 0.4079  loss_cls: 0.1879  loss_bbox: 0.2200
2025/05/13 02:42:28 - mmengine - INFO - Epoch(train) [12][1350/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:23:38  time: 0.2977  data_time: 0.0005  memory: 19478  loss: 0.4190  loss_cls: 0.1964  loss_bbox: 0.2227
2025/05/13 02:42:43 - mmengine - INFO - Epoch(train) [12][1400/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:23:22  time: 0.2986  data_time: 0.0006  memory: 19509  loss: 0.4202  loss_cls: 0.1988  loss_bbox: 0.2214
2025/05/13 02:42:58 - mmengine - INFO - Epoch(train) [12][1450/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:23:07  time: 0.2976  data_time: 0.0005  memory: 19502  loss: 0.4062  loss_cls: 0.1820  loss_bbox: 0.2242
2025/05/13 02:43:13 - mmengine - INFO - Epoch(train) [12][1500/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:22:53  time: 0.3018  data_time: 0.0005  memory: 19497  loss: 0.3965  loss_cls: 0.1874  loss_bbox: 0.2091
2025/05/13 02:43:21 - mmengine - INFO - Exp name: rtmdet_m_1x_custom_resume_20250513_014813
2025/05/13 02:43:21 - mmengine - INFO - Saving checkpoint at 12 epochs
2025/05/13 02:43:26 - mmengine - INFO - Epoch(val) [12][ 50/149]    eta: 0:00:08  time: 0.0834  data_time: 0.0040  memory: 19474  
2025/05/13 02:43:30 - mmengine - INFO - Epoch(val) [12][100/149]    eta: 0:00:04  time: 0.0815  data_time: 0.0029  memory: 1598  
2025/05/13 02:43:35 - mmengine - INFO - Evaluating bbox...
2025/05/13 02:43:38 - mmengine - INFO - bbox_mAP_copypaste: 0.769 0.942 0.856 0.452 0.655 0.813
2025/05/13 02:43:38 - mmengine - INFO - Epoch(val) [12][149/149]    coco/bbox_mAP: 0.7690  coco/bbox_mAP_50: 0.9420  coco/bbox_mAP_75: 0.8560  coco/bbox_mAP_s: 0.4520  coco/bbox_mAP_m: 0.6550  coco/bbox_mAP_l: 0.8130  data_time: 0.0032  time: 0.0815
2025/05/13 02:43:38 - mmengine - INFO - the monitored metric did not improve in the last 3 records. best score: 0.770. 
