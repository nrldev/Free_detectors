2025/05/12 18:53:52 - mmengine - INFO - 
------------------------------------------------------------
System environment:
    sys.platform: linux
    Python: 3.11.11 (main, Dec 11 2024, 16:28:39) [GCC 11.2.0]
    CUDA available: True
    MUSA available: False
    numpy_random_seed: 197433822
    GPU 0: NVIDIA GeForce RTX 4090
    CUDA_HOME: /usr
    NVCC: Cuda compilation tools, release 12.0, V12.0.140
    GCC: gcc (Ubuntu 13.3.0-6ubuntu2~24.04) 13.3.0
    PyTorch: 2.4.1+cu121
    PyTorch compiling details: PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v3.4.2 (Git Hash 1137e04ec0b5251ca2b4400a4fd3c667ce843d67)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX512
  - CUDA Runtime 12.1
  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 90.1  (built against CUDA 12.4)
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=12.1, CUDNN_VERSION=9.1.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wsuggest-override -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=2.4.1, USE_CUDA=ON, USE_CUDNN=ON, USE_CUSPARSELT=1, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_GLOO=ON, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, USE_ROCM_KERNEL_ASSERT=OFF, 

    TorchVision: 0.19.1+cu121
    OpenCV: 4.11.0
    MMEngine: 0.10.7

Runtime environment:
    cudnn_benchmark: False
    dist_cfg: {'backend': 'nccl'}
    mp_cfg: {'mp_start_method': 'fork', 'opencv_num_threads': 0}
    seed: 197433822
    Distributed launcher: none
    Distributed training: False
    GPU number: 1
------------------------------------------------------------

2025/05/12 18:53:52 - mmengine - INFO - Config:
HOME = '/home/jaa/Work/Prog/BSU/Detectors'
MODEL_GROUP = 'yolo-like'
MODEL_TYPE = 'RTMDet'
WEIGHT_SIZE = 'm'
additions = 'new1'
auto_scale_lr = dict(base_batch_size=6, enable=False)
backend_args = None
base_lr = 0.004
batch_size = 6
checkpoint_config = dict(interval=1)
custom_hooks = [
    dict(type='CustomFreezeHook', unfreeze_epoch=5),
]
custom_imports = dict(
    allow_failed_imports=False, imports=[
        'custom_hooks',
    ])
data_root = '/home/jaa/Work/Prog/BSU/Detectors/mmdetection/data/Padded_GroundingDINO.v1i.yolov5pytorch/'
dataset_type = 'CocoDataset'
default_hooks = dict(
    checkpoint=dict(interval=1, max_keep_ckpts=3, type='CheckpointHook'),
    early_stopping=dict(
        min_delta=0.001,
        monitor='coco/bbox_mAP',
        patience=3,
        type='EarlyStoppingHook'),
    logger=dict(interval=50, log_metric_by_epoch=True, type='LoggerHook'),
    param_scheduler=dict(type='ParamSchedulerHook'),
    sampler_seed=dict(type='DistSamplerSeedHook'),
    timer=dict(type='IterTimerHook'),
    visualization=dict(type='DetVisualizationHook'))
default_scope = 'mmdet'
deterministic = True
env_cfg = dict(
    cudnn_benchmark=False,
    dist_cfg=dict(backend='nccl'),
    mp_cfg=dict(mp_start_method='fork', opencv_num_threads=0))
evaluation = dict(interval=1, metric='bbox')
experiment = 'RTMDet_m_30e_new1_custom'
img_scales = [
    (
        640,
        640,
    ),
    (
        320,
        320,
    ),
    (
        960,
        960,
    ),
]
interval = 10
launcher = 'none'
load_from = '/home/jaa/Work/Prog/BSU/Detectors/work_dirs/RTMDet/RTMDet_m_30e_new3_custom/epoch_5.pth'
log_level = 'INFO'
log_processor = dict(by_epoch=True, type='LogProcessor', window_size=50)
max_epochs = 300
metainfo = dict(
    classes=('cow', ), palette=[
        (
            220,
            20,
            60,
        ),
    ])
model = dict(
    backbone=dict(
        act_cfg=dict(inplace=True, type='SiLU'),
        arch='P5',
        channel_attention=True,
        deepen_factor=0.67,
        expand_ratio=0.5,
        norm_cfg=dict(type='SyncBN'),
        type='CSPNeXt',
        widen_factor=0.75),
    bbox_head=dict(
        act_cfg=dict(inplace=True, type='SiLU'),
        anchor_generator=dict(
            offset=0, strides=[
                8,
                16,
                32,
            ], type='MlvlPointGenerator'),
        bbox_coder=dict(type='DistancePointBBoxCoder'),
        exp_on_reg=True,
        feat_channels=192,
        in_channels=192,
        loss_bbox=dict(loss_weight=2.0, type='GIoULoss'),
        loss_cls=dict(
            beta=2.0,
            loss_weight=1.0,
            type='QualityFocalLoss',
            use_sigmoid=True),
        norm_cfg=dict(type='SyncBN'),
        num_classes=1,
        pred_kernel_size=1,
        share_conv=True,
        stacked_convs=2,
        type='RTMDetSepBNHead',
        with_objectness=False),
    data_preprocessor=dict(
        batch_augments=None,
        bgr_to_rgb=False,
        mean=[
            103.53,
            116.28,
            123.675,
        ],
        std=[
            57.375,
            57.12,
            58.395,
        ],
        type='DetDataPreprocessor'),
    neck=dict(
        act_cfg=dict(inplace=True, type='SiLU'),
        expand_ratio=0.5,
        in_channels=[
            192,
            384,
            768,
        ],
        norm_cfg=dict(type='SyncBN'),
        num_csp_blocks=2,
        out_channels=192,
        type='CSPNeXtPAFPN'),
    test_cfg=dict(
        max_per_img=300,
        min_bbox_size=0,
        nms=dict(iou_threshold=0.65, type='nms'),
        nms_pre=30000,
        score_thr=0.001),
    train_cfg=dict(
        allowed_border=-1,
        assigner=dict(topk=13, type='DynamicSoftLabelAssigner'),
        debug=False,
        pos_weight=-1),
    type='RTMDet')
num_classes = 1
num_epochs = 20
num_workers = 6
optim_wrapper = dict(
    optimizer=dict(lr=0.0025, momentum=0.9, type='SGD', weight_decay=0.0005),
    paramwise_cfg=dict(
        bias_decay_mult=0, bypass_duplicate=True, norm_decay_mult=0),
    type='OptimWrapper')
param_scheduler = [
    dict(
        begin=0, by_epoch=False, end=500, start_factor=0.001, type='LinearLR'),
    dict(
        begin=0,
        by_epoch=True,
        end=20,
        gamma=0.1,
        milestones=[
            7,
            14,
        ],
        type='MultiStepLR'),
    dict(T_max=20, begin=0, by_epoch=True, end=20, type='CosineAnnealingLR'),
]
resume = True
seed = 11
stage2_num_epochs = 20
test_cfg = dict(type='TestLoop')
test_dataloader = dict(
    batch_size=6,
    dataset=dict(
        ann_file=
        '/home/jaa/Work/Prog/BSU/Detectors/mmdetection/data/Padded_GroundingDINO.v1i.yolov5pytorch/test_coco.json',
        backend_args=None,
        data_prefix=dict(
            img=
            '/home/jaa/Work/Prog/BSU/Detectors/mmdetection/data/Padded_GroundingDINO.v1i.yolov5pytorch/test/images'
        ),
        data_root=
        '/home/jaa/Work/Prog/BSU/Detectors/mmdetection/data/Padded_GroundingDINO.v1i.yolov5pytorch/',
        pipeline=[
            dict(backend_args=None, type='LoadImageFromFile'),
            dict(type='LoadAnnotations', with_bbox=True),
            dict(
                keep_empty=False,
                min_gt_bbox_wh=(
                    16,
                    16,
                ),
                type='FilterAnnotations'),
            dict(keep_ratio=True, scale=(
                1280,
                1280,
            ), type='Resize'),
            dict(
                meta_keys=(
                    'img_id',
                    'img_path',
                    'ori_shape',
                    'img_shape',
                    'scale_factor',
                ),
                type='PackDetInputs'),
        ],
        test_mode=True,
        type='CocoDataset'),
    drop_last=False,
    num_workers=6,
    persistent_workers=True,
    sampler=dict(shuffle=False, type='DefaultSampler'))
test_evaluator = dict(
    ann_file=
    '/home/jaa/Work/Prog/BSU/Detectors/mmdetection/data/Padded_GroundingDINO.v1i.yolov5pytorch/test_coco.json',
    backend_args=None,
    format_only=True,
    metric='bbox',
    outfile_prefix=
    '/home/jaa/Work/Prog/BSU/Detectors/mmdetection/data/Padded_GroundingDINO.v1i.yolov5pytorch/test/images',
    proposal_nums=(
        100,
        1,
        10,
    ),
    type='CocoMetric')
test_pipeline = [
    dict(backend_args=None, type='LoadImageFromFile'),
    dict(type='LoadAnnotations', with_bbox=True),
    dict(
        keep_empty=False, min_gt_bbox_wh=(
            16,
            16,
        ), type='FilterAnnotations'),
    dict(keep_ratio=True, scale=(
        1280,
        1280,
    ), type='Resize'),
    dict(
        meta_keys=(
            'img_id',
            'img_path',
            'ori_shape',
            'img_shape',
            'scale_factor',
        ),
        type='PackDetInputs'),
]
train_cfg = dict(
    dynamic_intervals=[
        (
            280,
            1,
        ),
    ],
    max_epochs=30,
    type='EpochBasedTrainLoop',
    val_interval=1)
train_dataloader = dict(
    batch_sampler=None,
    batch_size=6,
    dataset=dict(
        ann_file=
        '/home/jaa/Work/Prog/BSU/Detectors/mmdetection/data/Padded_GroundingDINO.v1i.yolov5pytorch/train_coco.json',
        backend_args=None,
        data_prefix=dict(
            img=
            '/home/jaa/Work/Prog/BSU/Detectors/mmdetection/data/Padded_GroundingDINO.v1i.yolov5pytorch/train/images'
        ),
        data_root=
        '/home/jaa/Work/Prog/BSU/Detectors/mmdetection/data/Padded_GroundingDINO.v1i.yolov5pytorch/',
        filter_cfg=dict(filter_empty_gt=True, min_size=32),
        metainfo=dict(classes=('cow', ), palette=[
            (
                220,
                20,
                60,
            ),
        ]),
        pipeline=[
            dict(backend_args=None, type='LoadImageFromFile'),
            dict(type='LoadAnnotations', with_bbox=True),
            dict(prob=0.5, type='RandomFlip'),
            dict(level=2, prob=0.3, type='Rotate'),
            dict(
                keep_empty=False,
                min_gt_bbox_wh=(
                    16,
                    16,
                ),
                type='FilterAnnotations'),
            dict(keep_ratio=True, scale=(
                1280,
                1280,
            ), type='Resize'),
            dict(type='PackDetInputs'),
        ],
        type='CocoDataset'),
    num_workers=6,
    persistent_workers=True,
    pin_memory=True,
    sampler=dict(shuffle=True, type='DefaultSampler'))
train_pipeline = [
    dict(backend_args=None, type='LoadImageFromFile'),
    dict(type='LoadAnnotations', with_bbox=True),
    dict(prob=0.5, type='RandomFlip'),
    dict(level=2, prob=0.3, type='Rotate'),
    dict(
        keep_empty=False, min_gt_bbox_wh=(
            16,
            16,
        ), type='FilterAnnotations'),
    dict(keep_ratio=True, scale=(
        1280,
        1280,
    ), type='Resize'),
    dict(type='PackDetInputs'),
]
train_pipeline_stage2 = [
    dict(backend_args=None, type='LoadImageFromFile'),
    dict(type='LoadAnnotations', with_bbox=True),
    dict(
        keep_ratio=True,
        ratio_range=(
            0.1,
            2.0,
        ),
        scale=(
            640,
            640,
        ),
        type='RandomResize'),
    dict(crop_size=(
        640,
        640,
    ), type='RandomCrop'),
    dict(type='YOLOXHSVRandomAug'),
    dict(prob=0.5, type='RandomFlip'),
    dict(pad_val=dict(img=(
        114,
        114,
        114,
    )), size=(
        640,
        640,
    ), type='Pad'),
    dict(type='PackDetInputs'),
]
tta_model = dict(
    tta_cfg=dict(max_per_img=100, nms=dict(iou_threshold=0.6, type='nms')),
    type='DetTTAModel')
tta_pipeline = [
    dict(backend_args=None, type='LoadImageFromFile'),
    dict(
        transforms=[
            [
                dict(keep_ratio=True, scale=(
                    640,
                    640,
                ), type='Resize'),
                dict(keep_ratio=True, scale=(
                    320,
                    320,
                ), type='Resize'),
                dict(keep_ratio=True, scale=(
                    960,
                    960,
                ), type='Resize'),
            ],
            [
                dict(prob=1.0, type='RandomFlip'),
                dict(prob=0.0, type='RandomFlip'),
            ],
            [
                dict(
                    pad_val=dict(img=(
                        114,
                        114,
                        114,
                    )),
                    size=(
                        960,
                        960,
                    ),
                    type='Pad'),
            ],
            [
                dict(type='LoadAnnotations', with_bbox=True),
            ],
            [
                dict(
                    meta_keys=(
                        'img_id',
                        'img_path',
                        'ori_shape',
                        'img_shape',
                        'scale_factor',
                        'flip',
                        'flip_direction',
                    ),
                    type='PackDetInputs'),
            ],
        ],
        type='TestTimeAug'),
]
val_cfg = dict(type='ValLoop')
val_dataloader = dict(
    batch_size=5,
    dataset=dict(
        ann_file=
        '/home/jaa/Work/Prog/BSU/Detectors/mmdetection/data/Padded_GroundingDINO.v1i.yolov5pytorch/valid_coco.json',
        backend_args=None,
        data_prefix=dict(
            img=
            '/home/jaa/Work/Prog/BSU/Detectors/mmdetection/data/Padded_GroundingDINO.v1i.yolov5pytorch/valid/images'
        ),
        data_root=
        '/home/jaa/Work/Prog/BSU/Detectors/mmdetection/data/Padded_GroundingDINO.v1i.yolov5pytorch/',
        metainfo=dict(classes=('cow', ), palette=[
            (
                220,
                20,
                60,
            ),
        ]),
        pipeline=[
            dict(backend_args=None, type='LoadImageFromFile'),
            dict(type='LoadAnnotations', with_bbox=True),
            dict(
                keep_empty=False,
                min_gt_bbox_wh=(
                    16,
                    16,
                ),
                type='FilterAnnotations'),
            dict(keep_ratio=True, scale=(
                1280,
                1280,
            ), type='Resize'),
            dict(
                meta_keys=(
                    'img_id',
                    'img_path',
                    'ori_shape',
                    'img_shape',
                    'scale_factor',
                ),
                type='PackDetInputs'),
        ],
        test_mode=True,
        type='CocoDataset'),
    drop_last=False,
    num_workers=6,
    persistent_workers=True,
    sampler=dict(shuffle=False, type='DefaultSampler'))
val_evaluator = dict(
    ann_file=
    '/home/jaa/Work/Prog/BSU/Detectors/mmdetection/data/Padded_GroundingDINO.v1i.yolov5pytorch//valid_coco.json',
    backend_args=None,
    format_only=False,
    metric='bbox',
    proposal_nums=(
        100,
        1,
        10,
    ),
    type='CocoMetric')
vis_backends = [
    dict(
        init_kwargs=dict(
            group='yolo-like',
            name='RTMDet_m_30e_6b_new1',
            project='Сomparison of detectors'),
        type='WandbVisBackend'),
]
visualizer = dict(
    type='Visualizer',
    vis_backends=[
        dict(
            init_kwargs=dict(
                group='yolo-like',
                name='RTMDet_m_30e_6b_new1',
                project='Сomparison of detectors'),
            type='WandbVisBackend'),
    ])
weights = 'rtmdet_m_8xb32-300e_coco_20220719_112220-229f527c.pth'
work_dir = '/home/jaa/Work/Prog/BSU/Detectors/work_dirs/RTMDet/RTMDet_m_30e_new1_custom/'

2025/05/12 18:53:55 - mmengine - INFO - Distributed training is not used, all SyncBatchNorm (SyncBN) layers in the model will be automatically reverted to BatchNormXd layers if they are used.
2025/05/12 18:53:55 - mmengine - INFO - Hooks will be executed in the following order:
before_run:
(VERY_HIGH   ) RuntimeInfoHook                    
(BELOW_NORMAL) LoggerHook                         
(LOWEST      ) EarlyStoppingHook                  
 -------------------- 
before_train:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(NORMAL      ) CustomFreezeHook                   
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
before_train_epoch:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(NORMAL      ) DistSamplerSeedHook                
(NORMAL      ) CustomFreezeHook                   
 -------------------- 
before_train_iter:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
 -------------------- 
after_train_iter:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(BELOW_NORMAL) LoggerHook                         
(LOW         ) ParamSchedulerHook                 
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
after_train_epoch:
(NORMAL      ) IterTimerHook                      
(LOW         ) ParamSchedulerHook                 
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
before_val:
(VERY_HIGH   ) RuntimeInfoHook                    
 -------------------- 
before_val_epoch:
(NORMAL      ) IterTimerHook                      
 -------------------- 
before_val_iter:
(NORMAL      ) IterTimerHook                      
 -------------------- 
after_val_iter:
(NORMAL      ) IterTimerHook                      
(NORMAL      ) DetVisualizationHook               
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
after_val_epoch:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(BELOW_NORMAL) LoggerHook                         
(LOW         ) ParamSchedulerHook                 
(VERY_LOW    ) CheckpointHook                     
(LOWEST      ) EarlyStoppingHook                  
 -------------------- 
after_val:
(VERY_HIGH   ) RuntimeInfoHook                    
 -------------------- 
after_train:
(VERY_HIGH   ) RuntimeInfoHook                    
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
before_test:
(VERY_HIGH   ) RuntimeInfoHook                    
 -------------------- 
before_test_epoch:
(NORMAL      ) IterTimerHook                      
 -------------------- 
before_test_iter:
(NORMAL      ) IterTimerHook                      
 -------------------- 
after_test_iter:
(NORMAL      ) IterTimerHook                      
(NORMAL      ) DetVisualizationHook               
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
after_test_epoch:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
after_test:
(VERY_HIGH   ) RuntimeInfoHook                    
 -------------------- 
after_run:
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
2025/05/12 18:53:56 - mmengine - INFO - paramwise_options -- backbone.stem.0.bn.weight:weight_decay=0.0
2025/05/12 18:53:56 - mmengine - INFO - paramwise_options -- backbone.stem.0.bn.bias:weight_decay=0.0
2025/05/12 18:53:56 - mmengine - INFO - paramwise_options -- backbone.stem.1.bn.weight:weight_decay=0.0
2025/05/12 18:53:56 - mmengine - INFO - paramwise_options -- backbone.stem.1.bn.bias:weight_decay=0.0
2025/05/12 18:53:56 - mmengine - INFO - paramwise_options -- backbone.stem.2.bn.weight:weight_decay=0.0
2025/05/12 18:53:56 - mmengine - INFO - paramwise_options -- backbone.stem.2.bn.bias:weight_decay=0.0
2025/05/12 18:53:56 - mmengine - INFO - paramwise_options -- backbone.stage1.0.bn.weight:weight_decay=0.0
2025/05/12 18:53:56 - mmengine - INFO - paramwise_options -- backbone.stage1.0.bn.bias:weight_decay=0.0
2025/05/12 18:53:56 - mmengine - INFO - paramwise_options -- backbone.stage1.1.main_conv.bn.weight:weight_decay=0.0
2025/05/12 18:53:56 - mmengine - INFO - paramwise_options -- backbone.stage1.1.main_conv.bn.bias:weight_decay=0.0
2025/05/12 18:53:56 - mmengine - INFO - paramwise_options -- backbone.stage1.1.short_conv.bn.weight:weight_decay=0.0
2025/05/12 18:53:56 - mmengine - INFO - paramwise_options -- backbone.stage1.1.short_conv.bn.bias:weight_decay=0.0
2025/05/12 18:53:56 - mmengine - INFO - paramwise_options -- backbone.stage1.1.final_conv.bn.weight:weight_decay=0.0
2025/05/12 18:53:56 - mmengine - INFO - paramwise_options -- backbone.stage1.1.final_conv.bn.bias:weight_decay=0.0
2025/05/12 18:53:56 - mmengine - INFO - paramwise_options -- backbone.stage1.1.blocks.0.conv1.bn.weight:weight_decay=0.0
2025/05/12 18:53:56 - mmengine - INFO - paramwise_options -- backbone.stage1.1.blocks.0.conv1.bn.bias:weight_decay=0.0
2025/05/12 18:53:56 - mmengine - INFO - paramwise_options -- backbone.stage1.1.blocks.0.conv2.depthwise_conv.bn.weight:weight_decay=0.0
2025/05/12 18:53:56 - mmengine - INFO - paramwise_options -- backbone.stage1.1.blocks.0.conv2.depthwise_conv.bn.bias:weight_decay=0.0
2025/05/12 18:53:56 - mmengine - INFO - paramwise_options -- backbone.stage1.1.blocks.0.conv2.pointwise_conv.bn.weight:weight_decay=0.0
2025/05/12 18:53:56 - mmengine - INFO - paramwise_options -- backbone.stage1.1.blocks.0.conv2.pointwise_conv.bn.bias:weight_decay=0.0
2025/05/12 18:53:56 - mmengine - INFO - paramwise_options -- backbone.stage1.1.blocks.1.conv1.bn.weight:weight_decay=0.0
2025/05/12 18:53:56 - mmengine - INFO - paramwise_options -- backbone.stage1.1.blocks.1.conv1.bn.bias:weight_decay=0.0
2025/05/12 18:53:56 - mmengine - INFO - paramwise_options -- backbone.stage1.1.blocks.1.conv2.depthwise_conv.bn.weight:weight_decay=0.0
2025/05/12 18:53:56 - mmengine - INFO - paramwise_options -- backbone.stage1.1.blocks.1.conv2.depthwise_conv.bn.bias:weight_decay=0.0
2025/05/12 18:53:56 - mmengine - INFO - paramwise_options -- backbone.stage1.1.blocks.1.conv2.pointwise_conv.bn.weight:weight_decay=0.0
2025/05/12 18:53:56 - mmengine - INFO - paramwise_options -- backbone.stage1.1.blocks.1.conv2.pointwise_conv.bn.bias:weight_decay=0.0
2025/05/12 18:53:56 - mmengine - INFO - paramwise_options -- backbone.stage1.1.attention.fc.bias:weight_decay=0.0
2025/05/12 18:53:56 - mmengine - INFO - paramwise_options -- backbone.stage2.0.bn.weight:weight_decay=0.0
2025/05/12 18:53:56 - mmengine - INFO - paramwise_options -- backbone.stage2.0.bn.bias:weight_decay=0.0
2025/05/12 18:53:56 - mmengine - INFO - paramwise_options -- backbone.stage2.1.main_conv.bn.weight:weight_decay=0.0
2025/05/12 18:53:56 - mmengine - INFO - paramwise_options -- backbone.stage2.1.main_conv.bn.bias:weight_decay=0.0
2025/05/12 18:53:56 - mmengine - INFO - paramwise_options -- backbone.stage2.1.short_conv.bn.weight:weight_decay=0.0
2025/05/12 18:53:56 - mmengine - INFO - paramwise_options -- backbone.stage2.1.short_conv.bn.bias:weight_decay=0.0
2025/05/12 18:53:56 - mmengine - INFO - paramwise_options -- backbone.stage2.1.final_conv.bn.weight:weight_decay=0.0
2025/05/12 18:53:56 - mmengine - INFO - paramwise_options -- backbone.stage2.1.final_conv.bn.bias:weight_decay=0.0
2025/05/12 18:53:56 - mmengine - INFO - paramwise_options -- backbone.stage2.1.blocks.0.conv1.bn.weight:weight_decay=0.0
2025/05/12 18:53:56 - mmengine - INFO - paramwise_options -- backbone.stage2.1.blocks.0.conv1.bn.bias:weight_decay=0.0
2025/05/12 18:53:56 - mmengine - INFO - paramwise_options -- backbone.stage2.1.blocks.0.conv2.depthwise_conv.bn.weight:weight_decay=0.0
2025/05/12 18:53:56 - mmengine - INFO - paramwise_options -- backbone.stage2.1.blocks.0.conv2.depthwise_conv.bn.bias:weight_decay=0.0
2025/05/12 18:53:56 - mmengine - INFO - paramwise_options -- backbone.stage2.1.blocks.0.conv2.pointwise_conv.bn.weight:weight_decay=0.0
2025/05/12 18:53:56 - mmengine - INFO - paramwise_options -- backbone.stage2.1.blocks.0.conv2.pointwise_conv.bn.bias:weight_decay=0.0
2025/05/12 18:53:56 - mmengine - INFO - paramwise_options -- backbone.stage2.1.blocks.1.conv1.bn.weight:weight_decay=0.0
2025/05/12 18:53:56 - mmengine - INFO - paramwise_options -- backbone.stage2.1.blocks.1.conv1.bn.bias:weight_decay=0.0
2025/05/12 18:53:56 - mmengine - INFO - paramwise_options -- backbone.stage2.1.blocks.1.conv2.depthwise_conv.bn.weight:weight_decay=0.0
2025/05/12 18:53:56 - mmengine - INFO - paramwise_options -- backbone.stage2.1.blocks.1.conv2.depthwise_conv.bn.bias:weight_decay=0.0
2025/05/12 18:53:56 - mmengine - INFO - paramwise_options -- backbone.stage2.1.blocks.1.conv2.pointwise_conv.bn.weight:weight_decay=0.0
2025/05/12 18:53:56 - mmengine - INFO - paramwise_options -- backbone.stage2.1.blocks.1.conv2.pointwise_conv.bn.bias:weight_decay=0.0
2025/05/12 18:53:56 - mmengine - INFO - paramwise_options -- backbone.stage2.1.blocks.2.conv1.bn.weight:weight_decay=0.0
2025/05/12 18:53:56 - mmengine - INFO - paramwise_options -- backbone.stage2.1.blocks.2.conv1.bn.bias:weight_decay=0.0
2025/05/12 18:53:56 - mmengine - INFO - paramwise_options -- backbone.stage2.1.blocks.2.conv2.depthwise_conv.bn.weight:weight_decay=0.0
2025/05/12 18:53:56 - mmengine - INFO - paramwise_options -- backbone.stage2.1.blocks.2.conv2.depthwise_conv.bn.bias:weight_decay=0.0
2025/05/12 18:53:56 - mmengine - INFO - paramwise_options -- backbone.stage2.1.blocks.2.conv2.pointwise_conv.bn.weight:weight_decay=0.0
2025/05/12 18:53:56 - mmengine - INFO - paramwise_options -- backbone.stage2.1.blocks.2.conv2.pointwise_conv.bn.bias:weight_decay=0.0
2025/05/12 18:53:56 - mmengine - INFO - paramwise_options -- backbone.stage2.1.blocks.3.conv1.bn.weight:weight_decay=0.0
2025/05/12 18:53:56 - mmengine - INFO - paramwise_options -- backbone.stage2.1.blocks.3.conv1.bn.bias:weight_decay=0.0
2025/05/12 18:53:56 - mmengine - INFO - paramwise_options -- backbone.stage2.1.blocks.3.conv2.depthwise_conv.bn.weight:weight_decay=0.0
2025/05/12 18:53:56 - mmengine - INFO - paramwise_options -- backbone.stage2.1.blocks.3.conv2.depthwise_conv.bn.bias:weight_decay=0.0
2025/05/12 18:53:56 - mmengine - INFO - paramwise_options -- backbone.stage2.1.blocks.3.conv2.pointwise_conv.bn.weight:weight_decay=0.0
2025/05/12 18:53:56 - mmengine - INFO - paramwise_options -- backbone.stage2.1.blocks.3.conv2.pointwise_conv.bn.bias:weight_decay=0.0
2025/05/12 18:53:56 - mmengine - INFO - paramwise_options -- backbone.stage2.1.attention.fc.bias:weight_decay=0.0
2025/05/12 18:53:56 - mmengine - INFO - paramwise_options -- backbone.stage3.0.bn.weight:weight_decay=0.0
2025/05/12 18:53:56 - mmengine - INFO - paramwise_options -- backbone.stage3.0.bn.bias:weight_decay=0.0
2025/05/12 18:53:56 - mmengine - INFO - paramwise_options -- backbone.stage3.1.main_conv.bn.weight:weight_decay=0.0
2025/05/12 18:53:56 - mmengine - INFO - paramwise_options -- backbone.stage3.1.main_conv.bn.bias:weight_decay=0.0
2025/05/12 18:53:56 - mmengine - INFO - paramwise_options -- backbone.stage3.1.short_conv.bn.weight:weight_decay=0.0
2025/05/12 18:53:56 - mmengine - INFO - paramwise_options -- backbone.stage3.1.short_conv.bn.bias:weight_decay=0.0
2025/05/12 18:53:56 - mmengine - INFO - paramwise_options -- backbone.stage3.1.final_conv.bn.weight:weight_decay=0.0
2025/05/12 18:53:56 - mmengine - INFO - paramwise_options -- backbone.stage3.1.final_conv.bn.bias:weight_decay=0.0
2025/05/12 18:53:56 - mmengine - INFO - paramwise_options -- backbone.stage3.1.blocks.0.conv1.bn.weight:weight_decay=0.0
2025/05/12 18:53:56 - mmengine - INFO - paramwise_options -- backbone.stage3.1.blocks.0.conv1.bn.bias:weight_decay=0.0
2025/05/12 18:53:56 - mmengine - INFO - paramwise_options -- backbone.stage3.1.blocks.0.conv2.depthwise_conv.bn.weight:weight_decay=0.0
2025/05/12 18:53:56 - mmengine - INFO - paramwise_options -- backbone.stage3.1.blocks.0.conv2.depthwise_conv.bn.bias:weight_decay=0.0
2025/05/12 18:53:56 - mmengine - INFO - paramwise_options -- backbone.stage3.1.blocks.0.conv2.pointwise_conv.bn.weight:weight_decay=0.0
2025/05/12 18:53:56 - mmengine - INFO - paramwise_options -- backbone.stage3.1.blocks.0.conv2.pointwise_conv.bn.bias:weight_decay=0.0
2025/05/12 18:53:56 - mmengine - INFO - paramwise_options -- backbone.stage3.1.blocks.1.conv1.bn.weight:weight_decay=0.0
2025/05/12 18:53:56 - mmengine - INFO - paramwise_options -- backbone.stage3.1.blocks.1.conv1.bn.bias:weight_decay=0.0
2025/05/12 18:53:56 - mmengine - INFO - paramwise_options -- backbone.stage3.1.blocks.1.conv2.depthwise_conv.bn.weight:weight_decay=0.0
2025/05/12 18:53:56 - mmengine - INFO - paramwise_options -- backbone.stage3.1.blocks.1.conv2.depthwise_conv.bn.bias:weight_decay=0.0
2025/05/12 18:53:56 - mmengine - INFO - paramwise_options -- backbone.stage3.1.blocks.1.conv2.pointwise_conv.bn.weight:weight_decay=0.0
2025/05/12 18:53:56 - mmengine - INFO - paramwise_options -- backbone.stage3.1.blocks.1.conv2.pointwise_conv.bn.bias:weight_decay=0.0
2025/05/12 18:53:56 - mmengine - INFO - paramwise_options -- backbone.stage3.1.blocks.2.conv1.bn.weight:weight_decay=0.0
2025/05/12 18:53:56 - mmengine - INFO - paramwise_options -- backbone.stage3.1.blocks.2.conv1.bn.bias:weight_decay=0.0
2025/05/12 18:53:56 - mmengine - INFO - paramwise_options -- backbone.stage3.1.blocks.2.conv2.depthwise_conv.bn.weight:weight_decay=0.0
2025/05/12 18:53:56 - mmengine - INFO - paramwise_options -- backbone.stage3.1.blocks.2.conv2.depthwise_conv.bn.bias:weight_decay=0.0
2025/05/12 18:53:56 - mmengine - INFO - paramwise_options -- backbone.stage3.1.blocks.2.conv2.pointwise_conv.bn.weight:weight_decay=0.0
2025/05/12 18:53:56 - mmengine - INFO - paramwise_options -- backbone.stage3.1.blocks.2.conv2.pointwise_conv.bn.bias:weight_decay=0.0
2025/05/12 18:53:56 - mmengine - INFO - paramwise_options -- backbone.stage3.1.blocks.3.conv1.bn.weight:weight_decay=0.0
2025/05/12 18:53:56 - mmengine - INFO - paramwise_options -- backbone.stage3.1.blocks.3.conv1.bn.bias:weight_decay=0.0
2025/05/12 18:53:56 - mmengine - INFO - paramwise_options -- backbone.stage3.1.blocks.3.conv2.depthwise_conv.bn.weight:weight_decay=0.0
2025/05/12 18:53:56 - mmengine - INFO - paramwise_options -- backbone.stage3.1.blocks.3.conv2.depthwise_conv.bn.bias:weight_decay=0.0
2025/05/12 18:53:56 - mmengine - INFO - paramwise_options -- backbone.stage3.1.blocks.3.conv2.pointwise_conv.bn.weight:weight_decay=0.0
2025/05/12 18:53:56 - mmengine - INFO - paramwise_options -- backbone.stage3.1.blocks.3.conv2.pointwise_conv.bn.bias:weight_decay=0.0
2025/05/12 18:53:56 - mmengine - INFO - paramwise_options -- backbone.stage3.1.attention.fc.bias:weight_decay=0.0
2025/05/12 18:53:56 - mmengine - INFO - paramwise_options -- backbone.stage4.0.bn.weight:weight_decay=0.0
2025/05/12 18:53:56 - mmengine - INFO - paramwise_options -- backbone.stage4.0.bn.bias:weight_decay=0.0
2025/05/12 18:53:56 - mmengine - INFO - paramwise_options -- backbone.stage4.1.conv1.bn.weight:weight_decay=0.0
2025/05/12 18:53:56 - mmengine - INFO - paramwise_options -- backbone.stage4.1.conv1.bn.bias:weight_decay=0.0
2025/05/12 18:53:56 - mmengine - INFO - paramwise_options -- backbone.stage4.1.conv2.bn.weight:weight_decay=0.0
2025/05/12 18:53:56 - mmengine - INFO - paramwise_options -- backbone.stage4.1.conv2.bn.bias:weight_decay=0.0
2025/05/12 18:53:56 - mmengine - INFO - paramwise_options -- backbone.stage4.2.main_conv.bn.weight:weight_decay=0.0
2025/05/12 18:53:56 - mmengine - INFO - paramwise_options -- backbone.stage4.2.main_conv.bn.bias:weight_decay=0.0
2025/05/12 18:53:56 - mmengine - INFO - paramwise_options -- backbone.stage4.2.short_conv.bn.weight:weight_decay=0.0
2025/05/12 18:53:56 - mmengine - INFO - paramwise_options -- backbone.stage4.2.short_conv.bn.bias:weight_decay=0.0
2025/05/12 18:53:56 - mmengine - INFO - paramwise_options -- backbone.stage4.2.final_conv.bn.weight:weight_decay=0.0
2025/05/12 18:53:56 - mmengine - INFO - paramwise_options -- backbone.stage4.2.final_conv.bn.bias:weight_decay=0.0
2025/05/12 18:53:56 - mmengine - INFO - paramwise_options -- backbone.stage4.2.blocks.0.conv1.bn.weight:weight_decay=0.0
2025/05/12 18:53:56 - mmengine - INFO - paramwise_options -- backbone.stage4.2.blocks.0.conv1.bn.bias:weight_decay=0.0
2025/05/12 18:53:56 - mmengine - INFO - paramwise_options -- backbone.stage4.2.blocks.0.conv2.depthwise_conv.bn.weight:weight_decay=0.0
2025/05/12 18:53:56 - mmengine - INFO - paramwise_options -- backbone.stage4.2.blocks.0.conv2.depthwise_conv.bn.bias:weight_decay=0.0
2025/05/12 18:53:56 - mmengine - INFO - paramwise_options -- backbone.stage4.2.blocks.0.conv2.pointwise_conv.bn.weight:weight_decay=0.0
2025/05/12 18:53:56 - mmengine - INFO - paramwise_options -- backbone.stage4.2.blocks.0.conv2.pointwise_conv.bn.bias:weight_decay=0.0
2025/05/12 18:53:56 - mmengine - INFO - paramwise_options -- backbone.stage4.2.blocks.1.conv1.bn.weight:weight_decay=0.0
2025/05/12 18:53:56 - mmengine - INFO - paramwise_options -- backbone.stage4.2.blocks.1.conv1.bn.bias:weight_decay=0.0
2025/05/12 18:53:56 - mmengine - INFO - paramwise_options -- backbone.stage4.2.blocks.1.conv2.depthwise_conv.bn.weight:weight_decay=0.0
2025/05/12 18:53:56 - mmengine - INFO - paramwise_options -- backbone.stage4.2.blocks.1.conv2.depthwise_conv.bn.bias:weight_decay=0.0
2025/05/12 18:53:56 - mmengine - INFO - paramwise_options -- backbone.stage4.2.blocks.1.conv2.pointwise_conv.bn.weight:weight_decay=0.0
2025/05/12 18:53:56 - mmengine - INFO - paramwise_options -- backbone.stage4.2.blocks.1.conv2.pointwise_conv.bn.bias:weight_decay=0.0
2025/05/12 18:53:56 - mmengine - INFO - paramwise_options -- backbone.stage4.2.attention.fc.bias:weight_decay=0.0
2025/05/12 18:53:56 - mmengine - INFO - paramwise_options -- neck.reduce_layers.0.bn.weight:weight_decay=0.0
2025/05/12 18:53:56 - mmengine - INFO - paramwise_options -- neck.reduce_layers.0.bn.bias:weight_decay=0.0
2025/05/12 18:53:56 - mmengine - INFO - paramwise_options -- neck.reduce_layers.1.bn.weight:weight_decay=0.0
2025/05/12 18:53:56 - mmengine - INFO - paramwise_options -- neck.reduce_layers.1.bn.bias:weight_decay=0.0
2025/05/12 18:53:56 - mmengine - INFO - paramwise_options -- neck.top_down_blocks.0.main_conv.bn.weight:weight_decay=0.0
2025/05/12 18:53:56 - mmengine - INFO - paramwise_options -- neck.top_down_blocks.0.main_conv.bn.bias:weight_decay=0.0
2025/05/12 18:53:56 - mmengine - INFO - paramwise_options -- neck.top_down_blocks.0.short_conv.bn.weight:weight_decay=0.0
2025/05/12 18:53:56 - mmengine - INFO - paramwise_options -- neck.top_down_blocks.0.short_conv.bn.bias:weight_decay=0.0
2025/05/12 18:53:56 - mmengine - INFO - paramwise_options -- neck.top_down_blocks.0.final_conv.bn.weight:weight_decay=0.0
2025/05/12 18:53:56 - mmengine - INFO - paramwise_options -- neck.top_down_blocks.0.final_conv.bn.bias:weight_decay=0.0
2025/05/12 18:53:56 - mmengine - INFO - paramwise_options -- neck.top_down_blocks.0.blocks.0.conv1.bn.weight:weight_decay=0.0
2025/05/12 18:53:56 - mmengine - INFO - paramwise_options -- neck.top_down_blocks.0.blocks.0.conv1.bn.bias:weight_decay=0.0
2025/05/12 18:53:56 - mmengine - INFO - paramwise_options -- neck.top_down_blocks.0.blocks.0.conv2.depthwise_conv.bn.weight:weight_decay=0.0
2025/05/12 18:53:56 - mmengine - INFO - paramwise_options -- neck.top_down_blocks.0.blocks.0.conv2.depthwise_conv.bn.bias:weight_decay=0.0
2025/05/12 18:53:56 - mmengine - INFO - paramwise_options -- neck.top_down_blocks.0.blocks.0.conv2.pointwise_conv.bn.weight:weight_decay=0.0
2025/05/12 18:53:56 - mmengine - INFO - paramwise_options -- neck.top_down_blocks.0.blocks.0.conv2.pointwise_conv.bn.bias:weight_decay=0.0
2025/05/12 18:53:56 - mmengine - INFO - paramwise_options -- neck.top_down_blocks.0.blocks.1.conv1.bn.weight:weight_decay=0.0
2025/05/12 18:53:56 - mmengine - INFO - paramwise_options -- neck.top_down_blocks.0.blocks.1.conv1.bn.bias:weight_decay=0.0
2025/05/12 18:53:56 - mmengine - INFO - paramwise_options -- neck.top_down_blocks.0.blocks.1.conv2.depthwise_conv.bn.weight:weight_decay=0.0
2025/05/12 18:53:56 - mmengine - INFO - paramwise_options -- neck.top_down_blocks.0.blocks.1.conv2.depthwise_conv.bn.bias:weight_decay=0.0
2025/05/12 18:53:56 - mmengine - INFO - paramwise_options -- neck.top_down_blocks.0.blocks.1.conv2.pointwise_conv.bn.weight:weight_decay=0.0
2025/05/12 18:53:56 - mmengine - INFO - paramwise_options -- neck.top_down_blocks.0.blocks.1.conv2.pointwise_conv.bn.bias:weight_decay=0.0
2025/05/12 18:53:56 - mmengine - INFO - paramwise_options -- neck.top_down_blocks.1.main_conv.bn.weight:weight_decay=0.0
2025/05/12 18:53:56 - mmengine - INFO - paramwise_options -- neck.top_down_blocks.1.main_conv.bn.bias:weight_decay=0.0
2025/05/12 18:53:56 - mmengine - INFO - paramwise_options -- neck.top_down_blocks.1.short_conv.bn.weight:weight_decay=0.0
2025/05/12 18:53:56 - mmengine - INFO - paramwise_options -- neck.top_down_blocks.1.short_conv.bn.bias:weight_decay=0.0
2025/05/12 18:53:56 - mmengine - INFO - paramwise_options -- neck.top_down_blocks.1.final_conv.bn.weight:weight_decay=0.0
2025/05/12 18:53:56 - mmengine - INFO - paramwise_options -- neck.top_down_blocks.1.final_conv.bn.bias:weight_decay=0.0
2025/05/12 18:53:56 - mmengine - INFO - paramwise_options -- neck.top_down_blocks.1.blocks.0.conv1.bn.weight:weight_decay=0.0
2025/05/12 18:53:56 - mmengine - INFO - paramwise_options -- neck.top_down_blocks.1.blocks.0.conv1.bn.bias:weight_decay=0.0
2025/05/12 18:53:56 - mmengine - INFO - paramwise_options -- neck.top_down_blocks.1.blocks.0.conv2.depthwise_conv.bn.weight:weight_decay=0.0
2025/05/12 18:53:56 - mmengine - INFO - paramwise_options -- neck.top_down_blocks.1.blocks.0.conv2.depthwise_conv.bn.bias:weight_decay=0.0
2025/05/12 18:53:56 - mmengine - INFO - paramwise_options -- neck.top_down_blocks.1.blocks.0.conv2.pointwise_conv.bn.weight:weight_decay=0.0
2025/05/12 18:53:56 - mmengine - INFO - paramwise_options -- neck.top_down_blocks.1.blocks.0.conv2.pointwise_conv.bn.bias:weight_decay=0.0
2025/05/12 18:53:56 - mmengine - INFO - paramwise_options -- neck.top_down_blocks.1.blocks.1.conv1.bn.weight:weight_decay=0.0
2025/05/12 18:53:56 - mmengine - INFO - paramwise_options -- neck.top_down_blocks.1.blocks.1.conv1.bn.bias:weight_decay=0.0
2025/05/12 18:53:56 - mmengine - INFO - paramwise_options -- neck.top_down_blocks.1.blocks.1.conv2.depthwise_conv.bn.weight:weight_decay=0.0
2025/05/12 18:53:56 - mmengine - INFO - paramwise_options -- neck.top_down_blocks.1.blocks.1.conv2.depthwise_conv.bn.bias:weight_decay=0.0
2025/05/12 18:53:56 - mmengine - INFO - paramwise_options -- neck.top_down_blocks.1.blocks.1.conv2.pointwise_conv.bn.weight:weight_decay=0.0
2025/05/12 18:53:56 - mmengine - INFO - paramwise_options -- neck.top_down_blocks.1.blocks.1.conv2.pointwise_conv.bn.bias:weight_decay=0.0
2025/05/12 18:53:56 - mmengine - INFO - paramwise_options -- neck.downsamples.0.bn.weight:weight_decay=0.0
2025/05/12 18:53:56 - mmengine - INFO - paramwise_options -- neck.downsamples.0.bn.bias:weight_decay=0.0
2025/05/12 18:53:56 - mmengine - INFO - paramwise_options -- neck.downsamples.1.bn.weight:weight_decay=0.0
2025/05/12 18:53:56 - mmengine - INFO - paramwise_options -- neck.downsamples.1.bn.bias:weight_decay=0.0
2025/05/12 18:53:56 - mmengine - INFO - paramwise_options -- neck.bottom_up_blocks.0.main_conv.bn.weight:weight_decay=0.0
2025/05/12 18:53:56 - mmengine - INFO - paramwise_options -- neck.bottom_up_blocks.0.main_conv.bn.bias:weight_decay=0.0
2025/05/12 18:53:56 - mmengine - INFO - paramwise_options -- neck.bottom_up_blocks.0.short_conv.bn.weight:weight_decay=0.0
2025/05/12 18:53:56 - mmengine - INFO - paramwise_options -- neck.bottom_up_blocks.0.short_conv.bn.bias:weight_decay=0.0
2025/05/12 18:53:56 - mmengine - INFO - paramwise_options -- neck.bottom_up_blocks.0.final_conv.bn.weight:weight_decay=0.0
2025/05/12 18:53:56 - mmengine - INFO - paramwise_options -- neck.bottom_up_blocks.0.final_conv.bn.bias:weight_decay=0.0
2025/05/12 18:53:56 - mmengine - INFO - paramwise_options -- neck.bottom_up_blocks.0.blocks.0.conv1.bn.weight:weight_decay=0.0
2025/05/12 18:53:56 - mmengine - INFO - paramwise_options -- neck.bottom_up_blocks.0.blocks.0.conv1.bn.bias:weight_decay=0.0
2025/05/12 18:53:56 - mmengine - INFO - paramwise_options -- neck.bottom_up_blocks.0.blocks.0.conv2.depthwise_conv.bn.weight:weight_decay=0.0
2025/05/12 18:53:56 - mmengine - INFO - paramwise_options -- neck.bottom_up_blocks.0.blocks.0.conv2.depthwise_conv.bn.bias:weight_decay=0.0
2025/05/12 18:53:56 - mmengine - INFO - paramwise_options -- neck.bottom_up_blocks.0.blocks.0.conv2.pointwise_conv.bn.weight:weight_decay=0.0
2025/05/12 18:53:56 - mmengine - INFO - paramwise_options -- neck.bottom_up_blocks.0.blocks.0.conv2.pointwise_conv.bn.bias:weight_decay=0.0
2025/05/12 18:53:56 - mmengine - INFO - paramwise_options -- neck.bottom_up_blocks.0.blocks.1.conv1.bn.weight:weight_decay=0.0
2025/05/12 18:53:56 - mmengine - INFO - paramwise_options -- neck.bottom_up_blocks.0.blocks.1.conv1.bn.bias:weight_decay=0.0
2025/05/12 18:53:56 - mmengine - INFO - paramwise_options -- neck.bottom_up_blocks.0.blocks.1.conv2.depthwise_conv.bn.weight:weight_decay=0.0
2025/05/12 18:53:56 - mmengine - INFO - paramwise_options -- neck.bottom_up_blocks.0.blocks.1.conv2.depthwise_conv.bn.bias:weight_decay=0.0
2025/05/12 18:53:56 - mmengine - INFO - paramwise_options -- neck.bottom_up_blocks.0.blocks.1.conv2.pointwise_conv.bn.weight:weight_decay=0.0
2025/05/12 18:53:56 - mmengine - INFO - paramwise_options -- neck.bottom_up_blocks.0.blocks.1.conv2.pointwise_conv.bn.bias:weight_decay=0.0
2025/05/12 18:53:56 - mmengine - INFO - paramwise_options -- neck.bottom_up_blocks.1.main_conv.bn.weight:weight_decay=0.0
2025/05/12 18:53:56 - mmengine - INFO - paramwise_options -- neck.bottom_up_blocks.1.main_conv.bn.bias:weight_decay=0.0
2025/05/12 18:53:56 - mmengine - INFO - paramwise_options -- neck.bottom_up_blocks.1.short_conv.bn.weight:weight_decay=0.0
2025/05/12 18:53:56 - mmengine - INFO - paramwise_options -- neck.bottom_up_blocks.1.short_conv.bn.bias:weight_decay=0.0
2025/05/12 18:53:56 - mmengine - INFO - paramwise_options -- neck.bottom_up_blocks.1.final_conv.bn.weight:weight_decay=0.0
2025/05/12 18:53:56 - mmengine - INFO - paramwise_options -- neck.bottom_up_blocks.1.final_conv.bn.bias:weight_decay=0.0
2025/05/12 18:53:56 - mmengine - INFO - paramwise_options -- neck.bottom_up_blocks.1.blocks.0.conv1.bn.weight:weight_decay=0.0
2025/05/12 18:53:56 - mmengine - INFO - paramwise_options -- neck.bottom_up_blocks.1.blocks.0.conv1.bn.bias:weight_decay=0.0
2025/05/12 18:53:56 - mmengine - INFO - paramwise_options -- neck.bottom_up_blocks.1.blocks.0.conv2.depthwise_conv.bn.weight:weight_decay=0.0
2025/05/12 18:53:56 - mmengine - INFO - paramwise_options -- neck.bottom_up_blocks.1.blocks.0.conv2.depthwise_conv.bn.bias:weight_decay=0.0
2025/05/12 18:53:56 - mmengine - INFO - paramwise_options -- neck.bottom_up_blocks.1.blocks.0.conv2.pointwise_conv.bn.weight:weight_decay=0.0
2025/05/12 18:53:56 - mmengine - INFO - paramwise_options -- neck.bottom_up_blocks.1.blocks.0.conv2.pointwise_conv.bn.bias:weight_decay=0.0
2025/05/12 18:53:56 - mmengine - INFO - paramwise_options -- neck.bottom_up_blocks.1.blocks.1.conv1.bn.weight:weight_decay=0.0
2025/05/12 18:53:56 - mmengine - INFO - paramwise_options -- neck.bottom_up_blocks.1.blocks.1.conv1.bn.bias:weight_decay=0.0
2025/05/12 18:53:56 - mmengine - INFO - paramwise_options -- neck.bottom_up_blocks.1.blocks.1.conv2.depthwise_conv.bn.weight:weight_decay=0.0
2025/05/12 18:53:56 - mmengine - INFO - paramwise_options -- neck.bottom_up_blocks.1.blocks.1.conv2.depthwise_conv.bn.bias:weight_decay=0.0
2025/05/12 18:53:56 - mmengine - INFO - paramwise_options -- neck.bottom_up_blocks.1.blocks.1.conv2.pointwise_conv.bn.weight:weight_decay=0.0
2025/05/12 18:53:56 - mmengine - INFO - paramwise_options -- neck.bottom_up_blocks.1.blocks.1.conv2.pointwise_conv.bn.bias:weight_decay=0.0
2025/05/12 18:53:56 - mmengine - INFO - paramwise_options -- neck.out_convs.0.bn.weight:weight_decay=0.0
2025/05/12 18:53:56 - mmengine - INFO - paramwise_options -- neck.out_convs.0.bn.bias:weight_decay=0.0
2025/05/12 18:53:56 - mmengine - INFO - paramwise_options -- neck.out_convs.1.bn.weight:weight_decay=0.0
2025/05/12 18:53:56 - mmengine - INFO - paramwise_options -- neck.out_convs.1.bn.bias:weight_decay=0.0
2025/05/12 18:53:56 - mmengine - INFO - paramwise_options -- neck.out_convs.2.bn.weight:weight_decay=0.0
2025/05/12 18:53:56 - mmengine - INFO - paramwise_options -- neck.out_convs.2.bn.bias:weight_decay=0.0
2025/05/12 18:53:56 - mmengine - INFO - paramwise_options -- bbox_head.cls_convs.0.0.bn.weight:weight_decay=0.0
2025/05/12 18:53:56 - mmengine - INFO - paramwise_options -- bbox_head.cls_convs.0.0.bn.bias:weight_decay=0.0
2025/05/12 18:53:56 - mmengine - INFO - paramwise_options -- bbox_head.cls_convs.0.1.bn.weight:weight_decay=0.0
2025/05/12 18:53:56 - mmengine - INFO - paramwise_options -- bbox_head.cls_convs.0.1.bn.bias:weight_decay=0.0
2025/05/12 18:53:56 - mmengine - WARNING - bbox_head.cls_convs.1.0.conv is duplicate. It is skipped since bypass_duplicate=True
2025/05/12 18:53:56 - mmengine - INFO - paramwise_options -- bbox_head.cls_convs.1.0.bn.weight:weight_decay=0.0
2025/05/12 18:53:56 - mmengine - INFO - paramwise_options -- bbox_head.cls_convs.1.0.bn.bias:weight_decay=0.0
2025/05/12 18:53:56 - mmengine - WARNING - bbox_head.cls_convs.1.1.conv is duplicate. It is skipped since bypass_duplicate=True
2025/05/12 18:53:56 - mmengine - INFO - paramwise_options -- bbox_head.cls_convs.1.1.bn.weight:weight_decay=0.0
2025/05/12 18:53:56 - mmengine - INFO - paramwise_options -- bbox_head.cls_convs.1.1.bn.bias:weight_decay=0.0
2025/05/12 18:53:56 - mmengine - WARNING - bbox_head.cls_convs.2.0.conv is duplicate. It is skipped since bypass_duplicate=True
2025/05/12 18:53:56 - mmengine - INFO - paramwise_options -- bbox_head.cls_convs.2.0.bn.weight:weight_decay=0.0
2025/05/12 18:53:56 - mmengine - INFO - paramwise_options -- bbox_head.cls_convs.2.0.bn.bias:weight_decay=0.0
2025/05/12 18:53:56 - mmengine - WARNING - bbox_head.cls_convs.2.1.conv is duplicate. It is skipped since bypass_duplicate=True
2025/05/12 18:53:56 - mmengine - INFO - paramwise_options -- bbox_head.cls_convs.2.1.bn.weight:weight_decay=0.0
2025/05/12 18:53:56 - mmengine - INFO - paramwise_options -- bbox_head.cls_convs.2.1.bn.bias:weight_decay=0.0
2025/05/12 18:53:56 - mmengine - INFO - paramwise_options -- bbox_head.reg_convs.0.0.bn.weight:weight_decay=0.0
2025/05/12 18:53:56 - mmengine - INFO - paramwise_options -- bbox_head.reg_convs.0.0.bn.bias:weight_decay=0.0
2025/05/12 18:53:56 - mmengine - INFO - paramwise_options -- bbox_head.reg_convs.0.1.bn.weight:weight_decay=0.0
2025/05/12 18:53:56 - mmengine - INFO - paramwise_options -- bbox_head.reg_convs.0.1.bn.bias:weight_decay=0.0
2025/05/12 18:53:56 - mmengine - WARNING - bbox_head.reg_convs.1.0.conv is duplicate. It is skipped since bypass_duplicate=True
2025/05/12 18:53:56 - mmengine - INFO - paramwise_options -- bbox_head.reg_convs.1.0.bn.weight:weight_decay=0.0
2025/05/12 18:53:56 - mmengine - INFO - paramwise_options -- bbox_head.reg_convs.1.0.bn.bias:weight_decay=0.0
2025/05/12 18:53:56 - mmengine - WARNING - bbox_head.reg_convs.1.1.conv is duplicate. It is skipped since bypass_duplicate=True
2025/05/12 18:53:56 - mmengine - INFO - paramwise_options -- bbox_head.reg_convs.1.1.bn.weight:weight_decay=0.0
2025/05/12 18:53:56 - mmengine - INFO - paramwise_options -- bbox_head.reg_convs.1.1.bn.bias:weight_decay=0.0
2025/05/12 18:53:56 - mmengine - WARNING - bbox_head.reg_convs.2.0.conv is duplicate. It is skipped since bypass_duplicate=True
2025/05/12 18:53:56 - mmengine - INFO - paramwise_options -- bbox_head.reg_convs.2.0.bn.weight:weight_decay=0.0
2025/05/12 18:53:56 - mmengine - INFO - paramwise_options -- bbox_head.reg_convs.2.0.bn.bias:weight_decay=0.0
2025/05/12 18:53:56 - mmengine - WARNING - bbox_head.reg_convs.2.1.conv is duplicate. It is skipped since bypass_duplicate=True
2025/05/12 18:53:56 - mmengine - INFO - paramwise_options -- bbox_head.reg_convs.2.1.bn.weight:weight_decay=0.0
2025/05/12 18:53:56 - mmengine - INFO - paramwise_options -- bbox_head.reg_convs.2.1.bn.bias:weight_decay=0.0
2025/05/12 18:53:56 - mmengine - INFO - paramwise_options -- bbox_head.rtm_cls.0.bias:weight_decay=0.0
2025/05/12 18:53:56 - mmengine - INFO - paramwise_options -- bbox_head.rtm_cls.1.bias:weight_decay=0.0
2025/05/12 18:53:56 - mmengine - INFO - paramwise_options -- bbox_head.rtm_cls.2.bias:weight_decay=0.0
2025/05/12 18:53:56 - mmengine - INFO - paramwise_options -- bbox_head.rtm_reg.0.bias:weight_decay=0.0
2025/05/12 18:53:56 - mmengine - INFO - paramwise_options -- bbox_head.rtm_reg.1.bias:weight_decay=0.0
2025/05/12 18:53:56 - mmengine - INFO - paramwise_options -- bbox_head.rtm_reg.2.bias:weight_decay=0.0
Name of parameter - Initialization information

backbone.stem.0.conv.weight - torch.Size([24, 3, 3, 3]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stem.0.bn.weight - torch.Size([24]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stem.0.bn.bias - torch.Size([24]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stem.1.conv.weight - torch.Size([24, 24, 3, 3]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stem.1.bn.weight - torch.Size([24]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stem.1.bn.bias - torch.Size([24]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stem.2.conv.weight - torch.Size([48, 24, 3, 3]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stem.2.bn.weight - torch.Size([48]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stem.2.bn.bias - torch.Size([48]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage1.0.conv.weight - torch.Size([96, 48, 3, 3]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage1.0.bn.weight - torch.Size([96]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage1.0.bn.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage1.1.main_conv.conv.weight - torch.Size([48, 96, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage1.1.main_conv.bn.weight - torch.Size([48]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage1.1.main_conv.bn.bias - torch.Size([48]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage1.1.short_conv.conv.weight - torch.Size([48, 96, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage1.1.short_conv.bn.weight - torch.Size([48]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage1.1.short_conv.bn.bias - torch.Size([48]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage1.1.final_conv.conv.weight - torch.Size([96, 96, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage1.1.final_conv.bn.weight - torch.Size([96]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage1.1.final_conv.bn.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage1.1.blocks.0.conv1.conv.weight - torch.Size([48, 48, 3, 3]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage1.1.blocks.0.conv1.bn.weight - torch.Size([48]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage1.1.blocks.0.conv1.bn.bias - torch.Size([48]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage1.1.blocks.0.conv2.depthwise_conv.conv.weight - torch.Size([48, 1, 5, 5]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage1.1.blocks.0.conv2.depthwise_conv.bn.weight - torch.Size([48]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage1.1.blocks.0.conv2.depthwise_conv.bn.bias - torch.Size([48]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage1.1.blocks.0.conv2.pointwise_conv.conv.weight - torch.Size([48, 48, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage1.1.blocks.0.conv2.pointwise_conv.bn.weight - torch.Size([48]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage1.1.blocks.0.conv2.pointwise_conv.bn.bias - torch.Size([48]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage1.1.blocks.1.conv1.conv.weight - torch.Size([48, 48, 3, 3]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage1.1.blocks.1.conv1.bn.weight - torch.Size([48]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage1.1.blocks.1.conv1.bn.bias - torch.Size([48]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage1.1.blocks.1.conv2.depthwise_conv.conv.weight - torch.Size([48, 1, 5, 5]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage1.1.blocks.1.conv2.depthwise_conv.bn.weight - torch.Size([48]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage1.1.blocks.1.conv2.depthwise_conv.bn.bias - torch.Size([48]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage1.1.blocks.1.conv2.pointwise_conv.conv.weight - torch.Size([48, 48, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage1.1.blocks.1.conv2.pointwise_conv.bn.weight - torch.Size([48]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage1.1.blocks.1.conv2.pointwise_conv.bn.bias - torch.Size([48]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage1.1.attention.fc.weight - torch.Size([96, 96, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage1.1.attention.fc.bias - torch.Size([96]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage2.0.conv.weight - torch.Size([192, 96, 3, 3]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage2.0.bn.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage2.0.bn.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage2.1.main_conv.conv.weight - torch.Size([96, 192, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage2.1.main_conv.bn.weight - torch.Size([96]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage2.1.main_conv.bn.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage2.1.short_conv.conv.weight - torch.Size([96, 192, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage2.1.short_conv.bn.weight - torch.Size([96]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage2.1.short_conv.bn.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage2.1.final_conv.conv.weight - torch.Size([192, 192, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage2.1.final_conv.bn.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage2.1.final_conv.bn.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage2.1.blocks.0.conv1.conv.weight - torch.Size([96, 96, 3, 3]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage2.1.blocks.0.conv1.bn.weight - torch.Size([96]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage2.1.blocks.0.conv1.bn.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage2.1.blocks.0.conv2.depthwise_conv.conv.weight - torch.Size([96, 1, 5, 5]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage2.1.blocks.0.conv2.depthwise_conv.bn.weight - torch.Size([96]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage2.1.blocks.0.conv2.depthwise_conv.bn.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage2.1.blocks.0.conv2.pointwise_conv.conv.weight - torch.Size([96, 96, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage2.1.blocks.0.conv2.pointwise_conv.bn.weight - torch.Size([96]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage2.1.blocks.0.conv2.pointwise_conv.bn.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage2.1.blocks.1.conv1.conv.weight - torch.Size([96, 96, 3, 3]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage2.1.blocks.1.conv1.bn.weight - torch.Size([96]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage2.1.blocks.1.conv1.bn.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage2.1.blocks.1.conv2.depthwise_conv.conv.weight - torch.Size([96, 1, 5, 5]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage2.1.blocks.1.conv2.depthwise_conv.bn.weight - torch.Size([96]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage2.1.blocks.1.conv2.depthwise_conv.bn.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage2.1.blocks.1.conv2.pointwise_conv.conv.weight - torch.Size([96, 96, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage2.1.blocks.1.conv2.pointwise_conv.bn.weight - torch.Size([96]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage2.1.blocks.1.conv2.pointwise_conv.bn.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage2.1.blocks.2.conv1.conv.weight - torch.Size([96, 96, 3, 3]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage2.1.blocks.2.conv1.bn.weight - torch.Size([96]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage2.1.blocks.2.conv1.bn.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage2.1.blocks.2.conv2.depthwise_conv.conv.weight - torch.Size([96, 1, 5, 5]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage2.1.blocks.2.conv2.depthwise_conv.bn.weight - torch.Size([96]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage2.1.blocks.2.conv2.depthwise_conv.bn.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage2.1.blocks.2.conv2.pointwise_conv.conv.weight - torch.Size([96, 96, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage2.1.blocks.2.conv2.pointwise_conv.bn.weight - torch.Size([96]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage2.1.blocks.2.conv2.pointwise_conv.bn.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage2.1.blocks.3.conv1.conv.weight - torch.Size([96, 96, 3, 3]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage2.1.blocks.3.conv1.bn.weight - torch.Size([96]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage2.1.blocks.3.conv1.bn.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage2.1.blocks.3.conv2.depthwise_conv.conv.weight - torch.Size([96, 1, 5, 5]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage2.1.blocks.3.conv2.depthwise_conv.bn.weight - torch.Size([96]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage2.1.blocks.3.conv2.depthwise_conv.bn.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage2.1.blocks.3.conv2.pointwise_conv.conv.weight - torch.Size([96, 96, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage2.1.blocks.3.conv2.pointwise_conv.bn.weight - torch.Size([96]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage2.1.blocks.3.conv2.pointwise_conv.bn.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage2.1.attention.fc.weight - torch.Size([192, 192, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage2.1.attention.fc.bias - torch.Size([192]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage3.0.conv.weight - torch.Size([384, 192, 3, 3]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage3.0.bn.weight - torch.Size([384]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage3.0.bn.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage3.1.main_conv.conv.weight - torch.Size([192, 384, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage3.1.main_conv.bn.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage3.1.main_conv.bn.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage3.1.short_conv.conv.weight - torch.Size([192, 384, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage3.1.short_conv.bn.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage3.1.short_conv.bn.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage3.1.final_conv.conv.weight - torch.Size([384, 384, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage3.1.final_conv.bn.weight - torch.Size([384]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage3.1.final_conv.bn.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage3.1.blocks.0.conv1.conv.weight - torch.Size([192, 192, 3, 3]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage3.1.blocks.0.conv1.bn.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage3.1.blocks.0.conv1.bn.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage3.1.blocks.0.conv2.depthwise_conv.conv.weight - torch.Size([192, 1, 5, 5]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage3.1.blocks.0.conv2.depthwise_conv.bn.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage3.1.blocks.0.conv2.depthwise_conv.bn.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage3.1.blocks.0.conv2.pointwise_conv.conv.weight - torch.Size([192, 192, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage3.1.blocks.0.conv2.pointwise_conv.bn.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage3.1.blocks.0.conv2.pointwise_conv.bn.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage3.1.blocks.1.conv1.conv.weight - torch.Size([192, 192, 3, 3]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage3.1.blocks.1.conv1.bn.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage3.1.blocks.1.conv1.bn.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage3.1.blocks.1.conv2.depthwise_conv.conv.weight - torch.Size([192, 1, 5, 5]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage3.1.blocks.1.conv2.depthwise_conv.bn.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage3.1.blocks.1.conv2.depthwise_conv.bn.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage3.1.blocks.1.conv2.pointwise_conv.conv.weight - torch.Size([192, 192, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage3.1.blocks.1.conv2.pointwise_conv.bn.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage3.1.blocks.1.conv2.pointwise_conv.bn.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage3.1.blocks.2.conv1.conv.weight - torch.Size([192, 192, 3, 3]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage3.1.blocks.2.conv1.bn.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage3.1.blocks.2.conv1.bn.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage3.1.blocks.2.conv2.depthwise_conv.conv.weight - torch.Size([192, 1, 5, 5]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage3.1.blocks.2.conv2.depthwise_conv.bn.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage3.1.blocks.2.conv2.depthwise_conv.bn.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage3.1.blocks.2.conv2.pointwise_conv.conv.weight - torch.Size([192, 192, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage3.1.blocks.2.conv2.pointwise_conv.bn.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage3.1.blocks.2.conv2.pointwise_conv.bn.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage3.1.blocks.3.conv1.conv.weight - torch.Size([192, 192, 3, 3]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage3.1.blocks.3.conv1.bn.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage3.1.blocks.3.conv1.bn.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage3.1.blocks.3.conv2.depthwise_conv.conv.weight - torch.Size([192, 1, 5, 5]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage3.1.blocks.3.conv2.depthwise_conv.bn.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage3.1.blocks.3.conv2.depthwise_conv.bn.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage3.1.blocks.3.conv2.pointwise_conv.conv.weight - torch.Size([192, 192, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage3.1.blocks.3.conv2.pointwise_conv.bn.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage3.1.blocks.3.conv2.pointwise_conv.bn.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage3.1.attention.fc.weight - torch.Size([384, 384, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage3.1.attention.fc.bias - torch.Size([384]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage4.0.conv.weight - torch.Size([768, 384, 3, 3]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage4.0.bn.weight - torch.Size([768]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage4.0.bn.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage4.1.conv1.conv.weight - torch.Size([384, 768, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage4.1.conv1.bn.weight - torch.Size([384]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage4.1.conv1.bn.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage4.1.conv2.conv.weight - torch.Size([768, 1536, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage4.1.conv2.bn.weight - torch.Size([768]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage4.1.conv2.bn.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage4.2.main_conv.conv.weight - torch.Size([384, 768, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage4.2.main_conv.bn.weight - torch.Size([384]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage4.2.main_conv.bn.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage4.2.short_conv.conv.weight - torch.Size([384, 768, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage4.2.short_conv.bn.weight - torch.Size([384]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage4.2.short_conv.bn.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage4.2.final_conv.conv.weight - torch.Size([768, 768, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage4.2.final_conv.bn.weight - torch.Size([768]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage4.2.final_conv.bn.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage4.2.blocks.0.conv1.conv.weight - torch.Size([384, 384, 3, 3]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage4.2.blocks.0.conv1.bn.weight - torch.Size([384]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage4.2.blocks.0.conv1.bn.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage4.2.blocks.0.conv2.depthwise_conv.conv.weight - torch.Size([384, 1, 5, 5]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage4.2.blocks.0.conv2.depthwise_conv.bn.weight - torch.Size([384]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage4.2.blocks.0.conv2.depthwise_conv.bn.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage4.2.blocks.0.conv2.pointwise_conv.conv.weight - torch.Size([384, 384, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage4.2.blocks.0.conv2.pointwise_conv.bn.weight - torch.Size([384]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage4.2.blocks.0.conv2.pointwise_conv.bn.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage4.2.blocks.1.conv1.conv.weight - torch.Size([384, 384, 3, 3]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage4.2.blocks.1.conv1.bn.weight - torch.Size([384]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage4.2.blocks.1.conv1.bn.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage4.2.blocks.1.conv2.depthwise_conv.conv.weight - torch.Size([384, 1, 5, 5]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage4.2.blocks.1.conv2.depthwise_conv.bn.weight - torch.Size([384]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage4.2.blocks.1.conv2.depthwise_conv.bn.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage4.2.blocks.1.conv2.pointwise_conv.conv.weight - torch.Size([384, 384, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage4.2.blocks.1.conv2.pointwise_conv.bn.weight - torch.Size([384]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage4.2.blocks.1.conv2.pointwise_conv.bn.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage4.2.attention.fc.weight - torch.Size([768, 768, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage4.2.attention.fc.bias - torch.Size([768]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

neck.reduce_layers.0.conv.weight - torch.Size([384, 768, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

neck.reduce_layers.0.bn.weight - torch.Size([384]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.reduce_layers.0.bn.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.reduce_layers.1.conv.weight - torch.Size([192, 384, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

neck.reduce_layers.1.bn.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.reduce_layers.1.bn.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.top_down_blocks.0.main_conv.conv.weight - torch.Size([192, 768, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

neck.top_down_blocks.0.main_conv.bn.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.top_down_blocks.0.main_conv.bn.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.top_down_blocks.0.short_conv.conv.weight - torch.Size([192, 768, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

neck.top_down_blocks.0.short_conv.bn.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.top_down_blocks.0.short_conv.bn.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.top_down_blocks.0.final_conv.conv.weight - torch.Size([384, 384, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

neck.top_down_blocks.0.final_conv.bn.weight - torch.Size([384]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.top_down_blocks.0.final_conv.bn.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.top_down_blocks.0.blocks.0.conv1.conv.weight - torch.Size([192, 192, 3, 3]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

neck.top_down_blocks.0.blocks.0.conv1.bn.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.top_down_blocks.0.blocks.0.conv1.bn.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.top_down_blocks.0.blocks.0.conv2.depthwise_conv.conv.weight - torch.Size([192, 1, 5, 5]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

neck.top_down_blocks.0.blocks.0.conv2.depthwise_conv.bn.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.top_down_blocks.0.blocks.0.conv2.depthwise_conv.bn.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.top_down_blocks.0.blocks.0.conv2.pointwise_conv.conv.weight - torch.Size([192, 192, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

neck.top_down_blocks.0.blocks.0.conv2.pointwise_conv.bn.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.top_down_blocks.0.blocks.0.conv2.pointwise_conv.bn.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.top_down_blocks.0.blocks.1.conv1.conv.weight - torch.Size([192, 192, 3, 3]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

neck.top_down_blocks.0.blocks.1.conv1.bn.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.top_down_blocks.0.blocks.1.conv1.bn.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.top_down_blocks.0.blocks.1.conv2.depthwise_conv.conv.weight - torch.Size([192, 1, 5, 5]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

neck.top_down_blocks.0.blocks.1.conv2.depthwise_conv.bn.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.top_down_blocks.0.blocks.1.conv2.depthwise_conv.bn.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.top_down_blocks.0.blocks.1.conv2.pointwise_conv.conv.weight - torch.Size([192, 192, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

neck.top_down_blocks.0.blocks.1.conv2.pointwise_conv.bn.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.top_down_blocks.0.blocks.1.conv2.pointwise_conv.bn.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.top_down_blocks.1.main_conv.conv.weight - torch.Size([96, 384, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

neck.top_down_blocks.1.main_conv.bn.weight - torch.Size([96]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.top_down_blocks.1.main_conv.bn.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.top_down_blocks.1.short_conv.conv.weight - torch.Size([96, 384, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

neck.top_down_blocks.1.short_conv.bn.weight - torch.Size([96]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.top_down_blocks.1.short_conv.bn.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.top_down_blocks.1.final_conv.conv.weight - torch.Size([192, 192, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

neck.top_down_blocks.1.final_conv.bn.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.top_down_blocks.1.final_conv.bn.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.top_down_blocks.1.blocks.0.conv1.conv.weight - torch.Size([96, 96, 3, 3]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

neck.top_down_blocks.1.blocks.0.conv1.bn.weight - torch.Size([96]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.top_down_blocks.1.blocks.0.conv1.bn.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.top_down_blocks.1.blocks.0.conv2.depthwise_conv.conv.weight - torch.Size([96, 1, 5, 5]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

neck.top_down_blocks.1.blocks.0.conv2.depthwise_conv.bn.weight - torch.Size([96]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.top_down_blocks.1.blocks.0.conv2.depthwise_conv.bn.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.top_down_blocks.1.blocks.0.conv2.pointwise_conv.conv.weight - torch.Size([96, 96, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

neck.top_down_blocks.1.blocks.0.conv2.pointwise_conv.bn.weight - torch.Size([96]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.top_down_blocks.1.blocks.0.conv2.pointwise_conv.bn.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.top_down_blocks.1.blocks.1.conv1.conv.weight - torch.Size([96, 96, 3, 3]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

neck.top_down_blocks.1.blocks.1.conv1.bn.weight - torch.Size([96]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.top_down_blocks.1.blocks.1.conv1.bn.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.top_down_blocks.1.blocks.1.conv2.depthwise_conv.conv.weight - torch.Size([96, 1, 5, 5]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

neck.top_down_blocks.1.blocks.1.conv2.depthwise_conv.bn.weight - torch.Size([96]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.top_down_blocks.1.blocks.1.conv2.depthwise_conv.bn.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.top_down_blocks.1.blocks.1.conv2.pointwise_conv.conv.weight - torch.Size([96, 96, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

neck.top_down_blocks.1.blocks.1.conv2.pointwise_conv.bn.weight - torch.Size([96]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.top_down_blocks.1.blocks.1.conv2.pointwise_conv.bn.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.downsamples.0.conv.weight - torch.Size([192, 192, 3, 3]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

neck.downsamples.0.bn.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.downsamples.0.bn.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.downsamples.1.conv.weight - torch.Size([384, 384, 3, 3]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

neck.downsamples.1.bn.weight - torch.Size([384]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.downsamples.1.bn.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.bottom_up_blocks.0.main_conv.conv.weight - torch.Size([192, 384, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

neck.bottom_up_blocks.0.main_conv.bn.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.bottom_up_blocks.0.main_conv.bn.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.bottom_up_blocks.0.short_conv.conv.weight - torch.Size([192, 384, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

neck.bottom_up_blocks.0.short_conv.bn.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.bottom_up_blocks.0.short_conv.bn.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.bottom_up_blocks.0.final_conv.conv.weight - torch.Size([384, 384, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

neck.bottom_up_blocks.0.final_conv.bn.weight - torch.Size([384]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.bottom_up_blocks.0.final_conv.bn.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.bottom_up_blocks.0.blocks.0.conv1.conv.weight - torch.Size([192, 192, 3, 3]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

neck.bottom_up_blocks.0.blocks.0.conv1.bn.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.bottom_up_blocks.0.blocks.0.conv1.bn.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.bottom_up_blocks.0.blocks.0.conv2.depthwise_conv.conv.weight - torch.Size([192, 1, 5, 5]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

neck.bottom_up_blocks.0.blocks.0.conv2.depthwise_conv.bn.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.bottom_up_blocks.0.blocks.0.conv2.depthwise_conv.bn.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.bottom_up_blocks.0.blocks.0.conv2.pointwise_conv.conv.weight - torch.Size([192, 192, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

neck.bottom_up_blocks.0.blocks.0.conv2.pointwise_conv.bn.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.bottom_up_blocks.0.blocks.0.conv2.pointwise_conv.bn.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.bottom_up_blocks.0.blocks.1.conv1.conv.weight - torch.Size([192, 192, 3, 3]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

neck.bottom_up_blocks.0.blocks.1.conv1.bn.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.bottom_up_blocks.0.blocks.1.conv1.bn.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.bottom_up_blocks.0.blocks.1.conv2.depthwise_conv.conv.weight - torch.Size([192, 1, 5, 5]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

neck.bottom_up_blocks.0.blocks.1.conv2.depthwise_conv.bn.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.bottom_up_blocks.0.blocks.1.conv2.depthwise_conv.bn.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.bottom_up_blocks.0.blocks.1.conv2.pointwise_conv.conv.weight - torch.Size([192, 192, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

neck.bottom_up_blocks.0.blocks.1.conv2.pointwise_conv.bn.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.bottom_up_blocks.0.blocks.1.conv2.pointwise_conv.bn.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.bottom_up_blocks.1.main_conv.conv.weight - torch.Size([384, 768, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

neck.bottom_up_blocks.1.main_conv.bn.weight - torch.Size([384]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.bottom_up_blocks.1.main_conv.bn.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.bottom_up_blocks.1.short_conv.conv.weight - torch.Size([384, 768, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

neck.bottom_up_blocks.1.short_conv.bn.weight - torch.Size([384]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.bottom_up_blocks.1.short_conv.bn.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.bottom_up_blocks.1.final_conv.conv.weight - torch.Size([768, 768, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

neck.bottom_up_blocks.1.final_conv.bn.weight - torch.Size([768]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.bottom_up_blocks.1.final_conv.bn.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.bottom_up_blocks.1.blocks.0.conv1.conv.weight - torch.Size([384, 384, 3, 3]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

neck.bottom_up_blocks.1.blocks.0.conv1.bn.weight - torch.Size([384]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.bottom_up_blocks.1.blocks.0.conv1.bn.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.bottom_up_blocks.1.blocks.0.conv2.depthwise_conv.conv.weight - torch.Size([384, 1, 5, 5]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

neck.bottom_up_blocks.1.blocks.0.conv2.depthwise_conv.bn.weight - torch.Size([384]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.bottom_up_blocks.1.blocks.0.conv2.depthwise_conv.bn.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.bottom_up_blocks.1.blocks.0.conv2.pointwise_conv.conv.weight - torch.Size([384, 384, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

neck.bottom_up_blocks.1.blocks.0.conv2.pointwise_conv.bn.weight - torch.Size([384]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.bottom_up_blocks.1.blocks.0.conv2.pointwise_conv.bn.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.bottom_up_blocks.1.blocks.1.conv1.conv.weight - torch.Size([384, 384, 3, 3]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

neck.bottom_up_blocks.1.blocks.1.conv1.bn.weight - torch.Size([384]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.bottom_up_blocks.1.blocks.1.conv1.bn.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.bottom_up_blocks.1.blocks.1.conv2.depthwise_conv.conv.weight - torch.Size([384, 1, 5, 5]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

neck.bottom_up_blocks.1.blocks.1.conv2.depthwise_conv.bn.weight - torch.Size([384]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.bottom_up_blocks.1.blocks.1.conv2.depthwise_conv.bn.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.bottom_up_blocks.1.blocks.1.conv2.pointwise_conv.conv.weight - torch.Size([384, 384, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

neck.bottom_up_blocks.1.blocks.1.conv2.pointwise_conv.bn.weight - torch.Size([384]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.bottom_up_blocks.1.blocks.1.conv2.pointwise_conv.bn.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.out_convs.0.conv.weight - torch.Size([192, 192, 3, 3]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

neck.out_convs.0.bn.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.out_convs.0.bn.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.out_convs.1.conv.weight - torch.Size([192, 384, 3, 3]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

neck.out_convs.1.bn.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.out_convs.1.bn.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.out_convs.2.conv.weight - torch.Size([192, 768, 3, 3]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

neck.out_convs.2.bn.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.out_convs.2.bn.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

bbox_head.cls_convs.0.0.conv.weight - torch.Size([192, 192, 3, 3]): 
Initialized by user-defined `init_weights` in RTMDetSepBNHead  

bbox_head.cls_convs.0.0.bn.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

bbox_head.cls_convs.0.0.bn.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

bbox_head.cls_convs.0.1.conv.weight - torch.Size([192, 192, 3, 3]): 
Initialized by user-defined `init_weights` in RTMDetSepBNHead  

bbox_head.cls_convs.0.1.bn.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

bbox_head.cls_convs.0.1.bn.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

bbox_head.cls_convs.1.0.bn.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

bbox_head.cls_convs.1.0.bn.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

bbox_head.cls_convs.1.1.bn.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

bbox_head.cls_convs.1.1.bn.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

bbox_head.cls_convs.2.0.bn.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

bbox_head.cls_convs.2.0.bn.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

bbox_head.cls_convs.2.1.bn.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

bbox_head.cls_convs.2.1.bn.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

bbox_head.reg_convs.0.0.conv.weight - torch.Size([192, 192, 3, 3]): 
Initialized by user-defined `init_weights` in RTMDetSepBNHead  

bbox_head.reg_convs.0.0.bn.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

bbox_head.reg_convs.0.0.bn.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

bbox_head.reg_convs.0.1.conv.weight - torch.Size([192, 192, 3, 3]): 
Initialized by user-defined `init_weights` in RTMDetSepBNHead  

bbox_head.reg_convs.0.1.bn.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

bbox_head.reg_convs.0.1.bn.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

bbox_head.reg_convs.1.0.bn.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

bbox_head.reg_convs.1.0.bn.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

bbox_head.reg_convs.1.1.bn.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

bbox_head.reg_convs.1.1.bn.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

bbox_head.reg_convs.2.0.bn.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

bbox_head.reg_convs.2.0.bn.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

bbox_head.reg_convs.2.1.bn.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

bbox_head.reg_convs.2.1.bn.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

bbox_head.rtm_cls.0.weight - torch.Size([1, 192, 1, 1]): 
Initialized by user-defined `init_weights` in RTMDetSepBNHead  

bbox_head.rtm_cls.0.bias - torch.Size([1]): 
Initialized by user-defined `init_weights` in RTMDetSepBNHead  

bbox_head.rtm_cls.1.weight - torch.Size([1, 192, 1, 1]): 
Initialized by user-defined `init_weights` in RTMDetSepBNHead  

bbox_head.rtm_cls.1.bias - torch.Size([1]): 
Initialized by user-defined `init_weights` in RTMDetSepBNHead  

bbox_head.rtm_cls.2.weight - torch.Size([1, 192, 1, 1]): 
Initialized by user-defined `init_weights` in RTMDetSepBNHead  

bbox_head.rtm_cls.2.bias - torch.Size([1]): 
Initialized by user-defined `init_weights` in RTMDetSepBNHead  

bbox_head.rtm_reg.0.weight - torch.Size([4, 192, 1, 1]): 
Initialized by user-defined `init_weights` in RTMDetSepBNHead  

bbox_head.rtm_reg.0.bias - torch.Size([4]): 
Initialized by user-defined `init_weights` in RTMDetSepBNHead  

bbox_head.rtm_reg.1.weight - torch.Size([4, 192, 1, 1]): 
Initialized by user-defined `init_weights` in RTMDetSepBNHead  

bbox_head.rtm_reg.1.bias - torch.Size([4]): 
Initialized by user-defined `init_weights` in RTMDetSepBNHead  

bbox_head.rtm_reg.2.weight - torch.Size([4, 192, 1, 1]): 
Initialized by user-defined `init_weights` in RTMDetSepBNHead  

bbox_head.rtm_reg.2.bias - torch.Size([4]): 
Initialized by user-defined `init_weights` in RTMDetSepBNHead  
2025/05/12 18:53:56 - mmengine - INFO - Load checkpoint from /home/jaa/Work/Prog/BSU/Detectors/work_dirs/RTMDet/RTMDet_m_30e_new3_custom/epoch_5.pth
2025/05/12 18:53:56 - mmengine - INFO - resumed epoch: 5, iter: 6550
2025/05/12 18:53:56 - mmengine - INFO - Backbone frozen before training.
2025/05/12 18:53:56 - mmengine - WARNING - "FileClient" will be deprecated in future. Please use io functions in https://mmengine.readthedocs.io/en/latest/api/fileio.html#file-io
2025/05/12 18:53:56 - mmengine - WARNING - "HardDiskBackend" is the alias of "LocalBackend" and the former will be deprecated in future.
2025/05/12 18:53:56 - mmengine - INFO - Checkpoints will be saved to /home/jaa/Work/Prog/BSU/Detectors/work_dirs/RTMDet/RTMDet_m_30e_new1_custom.
2025/05/12 18:53:56 - mmengine - INFO - Backbone was unfrozen at epoch 5
2025/05/12 18:54:12 - mmengine - INFO - Epoch(train)  [6][  50/1528]  base_lr: 1.2500e-03 lr: 1.2500e-03  eta: 3:28:51  time: 0.3194  data_time: 0.0055  memory: 19511  loss: 0.6857  loss_cls: 0.3738  loss_bbox: 0.3120
2025/05/12 18:54:28 - mmengine - INFO - Epoch(train)  [6][ 100/1528]  base_lr: 1.2500e-03 lr: 1.2500e-03  eta: 3:24:55  time: 0.3081  data_time: 0.0006  memory: 19482  loss: 0.6111  loss_cls: 0.3287  loss_bbox: 0.2824
2025/05/12 18:54:43 - mmengine - INFO - Epoch(train)  [6][ 150/1528]  base_lr: 1.2500e-03 lr: 1.2500e-03  eta: 3:22:59  time: 0.3060  data_time: 0.0006  memory: 19508  loss: 0.5929  loss_cls: 0.2981  loss_bbox: 0.2947
2025/05/12 18:55:00 - mmengine - INFO - Epoch(train)  [6][ 200/1528]  base_lr: 1.2500e-03 lr: 1.2500e-03  eta: 3:27:09  time: 0.3384  data_time: 0.0006  memory: 19508  loss: 0.5176  loss_cls: 0.2652  loss_bbox: 0.2524
2025/05/12 18:55:16 - mmengine - INFO - Epoch(train)  [6][ 250/1528]  base_lr: 1.2500e-03 lr: 1.2500e-03  eta: 3:27:50  time: 0.3253  data_time: 0.0006  memory: 19476  loss: 0.5869  loss_cls: 0.3019  loss_bbox: 0.2850
2025/05/12 18:55:32 - mmengine - INFO - Epoch(train)  [6][ 300/1528]  base_lr: 1.2500e-03 lr: 1.2500e-03  eta: 3:26:23  time: 0.3084  data_time: 0.0006  memory: 19481  loss: 0.5551  loss_cls: 0.2854  loss_bbox: 0.2697
2025/05/12 18:55:47 - mmengine - INFO - Epoch(train)  [6][ 350/1528]  base_lr: 1.2500e-03 lr: 1.2500e-03  eta: 3:25:00  time: 0.3056  data_time: 0.0005  memory: 19492  loss: 0.5512  loss_cls: 0.2864  loss_bbox: 0.2648
2025/05/12 18:56:02 - mmengine - INFO - Epoch(train)  [6][ 400/1528]  base_lr: 1.2500e-03 lr: 1.2500e-03  eta: 3:23:31  time: 0.3008  data_time: 0.0006  memory: 19514  loss: 0.5558  loss_cls: 0.2834  loss_bbox: 0.2724
2025/05/12 18:56:17 - mmengine - INFO - Exp name: rtmdet_m_1x_custom_resume_20250512_185352
2025/05/12 18:56:17 - mmengine - INFO - Epoch(train)  [6][ 450/1528]  base_lr: 1.2500e-03 lr: 1.2500e-03  eta: 3:22:34  time: 0.3045  data_time: 0.0005  memory: 19507  loss: 0.5245  loss_cls: 0.2590  loss_bbox: 0.2655
2025/05/12 18:56:32 - mmengine - INFO - Epoch(train)  [6][ 500/1528]  base_lr: 1.2500e-03 lr: 1.2500e-03  eta: 3:21:29  time: 0.3001  data_time: 0.0005  memory: 19505  loss: 0.5080  loss_cls: 0.2597  loss_bbox: 0.2483
2025/05/12 18:56:47 - mmengine - INFO - Epoch(train)  [6][ 550/1528]  base_lr: 1.2500e-03 lr: 1.2500e-03  eta: 3:20:48  time: 0.3047  data_time: 0.0005  memory: 19515  loss: 0.5590  loss_cls: 0.2851  loss_bbox: 0.2739
2025/05/12 18:57:03 - mmengine - INFO - Epoch(train)  [6][ 600/1528]  base_lr: 1.2500e-03 lr: 1.2500e-03  eta: 3:20:08  time: 0.3033  data_time: 0.0006  memory: 19491  loss: 0.5324  loss_cls: 0.2689  loss_bbox: 0.2635
2025/05/12 18:57:18 - mmengine - INFO - Epoch(train)  [6][ 650/1528]  base_lr: 1.2500e-03 lr: 1.2500e-03  eta: 3:19:58  time: 0.3123  data_time: 0.0006  memory: 19506  loss: 0.5498  loss_cls: 0.2714  loss_bbox: 0.2784
2025/05/12 18:57:34 - mmengine - INFO - Epoch(train)  [6][ 700/1528]  base_lr: 1.2500e-03 lr: 1.2500e-03  eta: 3:20:24  time: 0.3256  data_time: 0.0007  memory: 19498  loss: 0.5126  loss_cls: 0.2545  loss_bbox: 0.2581
2025/05/12 18:57:50 - mmengine - INFO - Epoch(train)  [6][ 750/1528]  base_lr: 1.2500e-03 lr: 1.2500e-03  eta: 3:20:20  time: 0.3161  data_time: 0.0007  memory: 19496  loss: 0.5335  loss_cls: 0.2678  loss_bbox: 0.2657
2025/05/12 18:58:06 - mmengine - INFO - Epoch(train)  [6][ 800/1528]  base_lr: 1.2500e-03 lr: 1.2500e-03  eta: 3:20:19  time: 0.3178  data_time: 0.0007  memory: 19511  loss: 0.5483  loss_cls: 0.2612  loss_bbox: 0.2871
2025/05/12 18:58:22 - mmengine - INFO - Epoch(train)  [6][ 850/1528]  base_lr: 1.2500e-03 lr: 1.2500e-03  eta: 3:20:15  time: 0.3176  data_time: 0.0006  memory: 19489  loss: 0.5234  loss_cls: 0.2588  loss_bbox: 0.2647
2025/05/12 18:58:38 - mmengine - INFO - Epoch(train)  [6][ 900/1528]  base_lr: 1.2500e-03 lr: 1.2500e-03  eta: 3:20:17  time: 0.3206  data_time: 0.0006  memory: 19487  loss: 0.5294  loss_cls: 0.2651  loss_bbox: 0.2644
2025/05/12 18:58:53 - mmengine - INFO - Epoch(train)  [6][ 950/1528]  base_lr: 1.2500e-03 lr: 1.2500e-03  eta: 3:19:42  time: 0.3036  data_time: 0.0006  memory: 19482  loss: 0.5035  loss_cls: 0.2457  loss_bbox: 0.2579
2025/05/12 18:59:09 - mmengine - INFO - Epoch(train)  [6][1000/1528]  base_lr: 1.2500e-03 lr: 1.2500e-03  eta: 3:19:15  time: 0.3067  data_time: 0.0006  memory: 19502  loss: 0.5356  loss_cls: 0.2649  loss_bbox: 0.2707
2025/05/12 18:59:24 - mmengine - INFO - Epoch(train)  [6][1050/1528]  base_lr: 1.2500e-03 lr: 1.2500e-03  eta: 3:18:47  time: 0.3053  data_time: 0.0006  memory: 19487  loss: 0.5400  loss_cls: 0.2658  loss_bbox: 0.2741
2025/05/12 18:59:39 - mmengine - INFO - Epoch(train)  [6][1100/1528]  base_lr: 1.2500e-03 lr: 1.2500e-03  eta: 3:18:15  time: 0.3026  data_time: 0.0005  memory: 19490  loss: 0.5360  loss_cls: 0.2681  loss_bbox: 0.2678
2025/05/12 18:59:54 - mmengine - INFO - Epoch(train)  [6][1150/1528]  base_lr: 1.2500e-03 lr: 1.2500e-03  eta: 3:17:48  time: 0.3042  data_time: 0.0006  memory: 19481  loss: 0.5021  loss_cls: 0.2518  loss_bbox: 0.2503
2025/05/12 19:00:10 - mmengine - INFO - Epoch(train)  [6][1200/1528]  base_lr: 1.2500e-03 lr: 1.2500e-03  eta: 3:17:35  time: 0.3131  data_time: 0.0006  memory: 19509  loss: 0.5021  loss_cls: 0.2496  loss_bbox: 0.2526
2025/05/12 19:00:26 - mmengine - INFO - Epoch(train)  [6][1250/1528]  base_lr: 1.2500e-03 lr: 1.2500e-03  eta: 3:17:34  time: 0.3208  data_time: 0.0007  memory: 19517  loss: 0.4818  loss_cls: 0.2358  loss_bbox: 0.2460
2025/05/12 19:00:42 - mmengine - INFO - Epoch(train)  [6][1300/1528]  base_lr: 1.2500e-03 lr: 1.2500e-03  eta: 3:17:44  time: 0.3291  data_time: 0.0007  memory: 19493  loss: 0.4911  loss_cls: 0.2328  loss_bbox: 0.2583
2025/05/12 19:00:59 - mmengine - INFO - Epoch(train)  [6][1350/1528]  base_lr: 1.2500e-03 lr: 1.2500e-03  eta: 3:17:49  time: 0.3267  data_time: 0.0007  memory: 19500  loss: 0.5104  loss_cls: 0.2543  loss_bbox: 0.2560
2025/05/12 19:01:15 - mmengine - INFO - Epoch(train)  [6][1400/1528]  base_lr: 1.2500e-03 lr: 1.2500e-03  eta: 3:17:56  time: 0.3297  data_time: 0.0007  memory: 19482  loss: 0.4750  loss_cls: 0.2276  loss_bbox: 0.2473
2025/05/12 19:01:31 - mmengine - INFO - Exp name: rtmdet_m_1x_custom_resume_20250512_185352
2025/05/12 19:01:31 - mmengine - INFO - Epoch(train)  [6][1450/1528]  base_lr: 1.2500e-03 lr: 1.2500e-03  eta: 3:17:53  time: 0.3230  data_time: 0.0006  memory: 19481  loss: 0.5016  loss_cls: 0.2441  loss_bbox: 0.2576
2025/05/12 19:01:48 - mmengine - INFO - Epoch(train)  [6][1500/1528]  base_lr: 1.2500e-03 lr: 1.2500e-03  eta: 3:17:57  time: 0.3301  data_time: 0.0007  memory: 19509  loss: 0.4959  loss_cls: 0.2422  loss_bbox: 0.2537
2025/05/12 19:01:57 - mmengine - INFO - Exp name: rtmdet_m_1x_custom_resume_20250512_185352
2025/05/12 19:01:57 - mmengine - INFO - Saving checkpoint at 6 epochs
2025/05/12 19:02:02 - mmengine - INFO - Epoch(val)  [6][ 50/149]    eta: 0:00:08  time: 0.0899  data_time: 0.0058  memory: 19480  
2025/05/12 19:02:06 - mmengine - INFO - Epoch(val)  [6][100/149]    eta: 0:00:04  time: 0.0870  data_time: 0.0026  memory: 1598  
2025/05/12 19:02:12 - mmengine - INFO - Evaluating bbox...
2025/05/12 19:02:15 - mmengine - INFO - bbox_mAP_copypaste: 0.730 0.928 0.824 0.426 0.636 0.769
2025/05/12 19:02:15 - mmengine - INFO - Epoch(val) [6][149/149]    coco/bbox_mAP: 0.7300  coco/bbox_mAP_50: 0.9280  coco/bbox_mAP_75: 0.8240  coco/bbox_mAP_s: 0.4260  coco/bbox_mAP_m: 0.6360  coco/bbox_mAP_l: 0.7690  data_time: 0.0036  time: 0.0868
2025/05/12 19:02:31 - mmengine - INFO - Epoch(train)  [7][  50/1528]  base_lr: 8.6373e-04 lr: 8.6373e-04  eta: 3:18:01  time: 0.3320  data_time: 0.0027  memory: 19490  loss: 0.4953  loss_cls: 0.2381  loss_bbox: 0.2572
2025/05/12 19:02:47 - mmengine - INFO - Epoch(train)  [7][ 100/1528]  base_lr: 8.6373e-04 lr: 8.6373e-04  eta: 3:17:44  time: 0.3142  data_time: 0.0005  memory: 19505  loss: 0.4871  loss_cls: 0.2370  loss_bbox: 0.2501
2025/05/12 19:03:03 - mmengine - INFO - Epoch(train)  [7][ 150/1528]  base_lr: 8.6373e-04 lr: 8.6373e-04  eta: 3:17:23  time: 0.3104  data_time: 0.0005  memory: 19502  loss: 0.4611  loss_cls: 0.2249  loss_bbox: 0.2362
2025/05/12 19:03:18 - mmengine - INFO - Epoch(train)  [7][ 200/1528]  base_lr: 8.6373e-04 lr: 8.6373e-04  eta: 3:17:08  time: 0.3156  data_time: 0.0005  memory: 19482  loss: 0.4764  loss_cls: 0.2293  loss_bbox: 0.2470
2025/05/12 19:03:34 - mmengine - INFO - Epoch(train)  [7][ 250/1528]  base_lr: 8.6373e-04 lr: 8.6373e-04  eta: 3:16:48  time: 0.3106  data_time: 0.0006  memory: 19508  loss: 0.4560  loss_cls: 0.2083  loss_bbox: 0.2477
2025/05/12 19:03:51 - mmengine - INFO - Epoch(train)  [7][ 300/1528]  base_lr: 8.6373e-04 lr: 8.6373e-04  eta: 3:16:50  time: 0.3325  data_time: 0.0006  memory: 19489  loss: 0.4603  loss_cls: 0.2130  loss_bbox: 0.2473
2025/05/12 19:04:07 - mmengine - INFO - Epoch(train)  [7][ 350/1528]  base_lr: 8.6373e-04 lr: 8.6373e-04  eta: 3:16:47  time: 0.3283  data_time: 0.0005  memory: 19509  loss: 0.4569  loss_cls: 0.2140  loss_bbox: 0.2429
2025/05/12 19:04:22 - mmengine - INFO - Epoch(train)  [7][ 400/1528]  base_lr: 8.6373e-04 lr: 8.6373e-04  eta: 3:16:23  time: 0.3067  data_time: 0.0005  memory: 19509  loss: 0.4464  loss_cls: 0.2019  loss_bbox: 0.2445
2025/05/12 19:04:38 - mmengine - INFO - Epoch(train)  [7][ 450/1528]  base_lr: 8.6373e-04 lr: 8.6373e-04  eta: 3:15:58  time: 0.3059  data_time: 0.0005  memory: 19498  loss: 0.4474  loss_cls: 0.2022  loss_bbox: 0.2451
2025/05/12 19:04:53 - mmengine - INFO - Epoch(train)  [7][ 500/1528]  base_lr: 8.6373e-04 lr: 8.6373e-04  eta: 3:15:36  time: 0.3085  data_time: 0.0006  memory: 19496  loss: 0.4538  loss_cls: 0.2133  loss_bbox: 0.2405
2025/05/12 19:05:08 - mmengine - INFO - Epoch(train)  [7][ 550/1528]  base_lr: 8.6373e-04 lr: 8.6373e-04  eta: 3:15:14  time: 0.3076  data_time: 0.0005  memory: 19486  loss: 0.4684  loss_cls: 0.2266  loss_bbox: 0.2417
2025/05/12 19:05:24 - mmengine - INFO - Epoch(train)  [7][ 600/1528]  base_lr: 8.6373e-04 lr: 8.6373e-04  eta: 3:14:53  time: 0.3091  data_time: 0.0005  memory: 19497  loss: 0.4411  loss_cls: 0.2114  loss_bbox: 0.2297
2025/05/12 19:05:39 - mmengine - INFO - Epoch(train)  [7][ 650/1528]  base_lr: 8.6373e-04 lr: 8.6373e-04  eta: 3:14:26  time: 0.3008  data_time: 0.0005  memory: 19510  loss: 0.4578  loss_cls: 0.2121  loss_bbox: 0.2457
2025/05/12 19:05:54 - mmengine - INFO - Epoch(train)  [7][ 700/1528]  base_lr: 8.6373e-04 lr: 8.6373e-04  eta: 3:14:02  time: 0.3047  data_time: 0.0005  memory: 19511  loss: 0.4534  loss_cls: 0.2151  loss_bbox: 0.2383
2025/05/12 19:06:09 - mmengine - INFO - Epoch(train)  [7][ 750/1528]  base_lr: 8.6373e-04 lr: 8.6373e-04  eta: 3:13:35  time: 0.3001  data_time: 0.0005  memory: 19482  loss: 0.4555  loss_cls: 0.2190  loss_bbox: 0.2366
2025/05/12 19:06:24 - mmengine - INFO - Epoch(train)  [7][ 800/1528]  base_lr: 8.6373e-04 lr: 8.6373e-04  eta: 3:13:09  time: 0.3007  data_time: 0.0004  memory: 19487  loss: 0.4837  loss_cls: 0.2419  loss_bbox: 0.2419
2025/05/12 19:06:40 - mmengine - INFO - Epoch(train)  [7][ 850/1528]  base_lr: 8.6373e-04 lr: 8.6373e-04  eta: 3:12:48  time: 0.3063  data_time: 0.0006  memory: 19485  loss: 0.4700  loss_cls: 0.2248  loss_bbox: 0.2452
2025/05/12 19:06:55 - mmengine - INFO - Epoch(train)  [7][ 900/1528]  base_lr: 8.6373e-04 lr: 8.6373e-04  eta: 3:12:29  time: 0.3091  data_time: 0.0005  memory: 19490  loss: 0.4662  loss_cls: 0.2199  loss_bbox: 0.2463
2025/05/12 19:07:02 - mmengine - INFO - Exp name: rtmdet_m_1x_custom_resume_20250512_185352
2025/05/12 19:07:10 - mmengine - INFO - Epoch(train)  [7][ 950/1528]  base_lr: 8.6373e-04 lr: 8.6373e-04  eta: 3:12:10  time: 0.3092  data_time: 0.0005  memory: 19485  loss: 0.4658  loss_cls: 0.2173  loss_bbox: 0.2485
2025/05/12 19:07:26 - mmengine - INFO - Epoch(train)  [7][1000/1528]  base_lr: 8.6373e-04 lr: 8.6373e-04  eta: 3:11:48  time: 0.3052  data_time: 0.0005  memory: 19502  loss: 0.4620  loss_cls: 0.2182  loss_bbox: 0.2438
2025/05/12 19:07:41 - mmengine - INFO - Epoch(train)  [7][1050/1528]  base_lr: 8.6373e-04 lr: 8.6373e-04  eta: 3:11:34  time: 0.3146  data_time: 0.0006  memory: 19513  loss: 0.4695  loss_cls: 0.2217  loss_bbox: 0.2478
2025/05/12 19:07:57 - mmengine - INFO - Epoch(train)  [7][1100/1528]  base_lr: 8.6373e-04 lr: 8.6373e-04  eta: 3:11:19  time: 0.3142  data_time: 0.0005  memory: 19497  loss: 0.4335  loss_cls: 0.2028  loss_bbox: 0.2307
2025/05/12 19:08:13 - mmengine - INFO - Epoch(train)  [7][1150/1528]  base_lr: 8.6373e-04 lr: 8.6373e-04  eta: 3:11:03  time: 0.3134  data_time: 0.0006  memory: 19500  loss: 0.4627  loss_cls: 0.2211  loss_bbox: 0.2415
2025/05/12 19:08:28 - mmengine - INFO - Epoch(train)  [7][1200/1528]  base_lr: 8.6373e-04 lr: 8.6373e-04  eta: 3:10:42  time: 0.3044  data_time: 0.0006  memory: 19515  loss: 0.4541  loss_cls: 0.2080  loss_bbox: 0.2461
2025/05/12 19:08:44 - mmengine - INFO - Epoch(train)  [7][1250/1528]  base_lr: 8.6373e-04 lr: 8.6373e-04  eta: 3:10:28  time: 0.3159  data_time: 0.0006  memory: 19486  loss: 0.4459  loss_cls: 0.2118  loss_bbox: 0.2342
2025/05/12 19:09:00 - mmengine - INFO - Epoch(train)  [7][1300/1528]  base_lr: 8.6373e-04 lr: 8.6373e-04  eta: 3:10:18  time: 0.3214  data_time: 0.0005  memory: 19502  loss: 0.4766  loss_cls: 0.2253  loss_bbox: 0.2513
2025/05/12 19:09:16 - mmengine - INFO - Epoch(train)  [7][1350/1528]  base_lr: 8.6373e-04 lr: 8.6373e-04  eta: 3:10:11  time: 0.3268  data_time: 0.0006  memory: 19507  loss: 0.4548  loss_cls: 0.2158  loss_bbox: 0.2390
2025/05/12 19:09:32 - mmengine - INFO - Epoch(train)  [7][1400/1528]  base_lr: 8.6373e-04 lr: 8.6373e-04  eta: 3:09:56  time: 0.3142  data_time: 0.0005  memory: 19477  loss: 0.4806  loss_cls: 0.2387  loss_bbox: 0.2419
2025/05/12 19:09:48 - mmengine - INFO - Epoch(train)  [7][1450/1528]  base_lr: 8.6373e-04 lr: 8.6373e-04  eta: 3:09:44  time: 0.3190  data_time: 0.0006  memory: 19488  loss: 0.4330  loss_cls: 0.2038  loss_bbox: 0.2293
2025/05/12 19:10:03 - mmengine - INFO - Epoch(train)  [7][1500/1528]  base_lr: 8.6373e-04 lr: 8.6373e-04  eta: 3:09:25  time: 0.3091  data_time: 0.0006  memory: 19509  loss: 0.4470  loss_cls: 0.2116  loss_bbox: 0.2354
2025/05/12 19:10:12 - mmengine - INFO - Exp name: rtmdet_m_1x_custom_resume_20250512_185352
2025/05/12 19:10:12 - mmengine - INFO - Saving checkpoint at 7 epochs
2025/05/12 19:10:17 - mmengine - INFO - Epoch(val)  [7][ 50/149]    eta: 0:00:08  time: 0.0826  data_time: 0.0034  memory: 19474  
2025/05/12 19:10:21 - mmengine - INFO - Epoch(val)  [7][100/149]    eta: 0:00:03  time: 0.0779  data_time: 0.0025  memory: 1598  
2025/05/12 19:10:26 - mmengine - INFO - Evaluating bbox...
2025/05/12 19:10:28 - mmengine - INFO - bbox_mAP_copypaste: 0.754 0.939 0.855 0.452 0.658 0.793
2025/05/12 19:10:28 - mmengine - INFO - Epoch(val) [7][149/149]    coco/bbox_mAP: 0.7540  coco/bbox_mAP_50: 0.9390  coco/bbox_mAP_75: 0.8550  coco/bbox_mAP_s: 0.4520  coco/bbox_mAP_m: 0.6580  coco/bbox_mAP_l: 0.7930  data_time: 0.0028  time: 0.0795
2025/05/12 19:10:44 - mmengine - INFO - Epoch(train)  [8][  50/1528]  base_lr: 5.1527e-05 lr: 5.1527e-05  eta: 3:08:56  time: 0.3100  data_time: 0.0027  memory: 19502  loss: 0.4419  loss_cls: 0.2010  loss_bbox: 0.2410
2025/05/12 19:11:00 - mmengine - INFO - Epoch(train)  [8][ 100/1528]  base_lr: 5.1527e-05 lr: 5.1527e-05  eta: 3:08:43  time: 0.3191  data_time: 0.0006  memory: 19500  loss: 0.4535  loss_cls: 0.2188  loss_bbox: 0.2347
2025/05/12 19:11:15 - mmengine - INFO - Epoch(train)  [8][ 150/1528]  base_lr: 5.1527e-05 lr: 5.1527e-05  eta: 3:08:25  time: 0.3084  data_time: 0.0006  memory: 19482  loss: 0.4050  loss_cls: 0.1875  loss_bbox: 0.2175
2025/05/12 19:11:31 - mmengine - INFO - Epoch(train)  [8][ 200/1528]  base_lr: 5.1527e-05 lr: 5.1527e-05  eta: 3:08:10  time: 0.3144  data_time: 0.0007  memory: 19515  loss: 0.4514  loss_cls: 0.2049  loss_bbox: 0.2465
2025/05/12 19:11:47 - mmengine - INFO - Epoch(train)  [8][ 250/1528]  base_lr: 5.1527e-05 lr: 5.1527e-05  eta: 3:08:00  time: 0.3235  data_time: 0.0006  memory: 19506  loss: 0.4348  loss_cls: 0.2077  loss_bbox: 0.2272
2025/05/12 19:12:03 - mmengine - INFO - Epoch(train)  [8][ 300/1528]  base_lr: 5.1527e-05 lr: 5.1527e-05  eta: 3:07:45  time: 0.3156  data_time: 0.0006  memory: 19478  loss: 0.4261  loss_cls: 0.2001  loss_bbox: 0.2260
2025/05/12 19:12:18 - mmengine - INFO - Epoch(train)  [8][ 350/1528]  base_lr: 5.1527e-05 lr: 5.1527e-05  eta: 3:07:26  time: 0.3063  data_time: 0.0006  memory: 19489  loss: 0.4296  loss_cls: 0.2076  loss_bbox: 0.2220
2025/05/12 19:12:32 - mmengine - INFO - Exp name: rtmdet_m_1x_custom_resume_20250512_185352
2025/05/12 19:12:33 - mmengine - INFO - Epoch(train)  [8][ 400/1528]  base_lr: 5.1527e-05 lr: 5.1527e-05  eta: 3:07:05  time: 0.3046  data_time: 0.0006  memory: 19484  loss: 0.4174  loss_cls: 0.1933  loss_bbox: 0.2240
2025/05/12 19:12:49 - mmengine - INFO - Epoch(train)  [8][ 450/1528]  base_lr: 5.1527e-05 lr: 5.1527e-05  eta: 3:06:49  time: 0.3127  data_time: 0.0005  memory: 19472  loss: 0.4419  loss_cls: 0.2088  loss_bbox: 0.2331
2025/05/12 19:13:05 - mmengine - INFO - Epoch(train)  [8][ 500/1528]  base_lr: 5.1527e-05 lr: 5.1527e-05  eta: 3:06:36  time: 0.3183  data_time: 0.0006  memory: 19495  loss: 0.4264  loss_cls: 0.1982  loss_bbox: 0.2283
2025/05/12 19:13:21 - mmengine - INFO - Epoch(train)  [8][ 550/1528]  base_lr: 5.1527e-05 lr: 5.1527e-05  eta: 3:06:19  time: 0.3093  data_time: 0.0006  memory: 19512  loss: 0.4444  loss_cls: 0.2132  loss_bbox: 0.2311
2025/05/12 19:13:35 - mmengine - INFO - Epoch(train)  [8][ 600/1528]  base_lr: 5.1527e-05 lr: 5.1527e-05  eta: 3:05:56  time: 0.2982  data_time: 0.0006  memory: 19490  loss: 0.4358  loss_cls: 0.2061  loss_bbox: 0.2296
2025/05/12 19:13:50 - mmengine - INFO - Epoch(train)  [8][ 650/1528]  base_lr: 5.1527e-05 lr: 5.1527e-05  eta: 3:05:33  time: 0.2991  data_time: 0.0006  memory: 19506  loss: 0.4135  loss_cls: 0.1974  loss_bbox: 0.2162
2025/05/12 19:14:05 - mmengine - INFO - Epoch(train)  [8][ 700/1528]  base_lr: 5.1527e-05 lr: 5.1527e-05  eta: 3:05:11  time: 0.2988  data_time: 0.0006  memory: 19503  loss: 0.4226  loss_cls: 0.2005  loss_bbox: 0.2221
2025/05/12 19:14:21 - mmengine - INFO - Epoch(train)  [8][ 750/1528]  base_lr: 5.1527e-05 lr: 5.1527e-05  eta: 3:04:54  time: 0.3089  data_time: 0.0006  memory: 19491  loss: 0.4310  loss_cls: 0.2056  loss_bbox: 0.2254
2025/05/12 19:14:36 - mmengine - INFO - Epoch(train)  [8][ 800/1528]  base_lr: 5.1527e-05 lr: 5.1527e-05  eta: 3:04:34  time: 0.3032  data_time: 0.0005  memory: 19497  loss: 0.4486  loss_cls: 0.2182  loss_bbox: 0.2304
2025/05/12 19:14:51 - mmengine - INFO - Epoch(train)  [8][ 850/1528]  base_lr: 5.1527e-05 lr: 5.1527e-05  eta: 3:04:12  time: 0.2994  data_time: 0.0004  memory: 19474  loss: 0.4434  loss_cls: 0.2111  loss_bbox: 0.2324
2025/05/12 19:15:06 - mmengine - INFO - Epoch(train)  [8][ 900/1528]  base_lr: 5.1527e-05 lr: 5.1527e-05  eta: 3:03:52  time: 0.3023  data_time: 0.0005  memory: 19478  loss: 0.4226  loss_cls: 0.2023  loss_bbox: 0.2203
2025/05/12 19:15:21 - mmengine - INFO - Epoch(train)  [8][ 950/1528]  base_lr: 5.1527e-05 lr: 5.1527e-05  eta: 3:03:33  time: 0.3048  data_time: 0.0005  memory: 19484  loss: 0.4065  loss_cls: 0.1879  loss_bbox: 0.2186
2025/05/12 19:15:37 - mmengine - INFO - Epoch(train)  [8][1000/1528]  base_lr: 5.1527e-05 lr: 5.1527e-05  eta: 3:03:18  time: 0.3138  data_time: 0.0007  memory: 19509  loss: 0.4108  loss_cls: 0.1907  loss_bbox: 0.2201
2025/05/12 19:15:53 - mmengine - INFO - Epoch(train)  [8][1050/1528]  base_lr: 5.1527e-05 lr: 5.1527e-05  eta: 3:03:05  time: 0.3179  data_time: 0.0006  memory: 19475  loss: 0.4421  loss_cls: 0.2100  loss_bbox: 0.2321
2025/05/12 19:16:09 - mmengine - INFO - Epoch(train)  [8][1100/1528]  base_lr: 5.1527e-05 lr: 5.1527e-05  eta: 3:02:50  time: 0.3144  data_time: 0.0006  memory: 19487  loss: 0.4490  loss_cls: 0.2116  loss_bbox: 0.2374
2025/05/12 19:16:24 - mmengine - INFO - Epoch(train)  [8][1150/1528]  base_lr: 5.1527e-05 lr: 5.1527e-05  eta: 3:02:33  time: 0.3092  data_time: 0.0006  memory: 19482  loss: 0.4153  loss_cls: 0.1897  loss_bbox: 0.2255
2025/05/12 19:16:39 - mmengine - INFO - Epoch(train)  [8][1200/1528]  base_lr: 5.1527e-05 lr: 5.1527e-05  eta: 3:02:12  time: 0.2989  data_time: 0.0006  memory: 19491  loss: 0.4136  loss_cls: 0.1959  loss_bbox: 0.2177
2025/05/12 19:16:54 - mmengine - INFO - Epoch(train)  [8][1250/1528]  base_lr: 5.1527e-05 lr: 5.1527e-05  eta: 3:01:52  time: 0.3013  data_time: 0.0005  memory: 19498  loss: 0.4278  loss_cls: 0.2011  loss_bbox: 0.2267
2025/05/12 19:17:09 - mmengine - INFO - Epoch(train)  [8][1300/1528]  base_lr: 5.1527e-05 lr: 5.1527e-05  eta: 3:01:33  time: 0.3030  data_time: 0.0005  memory: 19511  loss: 0.4252  loss_cls: 0.2007  loss_bbox: 0.2245
2025/05/12 19:17:24 - mmengine - INFO - Epoch(train)  [8][1350/1528]  base_lr: 5.1527e-05 lr: 5.1527e-05  eta: 3:01:13  time: 0.3007  data_time: 0.0006  memory: 19500  loss: 0.4288  loss_cls: 0.2010  loss_bbox: 0.2278
2025/05/12 19:17:38 - mmengine - INFO - Exp name: rtmdet_m_1x_custom_resume_20250512_185352
2025/05/12 19:17:40 - mmengine - INFO - Epoch(train)  [8][1400/1528]  base_lr: 5.1527e-05 lr: 5.1527e-05  eta: 3:00:57  time: 0.3115  data_time: 0.0006  memory: 19492  loss: 0.4377  loss_cls: 0.2106  loss_bbox: 0.2271
2025/05/12 19:17:56 - mmengine - INFO - Epoch(train)  [8][1450/1528]  base_lr: 5.1527e-05 lr: 5.1527e-05  eta: 3:00:44  time: 0.3162  data_time: 0.0006  memory: 19484  loss: 0.4223  loss_cls: 0.2084  loss_bbox: 0.2138
2025/05/12 19:18:11 - mmengine - INFO - Epoch(train)  [8][1500/1528]  base_lr: 5.1527e-05 lr: 5.1527e-05  eta: 3:00:26  time: 0.3059  data_time: 0.0005  memory: 19498  loss: 0.4204  loss_cls: 0.1947  loss_bbox: 0.2257
2025/05/12 19:18:19 - mmengine - INFO - Exp name: rtmdet_m_1x_custom_resume_20250512_185352
2025/05/12 19:18:19 - mmengine - INFO - Saving checkpoint at 8 epochs
2025/05/12 19:18:24 - mmengine - INFO - Epoch(val)  [8][ 50/149]    eta: 0:00:07  time: 0.0799  data_time: 0.0033  memory: 19503  
2025/05/12 19:18:28 - mmengine - INFO - Epoch(val)  [8][100/149]    eta: 0:00:03  time: 0.0818  data_time: 0.0026  memory: 1598  
2025/05/12 19:18:33 - mmengine - INFO - Evaluating bbox...
2025/05/12 19:18:36 - mmengine - INFO - bbox_mAP_copypaste: 0.770 0.940 0.859 0.445 0.661 0.814
2025/05/12 19:18:36 - mmengine - INFO - Epoch(val) [8][149/149]    coco/bbox_mAP: 0.7700  coco/bbox_mAP_50: 0.9400  coco/bbox_mAP_75: 0.8590  coco/bbox_mAP_s: 0.4450  coco/bbox_mAP_m: 0.6610  coco/bbox_mAP_l: 0.8140  data_time: 0.0028  time: 0.0794
2025/05/12 19:18:51 - mmengine - INFO - Epoch(train)  [9][  50/1528]  base_lr: 2.3873e-05 lr: 2.3873e-05  eta: 2:59:57  time: 0.3067  data_time: 0.0029  memory: 19490  loss: 0.4156  loss_cls: 0.1966  loss_bbox: 0.2190
2025/05/12 19:19:07 - mmengine - INFO - Epoch(train)  [9][ 100/1528]  base_lr: 2.3873e-05 lr: 2.3873e-05  eta: 2:59:41  time: 0.3111  data_time: 0.0005  memory: 19485  loss: 0.4257  loss_cls: 0.2037  loss_bbox: 0.2219
2025/05/12 19:19:22 - mmengine - INFO - Epoch(train)  [9][ 150/1528]  base_lr: 2.3873e-05 lr: 2.3873e-05  eta: 2:59:27  time: 0.3164  data_time: 0.0006  memory: 19487  loss: 0.4018  loss_cls: 0.1814  loss_bbox: 0.2204
2025/05/12 19:19:38 - mmengine - INFO - Epoch(train)  [9][ 200/1528]  base_lr: 2.3873e-05 lr: 2.3873e-05  eta: 2:59:08  time: 0.3010  data_time: 0.0005  memory: 19472  loss: 0.4372  loss_cls: 0.2125  loss_bbox: 0.2247
2025/05/12 19:19:53 - mmengine - INFO - Epoch(train)  [9][ 250/1528]  base_lr: 2.3873e-05 lr: 2.3873e-05  eta: 2:58:51  time: 0.3083  data_time: 0.0006  memory: 19505  loss: 0.4237  loss_cls: 0.1934  loss_bbox: 0.2303
2025/05/12 19:20:09 - mmengine - INFO - Epoch(train)  [9][ 300/1528]  base_lr: 2.3873e-05 lr: 2.3873e-05  eta: 2:58:36  time: 0.3113  data_time: 0.0006  memory: 19485  loss: 0.4341  loss_cls: 0.2024  loss_bbox: 0.2316
2025/05/12 19:20:24 - mmengine - INFO - Epoch(train)  [9][ 350/1528]  base_lr: 2.3873e-05 lr: 2.3873e-05  eta: 2:58:20  time: 0.3109  data_time: 0.0005  memory: 19504  loss: 0.4262  loss_cls: 0.2059  loss_bbox: 0.2203
2025/05/12 19:20:39 - mmengine - INFO - Epoch(train)  [9][ 400/1528]  base_lr: 2.3873e-05 lr: 2.3873e-05  eta: 2:58:03  time: 0.3070  data_time: 0.0005  memory: 19475  loss: 0.4220  loss_cls: 0.1933  loss_bbox: 0.2287
2025/05/12 19:20:55 - mmengine - INFO - Epoch(train)  [9][ 450/1528]  base_lr: 2.3873e-05 lr: 2.3873e-05  eta: 2:57:44  time: 0.3033  data_time: 0.0005  memory: 19491  loss: 0.4135  loss_cls: 0.1921  loss_bbox: 0.2214
2025/05/12 19:21:10 - mmengine - INFO - Epoch(train)  [9][ 500/1528]  base_lr: 2.3873e-05 lr: 2.3873e-05  eta: 2:57:30  time: 0.3139  data_time: 0.0006  memory: 19496  loss: 0.4314  loss_cls: 0.2045  loss_bbox: 0.2269
2025/05/12 19:21:26 - mmengine - INFO - Epoch(train)  [9][ 550/1528]  base_lr: 2.3873e-05 lr: 2.3873e-05  eta: 2:57:17  time: 0.3190  data_time: 0.0005  memory: 19497  loss: 0.4491  loss_cls: 0.2082  loss_bbox: 0.2409
2025/05/12 19:21:42 - mmengine - INFO - Epoch(train)  [9][ 600/1528]  base_lr: 2.3873e-05 lr: 2.3873e-05  eta: 2:57:01  time: 0.3102  data_time: 0.0006  memory: 19479  loss: 0.4354  loss_cls: 0.2071  loss_bbox: 0.2283
2025/05/12 19:21:57 - mmengine - INFO - Epoch(train)  [9][ 650/1528]  base_lr: 2.3873e-05 lr: 2.3873e-05  eta: 2:56:43  time: 0.3038  data_time: 0.0006  memory: 19498  loss: 0.4311  loss_cls: 0.2043  loss_bbox: 0.2268
2025/05/12 19:22:12 - mmengine - INFO - Epoch(train)  [9][ 700/1528]  base_lr: 2.3873e-05 lr: 2.3873e-05  eta: 2:56:26  time: 0.3080  data_time: 0.0004  memory: 19476  loss: 0.4338  loss_cls: 0.2098  loss_bbox: 0.2240
2025/05/12 19:22:28 - mmengine - INFO - Epoch(train)  [9][ 750/1528]  base_lr: 2.3873e-05 lr: 2.3873e-05  eta: 2:56:10  time: 0.3084  data_time: 0.0005  memory: 19489  loss: 0.4539  loss_cls: 0.2155  loss_bbox: 0.2383
2025/05/12 19:22:43 - mmengine - INFO - Epoch(train)  [9][ 800/1528]  base_lr: 2.3873e-05 lr: 2.3873e-05  eta: 2:55:53  time: 0.3085  data_time: 0.0005  memory: 19510  loss: 0.4181  loss_cls: 0.1975  loss_bbox: 0.2207
2025/05/12 19:22:59 - mmengine - INFO - Epoch(train)  [9][ 850/1528]  base_lr: 2.3873e-05 lr: 2.3873e-05  eta: 2:55:37  time: 0.3088  data_time: 0.0006  memory: 19519  loss: 0.4260  loss_cls: 0.2019  loss_bbox: 0.2241
2025/05/12 19:23:03 - mmengine - INFO - Exp name: rtmdet_m_1x_custom_resume_20250512_185352
2025/05/12 19:23:14 - mmengine - INFO - Epoch(train)  [9][ 900/1528]  base_lr: 2.3873e-05 lr: 2.3873e-05  eta: 2:55:22  time: 0.3133  data_time: 0.0005  memory: 19515  loss: 0.4382  loss_cls: 0.2071  loss_bbox: 0.2310
2025/05/12 19:23:31 - mmengine - INFO - Epoch(train)  [9][ 950/1528]  base_lr: 2.3873e-05 lr: 2.3873e-05  eta: 2:55:10  time: 0.3247  data_time: 0.0006  memory: 19505  loss: 0.4357  loss_cls: 0.2109  loss_bbox: 0.2248
2025/05/12 19:23:46 - mmengine - INFO - Epoch(train)  [9][1000/1528]  base_lr: 2.3873e-05 lr: 2.3873e-05  eta: 2:54:54  time: 0.3088  data_time: 0.0005  memory: 19499  loss: 0.4129  loss_cls: 0.1880  loss_bbox: 0.2249
2025/05/12 19:24:02 - mmengine - INFO - Epoch(train)  [9][1050/1528]  base_lr: 2.3873e-05 lr: 2.3873e-05  eta: 2:54:39  time: 0.3136  data_time: 0.0006  memory: 19491  loss: 0.4352  loss_cls: 0.2102  loss_bbox: 0.2250
2025/05/12 19:24:18 - mmengine - INFO - Epoch(train)  [9][1100/1528]  base_lr: 2.3873e-05 lr: 2.3873e-05  eta: 2:54:26  time: 0.3186  data_time: 0.0006  memory: 19509  loss: 0.4216  loss_cls: 0.2006  loss_bbox: 0.2209
2025/05/12 19:24:34 - mmengine - INFO - Epoch(train)  [9][1150/1528]  base_lr: 2.3873e-05 lr: 2.3873e-05  eta: 2:54:13  time: 0.3211  data_time: 0.0006  memory: 19506  loss: 0.4251  loss_cls: 0.1998  loss_bbox: 0.2254
2025/05/12 19:24:49 - mmengine - INFO - Epoch(train)  [9][1200/1528]  base_lr: 2.3873e-05 lr: 2.3873e-05  eta: 2:53:56  time: 0.3062  data_time: 0.0006  memory: 19500  loss: 0.4081  loss_cls: 0.1840  loss_bbox: 0.2242
2025/05/12 19:25:05 - mmengine - INFO - Epoch(train)  [9][1250/1528]  base_lr: 2.3873e-05 lr: 2.3873e-05  eta: 2:53:41  time: 0.3122  data_time: 0.0006  memory: 19506  loss: 0.4045  loss_cls: 0.1917  loss_bbox: 0.2128
2025/05/12 19:25:20 - mmengine - INFO - Epoch(train)  [9][1300/1528]  base_lr: 2.3873e-05 lr: 2.3873e-05  eta: 2:53:26  time: 0.3163  data_time: 0.0006  memory: 19511  loss: 0.4177  loss_cls: 0.2002  loss_bbox: 0.2175
2025/05/12 19:25:36 - mmengine - INFO - Epoch(train)  [9][1350/1528]  base_lr: 2.3873e-05 lr: 2.3873e-05  eta: 2:53:12  time: 0.3168  data_time: 0.0006  memory: 19485  loss: 0.4292  loss_cls: 0.1996  loss_bbox: 0.2296
2025/05/12 19:25:52 - mmengine - INFO - Epoch(train)  [9][1400/1528]  base_lr: 2.3873e-05 lr: 2.3873e-05  eta: 2:52:56  time: 0.3089  data_time: 0.0006  memory: 19485  loss: 0.4192  loss_cls: 0.1954  loss_bbox: 0.2237
2025/05/12 19:26:07 - mmengine - INFO - Epoch(train)  [9][1450/1528]  base_lr: 2.3873e-05 lr: 2.3873e-05  eta: 2:52:41  time: 0.3141  data_time: 0.0006  memory: 19495  loss: 0.4331  loss_cls: 0.2046  loss_bbox: 0.2285
2025/05/12 19:26:23 - mmengine - INFO - Epoch(train)  [9][1500/1528]  base_lr: 2.3873e-05 lr: 2.3873e-05  eta: 2:52:26  time: 0.3118  data_time: 0.0005  memory: 19502  loss: 0.3978  loss_cls: 0.1839  loss_bbox: 0.2139
2025/05/12 19:26:32 - mmengine - INFO - Exp name: rtmdet_m_1x_custom_resume_20250512_185352
2025/05/12 19:26:32 - mmengine - INFO - Saving checkpoint at 9 epochs
2025/05/12 19:26:36 - mmengine - INFO - Epoch(val)  [9][ 50/149]    eta: 0:00:08  time: 0.0824  data_time: 0.0033  memory: 19475  
2025/05/12 19:26:40 - mmengine - INFO - Epoch(val)  [9][100/149]    eta: 0:00:03  time: 0.0795  data_time: 0.0026  memory: 1598  
2025/05/12 19:26:46 - mmengine - INFO - Evaluating bbox...
2025/05/12 19:26:48 - mmengine - INFO - bbox_mAP_copypaste: 0.772 0.941 0.865 0.464 0.662 0.816
2025/05/12 19:26:48 - mmengine - INFO - Epoch(val) [9][149/149]    coco/bbox_mAP: 0.7720  coco/bbox_mAP_50: 0.9410  coco/bbox_mAP_75: 0.8650  coco/bbox_mAP_s: 0.4640  coco/bbox_mAP_m: 0.6620  coco/bbox_mAP_l: 0.8160  data_time: 0.0029  time: 0.0807
2025/05/12 19:27:05 - mmengine - INFO - Epoch(train) [10][  50/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:52:04  time: 0.3234  data_time: 0.0032  memory: 19498  loss: 0.4049  loss_cls: 0.1948  loss_bbox: 0.2101
2025/05/12 19:27:20 - mmengine - INFO - Epoch(train) [10][ 100/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:51:49  time: 0.3147  data_time: 0.0006  memory: 19496  loss: 0.4143  loss_cls: 0.1924  loss_bbox: 0.2218
2025/05/12 19:27:36 - mmengine - INFO - Epoch(train) [10][ 150/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:51:33  time: 0.3092  data_time: 0.0005  memory: 19489  loss: 0.4520  loss_cls: 0.2070  loss_bbox: 0.2450
2025/05/12 19:27:51 - mmengine - INFO - Epoch(train) [10][ 200/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:51:17  time: 0.3099  data_time: 0.0006  memory: 19487  loss: 0.4203  loss_cls: 0.1934  loss_bbox: 0.2269
2025/05/12 19:28:07 - mmengine - INFO - Epoch(train) [10][ 250/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:51:02  time: 0.3137  data_time: 0.0006  memory: 19511  loss: 0.4107  loss_cls: 0.1930  loss_bbox: 0.2177
2025/05/12 19:28:22 - mmengine - INFO - Epoch(train) [10][ 300/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:50:45  time: 0.3075  data_time: 0.0006  memory: 19498  loss: 0.4199  loss_cls: 0.1972  loss_bbox: 0.2227
2025/05/12 19:28:34 - mmengine - INFO - Exp name: rtmdet_m_1x_custom_resume_20250512_185352
2025/05/12 19:28:38 - mmengine - INFO - Epoch(train) [10][ 350/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:50:29  time: 0.3103  data_time: 0.0006  memory: 19495  loss: 0.4189  loss_cls: 0.2002  loss_bbox: 0.2187
2025/05/12 19:28:54 - mmengine - INFO - Epoch(train) [10][ 400/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:50:15  time: 0.3165  data_time: 0.0006  memory: 19491  loss: 0.4161  loss_cls: 0.1932  loss_bbox: 0.2229
2025/05/12 19:29:09 - mmengine - INFO - Epoch(train) [10][ 450/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:49:59  time: 0.3114  data_time: 0.0005  memory: 19472  loss: 0.4294  loss_cls: 0.2037  loss_bbox: 0.2256
2025/05/12 19:29:25 - mmengine - INFO - Epoch(train) [10][ 500/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:49:44  time: 0.3128  data_time: 0.0005  memory: 19509  loss: 0.4091  loss_cls: 0.1873  loss_bbox: 0.2219
2025/05/12 19:29:40 - mmengine - INFO - Epoch(train) [10][ 550/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:49:28  time: 0.3090  data_time: 0.0005  memory: 19507  loss: 0.4105  loss_cls: 0.1935  loss_bbox: 0.2170
2025/05/12 19:29:56 - mmengine - INFO - Epoch(train) [10][ 600/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:49:11  time: 0.3068  data_time: 0.0005  memory: 19500  loss: 0.4266  loss_cls: 0.1984  loss_bbox: 0.2282
2025/05/12 19:30:11 - mmengine - INFO - Epoch(train) [10][ 650/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:48:54  time: 0.3055  data_time: 0.0005  memory: 19509  loss: 0.4371  loss_cls: 0.2100  loss_bbox: 0.2271
2025/05/12 19:30:26 - mmengine - INFO - Epoch(train) [10][ 700/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:48:37  time: 0.3072  data_time: 0.0005  memory: 19498  loss: 0.4072  loss_cls: 0.1930  loss_bbox: 0.2142
2025/05/12 19:30:42 - mmengine - INFO - Epoch(train) [10][ 750/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:48:20  time: 0.3032  data_time: 0.0004  memory: 19508  loss: 0.4324  loss_cls: 0.2068  loss_bbox: 0.2256
2025/05/12 19:30:57 - mmengine - INFO - Epoch(train) [10][ 800/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:48:01  time: 0.2995  data_time: 0.0004  memory: 19515  loss: 0.4030  loss_cls: 0.1826  loss_bbox: 0.2204
2025/05/12 19:31:12 - mmengine - INFO - Epoch(train) [10][ 850/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:47:44  time: 0.3027  data_time: 0.0005  memory: 19493  loss: 0.4052  loss_cls: 0.1927  loss_bbox: 0.2126
2025/05/12 19:31:27 - mmengine - INFO - Epoch(train) [10][ 900/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:47:27  time: 0.3042  data_time: 0.0005  memory: 19484  loss: 0.4227  loss_cls: 0.2019  loss_bbox: 0.2208
2025/05/12 19:31:43 - mmengine - INFO - Epoch(train) [10][ 950/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:47:12  time: 0.3144  data_time: 0.0005  memory: 19501  loss: 0.4457  loss_cls: 0.2084  loss_bbox: 0.2373
2025/05/12 19:31:59 - mmengine - INFO - Epoch(train) [10][1000/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:46:58  time: 0.3196  data_time: 0.0006  memory: 19480  loss: 0.4308  loss_cls: 0.2079  loss_bbox: 0.2229
2025/05/12 19:32:14 - mmengine - INFO - Epoch(train) [10][1050/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:46:44  time: 0.3171  data_time: 0.0005  memory: 19480  loss: 0.4069  loss_cls: 0.1870  loss_bbox: 0.2198
2025/05/12 19:32:31 - mmengine - INFO - Epoch(train) [10][1100/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:46:31  time: 0.3228  data_time: 0.0006  memory: 19481  loss: 0.4104  loss_cls: 0.1928  loss_bbox: 0.2176
2025/05/12 19:32:46 - mmengine - INFO - Epoch(train) [10][1150/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:46:14  time: 0.3062  data_time: 0.0005  memory: 19510  loss: 0.4080  loss_cls: 0.1847  loss_bbox: 0.2233
2025/05/12 19:33:02 - mmengine - INFO - Epoch(train) [10][1200/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:45:59  time: 0.3153  data_time: 0.0005  memory: 19489  loss: 0.4448  loss_cls: 0.2115  loss_bbox: 0.2333
2025/05/12 19:33:17 - mmengine - INFO - Epoch(train) [10][1250/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:45:43  time: 0.3107  data_time: 0.0005  memory: 19509  loss: 0.4305  loss_cls: 0.2031  loss_bbox: 0.2274
2025/05/12 19:33:33 - mmengine - INFO - Epoch(train) [10][1300/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:45:29  time: 0.3160  data_time: 0.0006  memory: 19517  loss: 0.4057  loss_cls: 0.1904  loss_bbox: 0.2153
2025/05/12 19:33:45 - mmengine - INFO - Exp name: rtmdet_m_1x_custom_resume_20250512_185352
2025/05/12 19:33:49 - mmengine - INFO - Epoch(train) [10][1350/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:45:14  time: 0.3163  data_time: 0.0006  memory: 19499  loss: 0.4450  loss_cls: 0.2122  loss_bbox: 0.2328
2025/05/12 19:34:05 - mmengine - INFO - Epoch(train) [10][1400/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:45:00  time: 0.3185  data_time: 0.0005  memory: 19491  loss: 0.4176  loss_cls: 0.2006  loss_bbox: 0.2170
2025/05/12 19:34:20 - mmengine - INFO - Epoch(train) [10][1450/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:44:45  time: 0.3151  data_time: 0.0005  memory: 19511  loss: 0.4503  loss_cls: 0.2171  loss_bbox: 0.2332
2025/05/12 19:34:37 - mmengine - INFO - Epoch(train) [10][1500/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:44:33  time: 0.3247  data_time: 0.0006  memory: 19498  loss: 0.4270  loss_cls: 0.2016  loss_bbox: 0.2254
2025/05/12 19:34:46 - mmengine - INFO - Exp name: rtmdet_m_1x_custom_resume_20250512_185352
2025/05/12 19:34:46 - mmengine - INFO - Saving checkpoint at 10 epochs
2025/05/12 19:34:50 - mmengine - INFO - Epoch(val) [10][ 50/149]    eta: 0:00:08  time: 0.0825  data_time: 0.0034  memory: 19481  
2025/05/12 19:34:54 - mmengine - INFO - Epoch(val) [10][100/149]    eta: 0:00:04  time: 0.0836  data_time: 0.0025  memory: 1598  
2025/05/12 19:35:00 - mmengine - INFO - Evaluating bbox...
2025/05/12 19:35:02 - mmengine - INFO - bbox_mAP_copypaste: 0.772 0.942 0.862 0.462 0.664 0.814
2025/05/12 19:35:02 - mmengine - INFO - Epoch(val) [10][149/149]    coco/bbox_mAP: 0.7720  coco/bbox_mAP_50: 0.9420  coco/bbox_mAP_75: 0.8620  coco/bbox_mAP_s: 0.4620  coco/bbox_mAP_m: 0.6640  coco/bbox_mAP_l: 0.8140  data_time: 0.0029  time: 0.0820
2025/05/12 19:35:17 - mmengine - INFO - Epoch(train) [11][  50/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:44:07  time: 0.3014  data_time: 0.0029  memory: 19489  loss: 0.4002  loss_cls: 0.1803  loss_bbox: 0.2199
2025/05/12 19:35:34 - mmengine - INFO - Epoch(train) [11][ 100/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:43:54  time: 0.3256  data_time: 0.0006  memory: 19509  loss: 0.4346  loss_cls: 0.2045  loss_bbox: 0.2301
2025/05/12 19:35:50 - mmengine - INFO - Epoch(train) [11][ 150/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:43:40  time: 0.3184  data_time: 0.0006  memory: 19511  loss: 0.4041  loss_cls: 0.1892  loss_bbox: 0.2149
2025/05/12 19:36:05 - mmengine - INFO - Epoch(train) [11][ 200/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:43:24  time: 0.3121  data_time: 0.0006  memory: 19497  loss: 0.4180  loss_cls: 0.1961  loss_bbox: 0.2219
2025/05/12 19:36:21 - mmengine - INFO - Epoch(train) [11][ 250/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:43:10  time: 0.3210  data_time: 0.0006  memory: 19506  loss: 0.4371  loss_cls: 0.2051  loss_bbox: 0.2321
2025/05/12 19:36:37 - mmengine - INFO - Epoch(train) [11][ 300/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:42:56  time: 0.3198  data_time: 0.0006  memory: 19486  loss: 0.4345  loss_cls: 0.2087  loss_bbox: 0.2257
2025/05/12 19:36:53 - mmengine - INFO - Epoch(train) [11][ 350/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:42:42  time: 0.3187  data_time: 0.0006  memory: 19515  loss: 0.4217  loss_cls: 0.1947  loss_bbox: 0.2270
2025/05/12 19:37:09 - mmengine - INFO - Epoch(train) [11][ 400/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:42:26  time: 0.3083  data_time: 0.0006  memory: 19505  loss: 0.4391  loss_cls: 0.2081  loss_bbox: 0.2310
2025/05/12 19:37:24 - mmengine - INFO - Epoch(train) [11][ 450/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:42:10  time: 0.3086  data_time: 0.0005  memory: 19504  loss: 0.4149  loss_cls: 0.1914  loss_bbox: 0.2234
2025/05/12 19:37:40 - mmengine - INFO - Epoch(train) [11][ 500/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:41:55  time: 0.3184  data_time: 0.0005  memory: 19500  loss: 0.4350  loss_cls: 0.2079  loss_bbox: 0.2271
2025/05/12 19:37:56 - mmengine - INFO - Epoch(train) [11][ 550/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:41:40  time: 0.3140  data_time: 0.0006  memory: 19493  loss: 0.4070  loss_cls: 0.1869  loss_bbox: 0.2200
2025/05/12 19:38:11 - mmengine - INFO - Epoch(train) [11][ 600/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:41:25  time: 0.3146  data_time: 0.0006  memory: 19483  loss: 0.4338  loss_cls: 0.2015  loss_bbox: 0.2323
2025/05/12 19:38:27 - mmengine - INFO - Epoch(train) [11][ 650/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:41:08  time: 0.3062  data_time: 0.0006  memory: 19490  loss: 0.4139  loss_cls: 0.1907  loss_bbox: 0.2231
2025/05/12 19:38:42 - mmengine - INFO - Epoch(train) [11][ 700/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:40:53  time: 0.3125  data_time: 0.0006  memory: 19521  loss: 0.4318  loss_cls: 0.2028  loss_bbox: 0.2289
2025/05/12 19:38:58 - mmengine - INFO - Epoch(train) [11][ 750/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:40:37  time: 0.3117  data_time: 0.0005  memory: 19507  loss: 0.4228  loss_cls: 0.1978  loss_bbox: 0.2250
2025/05/12 19:39:14 - mmengine - INFO - Epoch(train) [11][ 800/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:40:21  time: 0.3101  data_time: 0.0005  memory: 19477  loss: 0.4312  loss_cls: 0.2065  loss_bbox: 0.2247
2025/05/12 19:39:17 - mmengine - INFO - Exp name: rtmdet_m_1x_custom_resume_20250512_185352
2025/05/12 19:39:29 - mmengine - INFO - Epoch(train) [11][ 850/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:40:07  time: 0.3196  data_time: 0.0006  memory: 19503  loss: 0.4137  loss_cls: 0.2020  loss_bbox: 0.2117
2025/05/12 19:39:45 - mmengine - INFO - Epoch(train) [11][ 900/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:39:50  time: 0.3011  data_time: 0.0005  memory: 19491  loss: 0.4067  loss_cls: 0.1880  loss_bbox: 0.2187
2025/05/12 19:40:00 - mmengine - INFO - Epoch(train) [11][ 950/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:39:34  time: 0.3140  data_time: 0.0006  memory: 19492  loss: 0.4243  loss_cls: 0.1969  loss_bbox: 0.2275
2025/05/12 19:40:16 - mmengine - INFO - Epoch(train) [11][1000/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:39:20  time: 0.3171  data_time: 0.0006  memory: 19482  loss: 0.4480  loss_cls: 0.2154  loss_bbox: 0.2326
2025/05/12 19:40:32 - mmengine - INFO - Epoch(train) [11][1050/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:39:05  time: 0.3156  data_time: 0.0006  memory: 19479  loss: 0.4370  loss_cls: 0.2168  loss_bbox: 0.2202
2025/05/12 19:40:48 - mmengine - INFO - Epoch(train) [11][1100/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:38:50  time: 0.3190  data_time: 0.0006  memory: 19479  loss: 0.4229  loss_cls: 0.2001  loss_bbox: 0.2228
2025/05/12 19:41:04 - mmengine - INFO - Epoch(train) [11][1150/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:38:36  time: 0.3161  data_time: 0.0007  memory: 19483  loss: 0.3986  loss_cls: 0.1814  loss_bbox: 0.2172
2025/05/12 19:41:19 - mmengine - INFO - Epoch(train) [11][1200/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:38:20  time: 0.3151  data_time: 0.0007  memory: 19491  loss: 0.4186  loss_cls: 0.1980  loss_bbox: 0.2206
2025/05/12 19:41:35 - mmengine - INFO - Epoch(train) [11][1250/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:38:06  time: 0.3171  data_time: 0.0006  memory: 19492  loss: 0.4102  loss_cls: 0.1940  loss_bbox: 0.2163
2025/05/12 19:41:51 - mmengine - INFO - Epoch(train) [11][1300/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:37:51  time: 0.3145  data_time: 0.0006  memory: 19513  loss: 0.4440  loss_cls: 0.2077  loss_bbox: 0.2363
2025/05/12 19:42:06 - mmengine - INFO - Epoch(train) [11][1350/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:37:34  time: 0.3081  data_time: 0.0006  memory: 19511  loss: 0.4081  loss_cls: 0.1897  loss_bbox: 0.2184
2025/05/12 19:42:22 - mmengine - INFO - Epoch(train) [11][1400/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:37:20  time: 0.3207  data_time: 0.0006  memory: 19493  loss: 0.4376  loss_cls: 0.2059  loss_bbox: 0.2317
2025/05/12 19:42:38 - mmengine - INFO - Epoch(train) [11][1450/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:37:06  time: 0.3196  data_time: 0.0007  memory: 19475  loss: 0.4297  loss_cls: 0.1995  loss_bbox: 0.2302
2025/05/12 19:42:54 - mmengine - INFO - Epoch(train) [11][1500/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:36:50  time: 0.3110  data_time: 0.0006  memory: 19485  loss: 0.3962  loss_cls: 0.1798  loss_bbox: 0.2165
2025/05/12 19:43:03 - mmengine - INFO - Exp name: rtmdet_m_1x_custom_resume_20250512_185352
2025/05/12 19:43:03 - mmengine - INFO - Saving checkpoint at 11 epochs
2025/05/12 19:43:07 - mmengine - INFO - Epoch(val) [11][ 50/149]    eta: 0:00:08  time: 0.0826  data_time: 0.0034  memory: 19504  
2025/05/12 19:43:11 - mmengine - INFO - Epoch(val) [11][100/149]    eta: 0:00:04  time: 0.0843  data_time: 0.0027  memory: 1598  
2025/05/12 19:43:17 - mmengine - INFO - Evaluating bbox...
2025/05/12 19:43:20 - mmengine - INFO - bbox_mAP_copypaste: 0.773 0.941 0.861 0.455 0.665 0.816
2025/05/12 19:43:20 - mmengine - INFO - Epoch(val) [11][149/149]    coco/bbox_mAP: 0.7730  coco/bbox_mAP_50: 0.9410  coco/bbox_mAP_75: 0.8610  coco/bbox_mAP_s: 0.4550  coco/bbox_mAP_m: 0.6650  coco/bbox_mAP_l: 0.8160  data_time: 0.0029  time: 0.0819
2025/05/12 19:43:35 - mmengine - INFO - Epoch(train) [12][  50/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:36:25  time: 0.3092  data_time: 0.0034  memory: 19487  loss: 0.4126  loss_cls: 0.1939  loss_bbox: 0.2187
2025/05/12 19:43:51 - mmengine - INFO - Epoch(train) [12][ 100/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:36:10  time: 0.3169  data_time: 0.0007  memory: 19482  loss: 0.4040  loss_cls: 0.1899  loss_bbox: 0.2141
2025/05/12 19:44:06 - mmengine - INFO - Epoch(train) [12][ 150/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:35:54  time: 0.3087  data_time: 0.0006  memory: 19508  loss: 0.4255  loss_cls: 0.1913  loss_bbox: 0.2342
2025/05/12 19:44:23 - mmengine - INFO - Epoch(train) [12][ 200/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:35:41  time: 0.3253  data_time: 0.0007  memory: 19484  loss: 0.4223  loss_cls: 0.1918  loss_bbox: 0.2306
2025/05/12 19:44:39 - mmengine - INFO - Epoch(train) [12][ 250/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:35:27  time: 0.3242  data_time: 0.0006  memory: 19484  loss: 0.4144  loss_cls: 0.1930  loss_bbox: 0.2214
2025/05/12 19:44:49 - mmengine - INFO - Exp name: rtmdet_m_1x_custom_resume_20250512_185352
2025/05/12 19:44:55 - mmengine - INFO - Epoch(train) [12][ 300/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:35:13  time: 0.3191  data_time: 0.0006  memory: 19505  loss: 0.4163  loss_cls: 0.1933  loss_bbox: 0.2230
2025/05/12 19:45:11 - mmengine - INFO - Epoch(train) [12][ 350/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:34:58  time: 0.3178  data_time: 0.0006  memory: 19510  loss: 0.4170  loss_cls: 0.1957  loss_bbox: 0.2213
2025/05/12 19:45:26 - mmengine - INFO - Epoch(train) [12][ 400/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:34:42  time: 0.3134  data_time: 0.0006  memory: 19502  loss: 0.4345  loss_cls: 0.2059  loss_bbox: 0.2286
2025/05/12 19:45:42 - mmengine - INFO - Epoch(train) [12][ 450/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:34:28  time: 0.3176  data_time: 0.0006  memory: 19502  loss: 0.4391  loss_cls: 0.2070  loss_bbox: 0.2321
2025/05/12 19:45:58 - mmengine - INFO - Epoch(train) [12][ 500/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:34:13  time: 0.3191  data_time: 0.0006  memory: 19483  loss: 0.4289  loss_cls: 0.2062  loss_bbox: 0.2228
2025/05/12 19:46:15 - mmengine - INFO - Epoch(train) [12][ 550/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:34:00  time: 0.3298  data_time: 0.0006  memory: 19506  loss: 0.4175  loss_cls: 0.1944  loss_bbox: 0.2231
2025/05/12 19:46:30 - mmengine - INFO - Epoch(train) [12][ 600/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:33:44  time: 0.3123  data_time: 0.0007  memory: 19482  loss: 0.4145  loss_cls: 0.1947  loss_bbox: 0.2198
2025/05/12 19:46:45 - mmengine - INFO - Epoch(train) [12][ 650/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:33:27  time: 0.3027  data_time: 0.0006  memory: 19476  loss: 0.3995  loss_cls: 0.1864  loss_bbox: 0.2131
2025/05/12 19:47:00 - mmengine - INFO - Epoch(train) [12][ 700/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:33:10  time: 0.3015  data_time: 0.0006  memory: 19504  loss: 0.4212  loss_cls: 0.1989  loss_bbox: 0.2223
2025/05/12 19:47:16 - mmengine - INFO - Epoch(train) [12][ 750/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:32:53  time: 0.3040  data_time: 0.0006  memory: 19489  loss: 0.4183  loss_cls: 0.1962  loss_bbox: 0.2221
2025/05/12 19:47:31 - mmengine - INFO - Epoch(train) [12][ 800/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:32:36  time: 0.2992  data_time: 0.0005  memory: 19500  loss: 0.4431  loss_cls: 0.2119  loss_bbox: 0.2312
2025/05/12 19:47:46 - mmengine - INFO - Epoch(train) [12][ 850/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:32:19  time: 0.3044  data_time: 0.0006  memory: 19485  loss: 0.4165  loss_cls: 0.1940  loss_bbox: 0.2225
2025/05/12 19:48:01 - mmengine - INFO - Epoch(train) [12][ 900/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:32:01  time: 0.2994  data_time: 0.0006  memory: 19513  loss: 0.4340  loss_cls: 0.2085  loss_bbox: 0.2254
2025/05/12 19:48:16 - mmengine - INFO - Epoch(train) [12][ 950/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:31:45  time: 0.3045  data_time: 0.0006  memory: 19504  loss: 0.4069  loss_cls: 0.1901  loss_bbox: 0.2168
2025/05/12 19:48:31 - mmengine - INFO - Epoch(train) [12][1000/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:31:27  time: 0.2992  data_time: 0.0006  memory: 19490  loss: 0.4219  loss_cls: 0.1998  loss_bbox: 0.2221
2025/05/12 19:48:46 - mmengine - INFO - Epoch(train) [12][1050/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:31:11  time: 0.3085  data_time: 0.0006  memory: 19513  loss: 0.4136  loss_cls: 0.1974  loss_bbox: 0.2162
2025/05/12 19:49:01 - mmengine - INFO - Epoch(train) [12][1100/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:30:53  time: 0.2979  data_time: 0.0005  memory: 19499  loss: 0.4177  loss_cls: 0.1995  loss_bbox: 0.2183
2025/05/12 19:49:16 - mmengine - INFO - Epoch(train) [12][1150/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:30:36  time: 0.3021  data_time: 0.0005  memory: 19503  loss: 0.4334  loss_cls: 0.2094  loss_bbox: 0.2240
2025/05/12 19:49:31 - mmengine - INFO - Epoch(train) [12][1200/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:30:19  time: 0.3002  data_time: 0.0005  memory: 19495  loss: 0.4132  loss_cls: 0.1920  loss_bbox: 0.2211
2025/05/12 19:49:46 - mmengine - INFO - Epoch(train) [12][1250/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:30:02  time: 0.3008  data_time: 0.0005  memory: 19475  loss: 0.4172  loss_cls: 0.1946  loss_bbox: 0.2226
2025/05/12 19:49:56 - mmengine - INFO - Exp name: rtmdet_m_1x_custom_resume_20250512_185352
2025/05/12 19:50:01 - mmengine - INFO - Epoch(train) [12][1300/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:29:45  time: 0.2995  data_time: 0.0006  memory: 19486  loss: 0.4139  loss_cls: 0.1994  loss_bbox: 0.2146
2025/05/12 19:50:17 - mmengine - INFO - Epoch(train) [12][1350/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:29:28  time: 0.3010  data_time: 0.0005  memory: 19509  loss: 0.4219  loss_cls: 0.1961  loss_bbox: 0.2258
2025/05/12 19:50:32 - mmengine - INFO - Epoch(train) [12][1400/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:29:11  time: 0.3017  data_time: 0.0006  memory: 19510  loss: 0.4277  loss_cls: 0.2002  loss_bbox: 0.2274
2025/05/12 19:50:47 - mmengine - INFO - Epoch(train) [12][1450/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:28:54  time: 0.3004  data_time: 0.0005  memory: 19503  loss: 0.4248  loss_cls: 0.1993  loss_bbox: 0.2255
2025/05/12 19:51:02 - mmengine - INFO - Epoch(train) [12][1500/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:28:37  time: 0.3041  data_time: 0.0006  memory: 19507  loss: 0.4188  loss_cls: 0.1997  loss_bbox: 0.2191
2025/05/12 19:51:10 - mmengine - INFO - Exp name: rtmdet_m_1x_custom_resume_20250512_185352
2025/05/12 19:51:10 - mmengine - INFO - Saving checkpoint at 12 epochs
2025/05/12 19:51:15 - mmengine - INFO - Epoch(val) [12][ 50/149]    eta: 0:00:07  time: 0.0787  data_time: 0.0033  memory: 19496  
2025/05/12 19:51:19 - mmengine - INFO - Epoch(val) [12][100/149]    eta: 0:00:03  time: 0.0820  data_time: 0.0027  memory: 1598  
2025/05/12 19:51:24 - mmengine - INFO - Evaluating bbox...
2025/05/12 19:51:27 - mmengine - INFO - bbox_mAP_copypaste: 0.773 0.942 0.861 0.453 0.666 0.816
2025/05/12 19:51:27 - mmengine - INFO - Epoch(val) [12][149/149]    coco/bbox_mAP: 0.7730  coco/bbox_mAP_50: 0.9420  coco/bbox_mAP_75: 0.8610  coco/bbox_mAP_s: 0.4530  coco/bbox_mAP_m: 0.6660  coco/bbox_mAP_l: 0.8160  data_time: 0.0028  time: 0.0796
2025/05/12 19:51:42 - mmengine - INFO - Epoch(train) [13][  50/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:28:11  time: 0.3085  data_time: 0.0035  memory: 19503  loss: 0.4103  loss_cls: 0.1949  loss_bbox: 0.2154
2025/05/12 19:51:57 - mmengine - INFO - Epoch(train) [13][ 100/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:27:55  time: 0.3042  data_time: 0.0006  memory: 19517  loss: 0.4298  loss_cls: 0.1986  loss_bbox: 0.2312
2025/05/12 19:52:13 - mmengine - INFO - Epoch(train) [13][ 150/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:27:39  time: 0.3077  data_time: 0.0007  memory: 19489  loss: 0.4334  loss_cls: 0.2035  loss_bbox: 0.2300
2025/05/12 19:52:28 - mmengine - INFO - Epoch(train) [13][ 200/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:27:23  time: 0.3084  data_time: 0.0007  memory: 19481  loss: 0.4256  loss_cls: 0.2023  loss_bbox: 0.2232
2025/05/12 19:52:44 - mmengine - INFO - Epoch(train) [13][ 250/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:27:07  time: 0.3113  data_time: 0.0007  memory: 19500  loss: 0.4217  loss_cls: 0.1962  loss_bbox: 0.2255
2025/05/12 19:52:59 - mmengine - INFO - Epoch(train) [13][ 300/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:26:51  time: 0.3078  data_time: 0.0006  memory: 19506  loss: 0.4178  loss_cls: 0.1929  loss_bbox: 0.2249
2025/05/12 19:53:14 - mmengine - INFO - Epoch(train) [13][ 350/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:26:35  time: 0.3079  data_time: 0.0006  memory: 19509  loss: 0.4161  loss_cls: 0.1969  loss_bbox: 0.2192
2025/05/12 19:53:29 - mmengine - INFO - Epoch(train) [13][ 400/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:26:18  time: 0.3010  data_time: 0.0005  memory: 19492  loss: 0.4500  loss_cls: 0.2195  loss_bbox: 0.2305
2025/05/12 19:53:45 - mmengine - INFO - Epoch(train) [13][ 450/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:26:02  time: 0.3046  data_time: 0.0005  memory: 19490  loss: 0.4359  loss_cls: 0.2094  loss_bbox: 0.2265
2025/05/12 19:54:00 - mmengine - INFO - Epoch(train) [13][ 500/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:25:45  time: 0.2990  data_time: 0.0006  memory: 19518  loss: 0.4231  loss_cls: 0.1995  loss_bbox: 0.2235
2025/05/12 19:54:15 - mmengine - INFO - Epoch(train) [13][ 550/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:25:28  time: 0.3047  data_time: 0.0006  memory: 19500  loss: 0.4017  loss_cls: 0.1851  loss_bbox: 0.2166
2025/05/12 19:54:30 - mmengine - INFO - Epoch(train) [13][ 600/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:25:11  time: 0.2990  data_time: 0.0006  memory: 19496  loss: 0.4212  loss_cls: 0.1925  loss_bbox: 0.2288
2025/05/12 19:54:45 - mmengine - INFO - Epoch(train) [13][ 650/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:24:55  time: 0.3043  data_time: 0.0006  memory: 19479  loss: 0.3960  loss_cls: 0.1831  loss_bbox: 0.2129
2025/05/12 19:55:00 - mmengine - INFO - Epoch(train) [13][ 700/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:24:39  time: 0.3075  data_time: 0.0006  memory: 19509  loss: 0.4178  loss_cls: 0.1932  loss_bbox: 0.2246
2025/05/12 19:55:16 - mmengine - INFO - Epoch(train) [13][ 750/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:24:23  time: 0.3126  data_time: 0.0006  memory: 19484  loss: 0.4329  loss_cls: 0.2042  loss_bbox: 0.2287
2025/05/12 19:55:17 - mmengine - INFO - Exp name: rtmdet_m_1x_custom_resume_20250512_185352
2025/05/12 19:55:31 - mmengine - INFO - Epoch(train) [13][ 800/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:24:07  time: 0.3035  data_time: 0.0007  memory: 19475  loss: 0.4177  loss_cls: 0.1921  loss_bbox: 0.2255
2025/05/12 19:55:47 - mmengine - INFO - Epoch(train) [13][ 850/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:23:51  time: 0.3091  data_time: 0.0006  memory: 19483  loss: 0.4122  loss_cls: 0.1947  loss_bbox: 0.2175
2025/05/12 19:56:02 - mmengine - INFO - Epoch(train) [13][ 900/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:23:35  time: 0.3067  data_time: 0.0007  memory: 19479  loss: 0.4129  loss_cls: 0.1957  loss_bbox: 0.2171
2025/05/12 19:56:17 - mmengine - INFO - Epoch(train) [13][ 950/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:23:19  time: 0.3067  data_time: 0.0006  memory: 19488  loss: 0.4234  loss_cls: 0.1959  loss_bbox: 0.2275
2025/05/12 19:56:33 - mmengine - INFO - Epoch(train) [13][1000/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:23:04  time: 0.3179  data_time: 0.0006  memory: 19482  loss: 0.4297  loss_cls: 0.2027  loss_bbox: 0.2270
2025/05/12 19:56:49 - mmengine - INFO - Epoch(train) [13][1050/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:22:50  time: 0.3206  data_time: 0.0006  memory: 19510  loss: 0.3901  loss_cls: 0.1853  loss_bbox: 0.2048
2025/05/12 19:57:05 - mmengine - INFO - Epoch(train) [13][1100/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:22:35  time: 0.3150  data_time: 0.0006  memory: 19502  loss: 0.4294  loss_cls: 0.2071  loss_bbox: 0.2223
2025/05/12 19:57:20 - mmengine - INFO - Epoch(train) [13][1150/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:22:19  time: 0.3077  data_time: 0.0005  memory: 19479  loss: 0.4258  loss_cls: 0.2007  loss_bbox: 0.2251
2025/05/12 19:57:36 - mmengine - INFO - Epoch(train) [13][1200/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:22:02  time: 0.3049  data_time: 0.0006  memory: 19492  loss: 0.4633  loss_cls: 0.2257  loss_bbox: 0.2376
2025/05/12 19:57:51 - mmengine - INFO - Epoch(train) [13][1250/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:21:46  time: 0.3042  data_time: 0.0005  memory: 19484  loss: 0.4199  loss_cls: 0.1917  loss_bbox: 0.2282
2025/05/12 19:58:07 - mmengine - INFO - Epoch(train) [13][1300/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:21:31  time: 0.3186  data_time: 0.0006  memory: 19511  loss: 0.4371  loss_cls: 0.2133  loss_bbox: 0.2238
2025/05/12 19:58:22 - mmengine - INFO - Epoch(train) [13][1350/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:21:15  time: 0.3071  data_time: 0.0006  memory: 19509  loss: 0.3973  loss_cls: 0.1803  loss_bbox: 0.2170
2025/05/12 19:58:38 - mmengine - INFO - Epoch(train) [13][1400/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:21:01  time: 0.3180  data_time: 0.0006  memory: 19510  loss: 0.4062  loss_cls: 0.1916  loss_bbox: 0.2146
2025/05/12 19:58:55 - mmengine - INFO - Epoch(train) [13][1450/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:20:48  time: 0.3335  data_time: 0.0007  memory: 19481  loss: 0.4068  loss_cls: 0.1889  loss_bbox: 0.2178
2025/05/12 19:59:11 - mmengine - INFO - Epoch(train) [13][1500/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:20:33  time: 0.3188  data_time: 0.0006  memory: 19511  loss: 0.4492  loss_cls: 0.2117  loss_bbox: 0.2374
2025/05/12 19:59:19 - mmengine - INFO - Exp name: rtmdet_m_1x_custom_resume_20250512_185352
2025/05/12 19:59:19 - mmengine - INFO - Saving checkpoint at 13 epochs
2025/05/12 19:59:24 - mmengine - INFO - Epoch(val) [13][ 50/149]    eta: 0:00:08  time: 0.0818  data_time: 0.0038  memory: 19471  
2025/05/12 19:59:28 - mmengine - INFO - Epoch(val) [13][100/149]    eta: 0:00:03  time: 0.0803  data_time: 0.0025  memory: 1598  
2025/05/12 19:59:33 - mmengine - INFO - Evaluating bbox...
2025/05/12 19:59:36 - mmengine - INFO - bbox_mAP_copypaste: 0.774 0.941 0.864 0.455 0.666 0.817
2025/05/12 19:59:36 - mmengine - INFO - Epoch(val) [13][149/149]    coco/bbox_mAP: 0.7740  coco/bbox_mAP_50: 0.9410  coco/bbox_mAP_75: 0.8640  coco/bbox_mAP_s: 0.4550  coco/bbox_mAP_m: 0.6660  coco/bbox_mAP_l: 0.8170  data_time: 0.0030  time: 0.0808
2025/05/12 19:59:53 - mmengine - INFO - Epoch(train) [14][  50/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:20:10  time: 0.3289  data_time: 0.0023  memory: 19508  loss: 0.4644  loss_cls: 0.2253  loss_bbox: 0.2391
2025/05/12 20:00:09 - mmengine - INFO - Epoch(train) [14][ 100/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:19:56  time: 0.3201  data_time: 0.0006  memory: 19509  loss: 0.4113  loss_cls: 0.1891  loss_bbox: 0.2222
2025/05/12 20:00:25 - mmengine - INFO - Epoch(train) [14][ 150/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:19:41  time: 0.3192  data_time: 0.0006  memory: 19515  loss: 0.4234  loss_cls: 0.1986  loss_bbox: 0.2248
2025/05/12 20:00:41 - mmengine - INFO - Epoch(train) [14][ 200/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:19:26  time: 0.3198  data_time: 0.0007  memory: 19502  loss: 0.4094  loss_cls: 0.1949  loss_bbox: 0.2145
2025/05/12 20:00:49 - mmengine - INFO - Exp name: rtmdet_m_1x_custom_resume_20250512_185352
2025/05/12 20:00:56 - mmengine - INFO - Epoch(train) [14][ 250/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:19:11  time: 0.3132  data_time: 0.0007  memory: 19491  loss: 0.4466  loss_cls: 0.2106  loss_bbox: 0.2360
2025/05/12 20:01:12 - mmengine - INFO - Epoch(train) [14][ 300/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:18:56  time: 0.3129  data_time: 0.0006  memory: 19484  loss: 0.4074  loss_cls: 0.1889  loss_bbox: 0.2185
2025/05/12 20:01:27 - mmengine - INFO - Epoch(train) [14][ 350/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:18:39  time: 0.3062  data_time: 0.0006  memory: 19484  loss: 0.4135  loss_cls: 0.1843  loss_bbox: 0.2292
2025/05/12 20:01:42 - mmengine - INFO - Epoch(train) [14][ 400/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:18:23  time: 0.3030  data_time: 0.0006  memory: 19509  loss: 0.4108  loss_cls: 0.1879  loss_bbox: 0.2229
2025/05/12 20:01:58 - mmengine - INFO - Epoch(train) [14][ 450/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:18:07  time: 0.3033  data_time: 0.0006  memory: 19480  loss: 0.4138  loss_cls: 0.1876  loss_bbox: 0.2262
2025/05/12 20:02:13 - mmengine - INFO - Epoch(train) [14][ 500/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:17:51  time: 0.3070  data_time: 0.0006  memory: 19479  loss: 0.4093  loss_cls: 0.1852  loss_bbox: 0.2241
2025/05/12 20:02:28 - mmengine - INFO - Epoch(train) [14][ 550/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:17:34  time: 0.3039  data_time: 0.0006  memory: 19510  loss: 0.4523  loss_cls: 0.2163  loss_bbox: 0.2360
2025/05/12 20:02:43 - mmengine - INFO - Epoch(train) [14][ 600/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:17:18  time: 0.3082  data_time: 0.0006  memory: 19475  loss: 0.4524  loss_cls: 0.2247  loss_bbox: 0.2277
2025/05/12 20:02:59 - mmengine - INFO - Epoch(train) [14][ 650/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:17:02  time: 0.3043  data_time: 0.0006  memory: 19493  loss: 0.4120  loss_cls: 0.1884  loss_bbox: 0.2236
2025/05/12 20:03:14 - mmengine - INFO - Epoch(train) [14][ 700/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:16:45  time: 0.3012  data_time: 0.0006  memory: 19490  loss: 0.4197  loss_cls: 0.1914  loss_bbox: 0.2283
2025/05/12 20:03:29 - mmengine - INFO - Epoch(train) [14][ 750/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:16:30  time: 0.3094  data_time: 0.0006  memory: 19487  loss: 0.4042  loss_cls: 0.1910  loss_bbox: 0.2132
2025/05/12 20:03:46 - mmengine - INFO - Epoch(train) [14][ 800/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:16:16  time: 0.3272  data_time: 0.0007  memory: 19493  loss: 0.4119  loss_cls: 0.1981  loss_bbox: 0.2138
2025/05/12 20:04:02 - mmengine - INFO - Epoch(train) [14][ 850/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:16:01  time: 0.3217  data_time: 0.0006  memory: 19504  loss: 0.4154  loss_cls: 0.1993  loss_bbox: 0.2162
2025/05/12 20:04:18 - mmengine - INFO - Epoch(train) [14][ 900/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:15:46  time: 0.3191  data_time: 0.0007  memory: 19480  loss: 0.4192  loss_cls: 0.1953  loss_bbox: 0.2239
2025/05/12 20:04:33 - mmengine - INFO - Epoch(train) [14][ 950/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:15:31  time: 0.3117  data_time: 0.0006  memory: 19488  loss: 0.4102  loss_cls: 0.1905  loss_bbox: 0.2196
2025/05/12 20:04:49 - mmengine - INFO - Epoch(train) [14][1000/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:15:15  time: 0.3126  data_time: 0.0006  memory: 19485  loss: 0.4438  loss_cls: 0.2126  loss_bbox: 0.2312
2025/05/12 20:05:04 - mmengine - INFO - Epoch(train) [14][1050/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:15:00  time: 0.3103  data_time: 0.0006  memory: 19515  loss: 0.4170  loss_cls: 0.1949  loss_bbox: 0.2221
2025/05/12 20:05:20 - mmengine - INFO - Epoch(train) [14][1100/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:14:43  time: 0.3029  data_time: 0.0006  memory: 19487  loss: 0.4003  loss_cls: 0.1891  loss_bbox: 0.2112
2025/05/12 20:05:35 - mmengine - INFO - Epoch(train) [14][1150/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:14:27  time: 0.3052  data_time: 0.0006  memory: 19487  loss: 0.4180  loss_cls: 0.1959  loss_bbox: 0.2221
2025/05/12 20:05:51 - mmengine - INFO - Epoch(train) [14][1200/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:14:12  time: 0.3166  data_time: 0.0006  memory: 19506  loss: 0.4069  loss_cls: 0.1952  loss_bbox: 0.2117
2025/05/12 20:05:59 - mmengine - INFO - Exp name: rtmdet_m_1x_custom_resume_20250512_185352
2025/05/12 20:06:06 - mmengine - INFO - Epoch(train) [14][1250/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:13:57  time: 0.3178  data_time: 0.0007  memory: 19478  loss: 0.4121  loss_cls: 0.1958  loss_bbox: 0.2163
2025/05/12 20:06:22 - mmengine - INFO - Epoch(train) [14][1300/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:13:41  time: 0.3085  data_time: 0.0006  memory: 19508  loss: 0.4020  loss_cls: 0.1888  loss_bbox: 0.2133
2025/05/12 20:06:38 - mmengine - INFO - Epoch(train) [14][1350/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:13:27  time: 0.3189  data_time: 0.0006  memory: 19500  loss: 0.4278  loss_cls: 0.2046  loss_bbox: 0.2232
2025/05/12 20:06:54 - mmengine - INFO - Epoch(train) [14][1400/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:13:12  time: 0.3207  data_time: 0.0006  memory: 19504  loss: 0.4182  loss_cls: 0.1988  loss_bbox: 0.2195
2025/05/12 20:07:09 - mmengine - INFO - Epoch(train) [14][1450/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:12:56  time: 0.3111  data_time: 0.0005  memory: 19504  loss: 0.4149  loss_cls: 0.1891  loss_bbox: 0.2257
2025/05/12 20:07:25 - mmengine - INFO - Epoch(train) [14][1500/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:12:41  time: 0.3141  data_time: 0.0006  memory: 19500  loss: 0.4047  loss_cls: 0.1907  loss_bbox: 0.2140
2025/05/12 20:07:34 - mmengine - INFO - Exp name: rtmdet_m_1x_custom_resume_20250512_185352
2025/05/12 20:07:34 - mmengine - INFO - Saving checkpoint at 14 epochs
2025/05/12 20:07:38 - mmengine - INFO - Epoch(val) [14][ 50/149]    eta: 0:00:08  time: 0.0822  data_time: 0.0039  memory: 19483  
2025/05/12 20:07:42 - mmengine - INFO - Epoch(val) [14][100/149]    eta: 0:00:03  time: 0.0798  data_time: 0.0026  memory: 1598  
2025/05/12 20:07:47 - mmengine - INFO - Evaluating bbox...
2025/05/12 20:07:50 - mmengine - INFO - bbox_mAP_copypaste: 0.774 0.941 0.862 0.452 0.664 0.817
2025/05/12 20:07:50 - mmengine - INFO - Epoch(val) [14][149/149]    coco/bbox_mAP: 0.7740  coco/bbox_mAP_50: 0.9410  coco/bbox_mAP_75: 0.8620  coco/bbox_mAP_s: 0.4520  coco/bbox_mAP_m: 0.6640  coco/bbox_mAP_l: 0.8170  data_time: 0.0030  time: 0.0801
2025/05/12 20:08:06 - mmengine - INFO - Epoch(train) [15][  50/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:12:17  time: 0.3204  data_time: 0.0030  memory: 19484  loss: 0.4040  loss_cls: 0.1890  loss_bbox: 0.2149
2025/05/12 20:08:22 - mmengine - INFO - Epoch(train) [15][ 100/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:12:02  time: 0.3182  data_time: 0.0006  memory: 19484  loss: 0.4038  loss_cls: 0.1868  loss_bbox: 0.2170
2025/05/12 20:08:38 - mmengine - INFO - Epoch(train) [15][ 150/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:11:47  time: 0.3183  data_time: 0.0006  memory: 19509  loss: 0.3997  loss_cls: 0.1895  loss_bbox: 0.2102
2025/05/12 20:08:54 - mmengine - INFO - Epoch(train) [15][ 200/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:11:32  time: 0.3163  data_time: 0.0006  memory: 19513  loss: 0.4441  loss_cls: 0.2108  loss_bbox: 0.2332
2025/05/12 20:09:09 - mmengine - INFO - Epoch(train) [15][ 250/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:11:16  time: 0.3045  data_time: 0.0006  memory: 19508  loss: 0.3919  loss_cls: 0.1842  loss_bbox: 0.2076
2025/05/12 20:09:24 - mmengine - INFO - Epoch(train) [15][ 300/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:11:00  time: 0.3068  data_time: 0.0006  memory: 19509  loss: 0.4131  loss_cls: 0.1931  loss_bbox: 0.2200
2025/05/12 20:09:40 - mmengine - INFO - Epoch(train) [15][ 350/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:10:44  time: 0.3066  data_time: 0.0006  memory: 19482  loss: 0.4295  loss_cls: 0.2077  loss_bbox: 0.2219
2025/05/12 20:09:55 - mmengine - INFO - Epoch(train) [15][ 400/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:10:28  time: 0.3079  data_time: 0.0006  memory: 19504  loss: 0.4124  loss_cls: 0.1965  loss_bbox: 0.2160
2025/05/12 20:10:11 - mmengine - INFO - Epoch(train) [15][ 450/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:10:12  time: 0.3119  data_time: 0.0006  memory: 19479  loss: 0.4108  loss_cls: 0.1881  loss_bbox: 0.2228
2025/05/12 20:10:26 - mmengine - INFO - Epoch(train) [15][ 500/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:09:57  time: 0.3122  data_time: 0.0006  memory: 19480  loss: 0.4269  loss_cls: 0.2029  loss_bbox: 0.2240
2025/05/12 20:10:42 - mmengine - INFO - Epoch(train) [15][ 550/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:09:41  time: 0.3111  data_time: 0.0006  memory: 19489  loss: 0.4186  loss_cls: 0.2016  loss_bbox: 0.2169
2025/05/12 20:10:58 - mmengine - INFO - Epoch(train) [15][ 600/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:09:26  time: 0.3205  data_time: 0.0006  memory: 19504  loss: 0.4267  loss_cls: 0.1990  loss_bbox: 0.2277
2025/05/12 20:11:14 - mmengine - INFO - Epoch(train) [15][ 650/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:09:12  time: 0.3223  data_time: 0.0006  memory: 19482  loss: 0.4365  loss_cls: 0.2047  loss_bbox: 0.2318
2025/05/12 20:11:29 - mmengine - INFO - Exp name: rtmdet_m_1x_custom_resume_20250512_185352
2025/05/12 20:11:30 - mmengine - INFO - Epoch(train) [15][ 700/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:08:57  time: 0.3215  data_time: 0.0006  memory: 19521  loss: 0.4466  loss_cls: 0.2063  loss_bbox: 0.2404
2025/05/12 20:11:46 - mmengine - INFO - Epoch(train) [15][ 750/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:08:42  time: 0.3177  data_time: 0.0007  memory: 19488  loss: 0.4306  loss_cls: 0.2104  loss_bbox: 0.2202
2025/05/12 20:12:01 - mmengine - INFO - Epoch(train) [15][ 800/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:08:26  time: 0.3093  data_time: 0.0007  memory: 19484  loss: 0.4452  loss_cls: 0.2100  loss_bbox: 0.2353
2025/05/12 20:12:18 - mmengine - INFO - Epoch(train) [15][ 850/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:08:12  time: 0.3266  data_time: 0.0007  memory: 19513  loss: 0.4260  loss_cls: 0.2062  loss_bbox: 0.2198
2025/05/12 20:12:34 - mmengine - INFO - Epoch(train) [15][ 900/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:07:57  time: 0.3194  data_time: 0.0007  memory: 19509  loss: 0.4243  loss_cls: 0.1991  loss_bbox: 0.2252
2025/05/12 20:12:50 - mmengine - INFO - Epoch(train) [15][ 950/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:07:42  time: 0.3214  data_time: 0.0007  memory: 19510  loss: 0.4104  loss_cls: 0.1920  loss_bbox: 0.2184
2025/05/12 20:13:05 - mmengine - INFO - Epoch(train) [15][1000/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:07:27  time: 0.3122  data_time: 0.0007  memory: 19489  loss: 0.4391  loss_cls: 0.2065  loss_bbox: 0.2326
2025/05/12 20:13:21 - mmengine - INFO - Epoch(train) [15][1050/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:07:11  time: 0.3070  data_time: 0.0006  memory: 19487  loss: 0.4202  loss_cls: 0.1955  loss_bbox: 0.2247
2025/05/12 20:13:36 - mmengine - INFO - Epoch(train) [15][1100/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:06:54  time: 0.3024  data_time: 0.0006  memory: 19496  loss: 0.4092  loss_cls: 0.1843  loss_bbox: 0.2249
2025/05/12 20:13:51 - mmengine - INFO - Epoch(train) [15][1150/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:06:38  time: 0.3010  data_time: 0.0006  memory: 19506  loss: 0.4047  loss_cls: 0.1832  loss_bbox: 0.2216
2025/05/12 20:14:06 - mmengine - INFO - Epoch(train) [15][1200/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:06:22  time: 0.3079  data_time: 0.0005  memory: 19484  loss: 0.4204  loss_cls: 0.1941  loss_bbox: 0.2263
2025/05/12 20:14:22 - mmengine - INFO - Epoch(train) [15][1250/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:06:07  time: 0.3169  data_time: 0.0005  memory: 19505  loss: 0.4230  loss_cls: 0.1953  loss_bbox: 0.2277
2025/05/12 20:14:38 - mmengine - INFO - Epoch(train) [15][1300/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:05:52  time: 0.3271  data_time: 0.0007  memory: 19492  loss: 0.4415  loss_cls: 0.2101  loss_bbox: 0.2314
2025/05/12 20:14:54 - mmengine - INFO - Epoch(train) [15][1350/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:05:37  time: 0.3173  data_time: 0.0006  memory: 19491  loss: 0.4105  loss_cls: 0.1868  loss_bbox: 0.2237
2025/05/12 20:15:10 - mmengine - INFO - Epoch(train) [15][1400/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:05:23  time: 0.3213  data_time: 0.0006  memory: 19509  loss: 0.3861  loss_cls: 0.1717  loss_bbox: 0.2144
2025/05/12 20:15:26 - mmengine - INFO - Epoch(train) [15][1450/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:05:08  time: 0.3192  data_time: 0.0007  memory: 19476  loss: 0.4140  loss_cls: 0.1954  loss_bbox: 0.2186
2025/05/12 20:15:42 - mmengine - INFO - Epoch(train) [15][1500/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:04:52  time: 0.3068  data_time: 0.0007  memory: 19498  loss: 0.4216  loss_cls: 0.1999  loss_bbox: 0.2217
2025/05/12 20:15:51 - mmengine - INFO - Exp name: rtmdet_m_1x_custom_resume_20250512_185352
2025/05/12 20:15:51 - mmengine - INFO - Saving checkpoint at 15 epochs
2025/05/12 20:15:55 - mmengine - INFO - Epoch(val) [15][ 50/149]    eta: 0:00:08  time: 0.0825  data_time: 0.0039  memory: 19508  
2025/05/12 20:15:59 - mmengine - INFO - Epoch(val) [15][100/149]    eta: 0:00:04  time: 0.0824  data_time: 0.0027  memory: 1598  
2025/05/12 20:16:05 - mmengine - INFO - Evaluating bbox...
2025/05/12 20:16:07 - mmengine - INFO - bbox_mAP_copypaste: 0.773 0.943 0.862 0.462 0.665 0.814
2025/05/12 20:16:08 - mmengine - INFO - Epoch(val) [15][149/149]    coco/bbox_mAP: 0.7730  coco/bbox_mAP_50: 0.9430  coco/bbox_mAP_75: 0.8620  coco/bbox_mAP_s: 0.4620  coco/bbox_mAP_m: 0.6650  coco/bbox_mAP_l: 0.8140  data_time: 0.0031  time: 0.0817
2025/05/12 20:16:23 - mmengine - INFO - Epoch(train) [16][  50/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:04:28  time: 0.3120  data_time: 0.0023  memory: 19503  loss: 0.4180  loss_cls: 0.2009  loss_bbox: 0.2171
2025/05/12 20:16:39 - mmengine - INFO - Epoch(train) [16][ 100/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:04:12  time: 0.3096  data_time: 0.0006  memory: 19504  loss: 0.4359  loss_cls: 0.2080  loss_bbox: 0.2279
2025/05/12 20:16:54 - mmengine - INFO - Epoch(train) [16][ 150/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:03:56  time: 0.3120  data_time: 0.0006  memory: 19495  loss: 0.4005  loss_cls: 0.1875  loss_bbox: 0.2130
2025/05/12 20:17:00 - mmengine - INFO - Exp name: rtmdet_m_1x_custom_resume_20250512_185352
2025/05/12 20:17:10 - mmengine - INFO - Epoch(train) [16][ 200/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:03:41  time: 0.3104  data_time: 0.0005  memory: 19504  loss: 0.4142  loss_cls: 0.1907  loss_bbox: 0.2235
2025/05/12 20:17:26 - mmengine - INFO - Epoch(train) [16][ 250/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:03:26  time: 0.3212  data_time: 0.0007  memory: 19485  loss: 0.3879  loss_cls: 0.1747  loss_bbox: 0.2132
2025/05/12 20:17:42 - mmengine - INFO - Epoch(train) [16][ 300/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:03:11  time: 0.3177  data_time: 0.0006  memory: 19513  loss: 0.4348  loss_cls: 0.2051  loss_bbox: 0.2297
2025/05/12 20:17:57 - mmengine - INFO - Epoch(train) [16][ 350/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:02:55  time: 0.3110  data_time: 0.0007  memory: 19476  loss: 0.4119  loss_cls: 0.1896  loss_bbox: 0.2223
2025/05/12 20:18:13 - mmengine - INFO - Epoch(train) [16][ 400/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:02:40  time: 0.3132  data_time: 0.0006  memory: 19477  loss: 0.4187  loss_cls: 0.1922  loss_bbox: 0.2265
2025/05/12 20:18:29 - mmengine - INFO - Epoch(train) [16][ 450/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:02:25  time: 0.3256  data_time: 0.0007  memory: 19480  loss: 0.3885  loss_cls: 0.1788  loss_bbox: 0.2097
2025/05/12 20:18:45 - mmengine - INFO - Epoch(train) [16][ 500/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:02:10  time: 0.3127  data_time: 0.0006  memory: 19499  loss: 0.4081  loss_cls: 0.1894  loss_bbox: 0.2187
2025/05/12 20:19:00 - mmengine - INFO - Epoch(train) [16][ 550/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:01:53  time: 0.2991  data_time: 0.0006  memory: 19500  loss: 0.4071  loss_cls: 0.1870  loss_bbox: 0.2201
2025/05/12 20:19:16 - mmengine - INFO - Epoch(train) [16][ 600/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:01:38  time: 0.3169  data_time: 0.0006  memory: 19514  loss: 0.4268  loss_cls: 0.2016  loss_bbox: 0.2252
2025/05/12 20:19:31 - mmengine - INFO - Epoch(train) [16][ 650/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:01:22  time: 0.3038  data_time: 0.0006  memory: 19482  loss: 0.4048  loss_cls: 0.1913  loss_bbox: 0.2135
2025/05/12 20:19:46 - mmengine - INFO - Epoch(train) [16][ 700/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:01:06  time: 0.3089  data_time: 0.0006  memory: 19511  loss: 0.4826  loss_cls: 0.2277  loss_bbox: 0.2548
2025/05/12 20:20:02 - mmengine - INFO - Epoch(train) [16][ 750/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:00:50  time: 0.3110  data_time: 0.0006  memory: 19511  loss: 0.4240  loss_cls: 0.1964  loss_bbox: 0.2275
2025/05/12 20:20:18 - mmengine - INFO - Epoch(train) [16][ 800/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:00:35  time: 0.3164  data_time: 0.0006  memory: 19515  loss: 0.4107  loss_cls: 0.1907  loss_bbox: 0.2200
2025/05/12 20:20:33 - mmengine - INFO - Epoch(train) [16][ 850/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:00:20  time: 0.3147  data_time: 0.0006  memory: 19479  loss: 0.4283  loss_cls: 0.2112  loss_bbox: 0.2171
2025/05/12 20:20:49 - mmengine - INFO - Epoch(train) [16][ 900/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:00:04  time: 0.3105  data_time: 0.0006  memory: 19481  loss: 0.4174  loss_cls: 0.1935  loss_bbox: 0.2240
2025/05/12 20:21:05 - mmengine - INFO - Epoch(train) [16][ 950/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 1:59:49  time: 0.3194  data_time: 0.0007  memory: 19488  loss: 0.4327  loss_cls: 0.2107  loss_bbox: 0.2220
2025/05/12 20:21:21 - mmengine - INFO - Epoch(train) [16][1000/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 1:59:33  time: 0.3145  data_time: 0.0006  memory: 19482  loss: 0.4096  loss_cls: 0.1919  loss_bbox: 0.2177
2025/05/12 20:21:36 - mmengine - INFO - Epoch(train) [16][1050/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 1:59:18  time: 0.3166  data_time: 0.0006  memory: 19510  loss: 0.4081  loss_cls: 0.1897  loss_bbox: 0.2184
2025/05/12 20:21:52 - mmengine - INFO - Epoch(train) [16][1100/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 1:59:03  time: 0.3130  data_time: 0.0006  memory: 19494  loss: 0.4588  loss_cls: 0.2152  loss_bbox: 0.2436
2025/05/12 20:22:08 - mmengine - INFO - Epoch(train) [16][1150/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 1:58:47  time: 0.3130  data_time: 0.0006  memory: 19481  loss: 0.4277  loss_cls: 0.2006  loss_bbox: 0.2271
2025/05/12 20:22:14 - mmengine - INFO - Exp name: rtmdet_m_1x_custom_resume_20250512_185352
2025/05/12 20:22:24 - mmengine - INFO - Epoch(train) [16][1200/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 1:58:33  time: 0.3279  data_time: 0.0007  memory: 19504  loss: 0.4331  loss_cls: 0.2121  loss_bbox: 0.2211
2025/05/12 20:22:39 - mmengine - INFO - Epoch(train) [16][1250/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 1:58:17  time: 0.3071  data_time: 0.0007  memory: 19507  loss: 0.4331  loss_cls: 0.2091  loss_bbox: 0.2240
2025/05/12 20:22:55 - mmengine - INFO - Epoch(train) [16][1300/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 1:58:01  time: 0.3128  data_time: 0.0007  memory: 19484  loss: 0.4108  loss_cls: 0.1870  loss_bbox: 0.2238
2025/05/12 20:23:11 - mmengine - INFO - Epoch(train) [16][1350/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 1:57:46  time: 0.3132  data_time: 0.0006  memory: 19488  loss: 0.4463  loss_cls: 0.2191  loss_bbox: 0.2272
2025/05/12 20:23:27 - mmengine - INFO - Epoch(train) [16][1400/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 1:57:31  time: 0.3208  data_time: 0.0007  memory: 19481  loss: 0.4116  loss_cls: 0.1960  loss_bbox: 0.2156
2025/05/12 20:23:42 - mmengine - INFO - Epoch(train) [16][1450/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 1:57:15  time: 0.3109  data_time: 0.0006  memory: 19502  loss: 0.4213  loss_cls: 0.1915  loss_bbox: 0.2298
2025/05/12 20:23:58 - mmengine - INFO - Epoch(train) [16][1500/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 1:57:00  time: 0.3163  data_time: 0.0007  memory: 19496  loss: 0.4123  loss_cls: 0.1892  loss_bbox: 0.2231
2025/05/12 20:24:07 - mmengine - INFO - Exp name: rtmdet_m_1x_custom_resume_20250512_185352
2025/05/12 20:24:07 - mmengine - INFO - Saving checkpoint at 16 epochs
2025/05/12 20:24:11 - mmengine - INFO - Epoch(val) [16][ 50/149]    eta: 0:00:08  time: 0.0842  data_time: 0.0037  memory: 19480  
2025/05/12 20:24:16 - mmengine - INFO - Epoch(val) [16][100/149]    eta: 0:00:04  time: 0.0833  data_time: 0.0026  memory: 1598  
2025/05/12 20:24:21 - mmengine - INFO - Evaluating bbox...
2025/05/12 20:24:24 - mmengine - INFO - bbox_mAP_copypaste: 0.775 0.942 0.866 0.461 0.666 0.818
2025/05/12 20:24:24 - mmengine - INFO - Epoch(val) [16][149/149]    coco/bbox_mAP: 0.7750  coco/bbox_mAP_50: 0.9420  coco/bbox_mAP_75: 0.8660  coco/bbox_mAP_s: 0.4610  coco/bbox_mAP_m: 0.6660  coco/bbox_mAP_l: 0.8180  data_time: 0.0030  time: 0.0824
2025/05/12 20:24:39 - mmengine - INFO - Epoch(train) [17][  50/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 1:56:35  time: 0.3105  data_time: 0.0024  memory: 19506  loss: 0.4133  loss_cls: 0.1939  loss_bbox: 0.2194
2025/05/12 20:24:55 - mmengine - INFO - Epoch(train) [17][ 100/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 1:56:20  time: 0.3167  data_time: 0.0007  memory: 19479  loss: 0.4064  loss_cls: 0.1927  loss_bbox: 0.2136
2025/05/12 20:25:11 - mmengine - INFO - Epoch(train) [17][ 150/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 1:56:04  time: 0.3119  data_time: 0.0006  memory: 19485  loss: 0.4371  loss_cls: 0.2072  loss_bbox: 0.2300
2025/05/12 20:25:27 - mmengine - INFO - Epoch(train) [17][ 200/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 1:55:49  time: 0.3192  data_time: 0.0007  memory: 19504  loss: 0.4239  loss_cls: 0.1971  loss_bbox: 0.2269
2025/05/12 20:25:43 - mmengine - INFO - Epoch(train) [17][ 250/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 1:55:34  time: 0.3193  data_time: 0.0006  memory: 19500  loss: 0.4060  loss_cls: 0.1850  loss_bbox: 0.2211
2025/05/12 20:25:59 - mmengine - INFO - Epoch(train) [17][ 300/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 1:55:19  time: 0.3209  data_time: 0.0007  memory: 19519  loss: 0.4257  loss_cls: 0.1995  loss_bbox: 0.2262
2025/05/12 20:26:14 - mmengine - INFO - Epoch(train) [17][ 350/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 1:55:04  time: 0.3142  data_time: 0.0007  memory: 19486  loss: 0.4156  loss_cls: 0.1900  loss_bbox: 0.2256
2025/05/12 20:26:30 - mmengine - INFO - Epoch(train) [17][ 400/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 1:54:48  time: 0.3057  data_time: 0.0006  memory: 19506  loss: 0.4247  loss_cls: 0.1999  loss_bbox: 0.2248
2025/05/12 20:26:46 - mmengine - INFO - Epoch(train) [17][ 450/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 1:54:33  time: 0.3208  data_time: 0.0007  memory: 19481  loss: 0.4195  loss_cls: 0.1965  loss_bbox: 0.2230
2025/05/12 20:27:02 - mmengine - INFO - Epoch(train) [17][ 500/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 1:54:18  time: 0.3231  data_time: 0.0007  memory: 19487  loss: 0.4070  loss_cls: 0.1941  loss_bbox: 0.2129
2025/05/12 20:27:18 - mmengine - INFO - Epoch(train) [17][ 550/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 1:54:02  time: 0.3164  data_time: 0.0006  memory: 19518  loss: 0.4200  loss_cls: 0.1910  loss_bbox: 0.2290
2025/05/12 20:27:33 - mmengine - INFO - Epoch(train) [17][ 600/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 1:53:47  time: 0.3139  data_time: 0.0006  memory: 19507  loss: 0.4196  loss_cls: 0.1993  loss_bbox: 0.2202
2025/05/12 20:27:47 - mmengine - INFO - Exp name: rtmdet_m_1x_custom_resume_20250512_185352
2025/05/12 20:27:49 - mmengine - INFO - Epoch(train) [17][ 650/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 1:53:32  time: 0.3151  data_time: 0.0007  memory: 19484  loss: 0.4441  loss_cls: 0.2126  loss_bbox: 0.2315
2025/05/12 20:28:05 - mmengine - INFO - Epoch(train) [17][ 700/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 1:53:16  time: 0.3191  data_time: 0.0007  memory: 19500  loss: 0.4098  loss_cls: 0.1979  loss_bbox: 0.2119
2025/05/12 20:28:21 - mmengine - INFO - Epoch(train) [17][ 750/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 1:53:02  time: 0.3246  data_time: 0.0007  memory: 19486  loss: 0.4390  loss_cls: 0.2120  loss_bbox: 0.2271
2025/05/12 20:28:37 - mmengine - INFO - Epoch(train) [17][ 800/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 1:52:47  time: 0.3231  data_time: 0.0007  memory: 19504  loss: 0.4096  loss_cls: 0.1944  loss_bbox: 0.2152
2025/05/12 20:28:54 - mmengine - INFO - Epoch(train) [17][ 850/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 1:52:32  time: 0.3258  data_time: 0.0007  memory: 19490  loss: 0.4143  loss_cls: 0.1996  loss_bbox: 0.2147
2025/05/12 20:29:09 - mmengine - INFO - Epoch(train) [17][ 900/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 1:52:16  time: 0.3134  data_time: 0.0006  memory: 19498  loss: 0.4150  loss_cls: 0.1893  loss_bbox: 0.2257
2025/05/12 20:29:25 - mmengine - INFO - Epoch(train) [17][ 950/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 1:52:00  time: 0.3079  data_time: 0.0006  memory: 19505  loss: 0.4236  loss_cls: 0.1956  loss_bbox: 0.2280
2025/05/12 20:29:40 - mmengine - INFO - Epoch(train) [17][1000/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 1:51:45  time: 0.3066  data_time: 0.0006  memory: 19489  loss: 0.3997  loss_cls: 0.1794  loss_bbox: 0.2203
2025/05/12 20:29:56 - mmengine - INFO - Epoch(train) [17][1050/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 1:51:29  time: 0.3148  data_time: 0.0007  memory: 19509  loss: 0.4255  loss_cls: 0.2039  loss_bbox: 0.2217
2025/05/12 20:30:12 - mmengine - INFO - Epoch(train) [17][1100/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 1:51:14  time: 0.3201  data_time: 0.0007  memory: 19478  loss: 0.4147  loss_cls: 0.2022  loss_bbox: 0.2125
2025/05/12 20:30:27 - mmengine - INFO - Epoch(train) [17][1150/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 1:50:58  time: 0.2994  data_time: 0.0006  memory: 19504  loss: 0.4282  loss_cls: 0.1983  loss_bbox: 0.2299
2025/05/12 20:30:43 - mmengine - INFO - Epoch(train) [17][1200/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 1:50:42  time: 0.3181  data_time: 0.0007  memory: 19489  loss: 0.4292  loss_cls: 0.2035  loss_bbox: 0.2257
2025/05/12 20:30:58 - mmengine - INFO - Epoch(train) [17][1250/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 1:50:26  time: 0.3033  data_time: 0.0006  memory: 19486  loss: 0.4559  loss_cls: 0.2202  loss_bbox: 0.2357
2025/05/12 20:31:14 - mmengine - INFO - Epoch(train) [17][1300/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 1:50:11  time: 0.3148  data_time: 0.0007  memory: 19504  loss: 0.4121  loss_cls: 0.1950  loss_bbox: 0.2171
2025/05/12 20:31:30 - mmengine - INFO - Epoch(train) [17][1350/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 1:49:56  time: 0.3232  data_time: 0.0007  memory: 19491  loss: 0.4085  loss_cls: 0.1882  loss_bbox: 0.2203
2025/05/12 20:31:46 - mmengine - INFO - Epoch(train) [17][1400/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 1:49:41  time: 0.3247  data_time: 0.0007  memory: 19497  loss: 0.4280  loss_cls: 0.2022  loss_bbox: 0.2258
2025/05/12 20:32:02 - mmengine - INFO - Epoch(train) [17][1450/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 1:49:26  time: 0.3205  data_time: 0.0007  memory: 19479  loss: 0.4196  loss_cls: 0.2025  loss_bbox: 0.2171
2025/05/12 20:32:18 - mmengine - INFO - Epoch(train) [17][1500/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 1:49:10  time: 0.3095  data_time: 0.0006  memory: 19503  loss: 0.4192  loss_cls: 0.1909  loss_bbox: 0.2282
2025/05/12 20:32:26 - mmengine - INFO - Exp name: rtmdet_m_1x_custom_resume_20250512_185352
2025/05/12 20:32:26 - mmengine - INFO - Saving checkpoint at 17 epochs
2025/05/12 20:32:31 - mmengine - INFO - Epoch(val) [17][ 50/149]    eta: 0:00:08  time: 0.0836  data_time: 0.0039  memory: 19509  
2025/05/12 20:32:35 - mmengine - INFO - Epoch(val) [17][100/149]    eta: 0:00:04  time: 0.0819  data_time: 0.0026  memory: 1598  
2025/05/12 20:32:41 - mmengine - INFO - Evaluating bbox...
2025/05/12 20:32:43 - mmengine - INFO - bbox_mAP_copypaste: 0.773 0.942 0.863 0.458 0.666 0.815
2025/05/12 20:32:43 - mmengine - INFO - Epoch(val) [17][149/149]    coco/bbox_mAP: 0.7730  coco/bbox_mAP_50: 0.9420  coco/bbox_mAP_75: 0.8630  coco/bbox_mAP_s: 0.4580  coco/bbox_mAP_m: 0.6660  coco/bbox_mAP_l: 0.8150  data_time: 0.0030  time: 0.0828
2025/05/12 20:32:59 - mmengine - INFO - Epoch(train) [18][  50/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 1:48:46  time: 0.3132  data_time: 0.0025  memory: 19492  loss: 0.4206  loss_cls: 0.1958  loss_bbox: 0.2248
2025/05/12 20:33:14 - mmengine - INFO - Epoch(train) [18][ 100/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 1:48:30  time: 0.3017  data_time: 0.0006  memory: 19511  loss: 0.4228  loss_cls: 0.1991  loss_bbox: 0.2236
2025/05/12 20:33:18 - mmengine - INFO - Exp name: rtmdet_m_1x_custom_resume_20250512_185352
2025/05/12 20:33:29 - mmengine - INFO - Epoch(train) [18][ 150/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 1:48:13  time: 0.3038  data_time: 0.0006  memory: 19513  loss: 0.4501  loss_cls: 0.2244  loss_bbox: 0.2258
2025/05/12 20:33:45 - mmengine - INFO - Epoch(train) [18][ 200/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 1:47:57  time: 0.3044  data_time: 0.0006  memory: 19509  loss: 0.4436  loss_cls: 0.2181  loss_bbox: 0.2255
2025/05/12 20:34:00 - mmengine - INFO - Epoch(train) [18][ 250/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 1:47:42  time: 0.3115  data_time: 0.0006  memory: 19484  loss: 0.4275  loss_cls: 0.2012  loss_bbox: 0.2263
2025/05/12 20:34:16 - mmengine - INFO - Epoch(train) [18][ 300/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 1:47:27  time: 0.3262  data_time: 0.0007  memory: 19517  loss: 0.4127  loss_cls: 0.1957  loss_bbox: 0.2169
2025/05/12 20:34:32 - mmengine - INFO - Epoch(train) [18][ 350/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 1:47:11  time: 0.3134  data_time: 0.0006  memory: 19478  loss: 0.3929  loss_cls: 0.1834  loss_bbox: 0.2094
2025/05/12 20:34:48 - mmengine - INFO - Epoch(train) [18][ 400/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 1:46:56  time: 0.3080  data_time: 0.0006  memory: 19489  loss: 0.3986  loss_cls: 0.1805  loss_bbox: 0.2181
2025/05/12 20:35:03 - mmengine - INFO - Epoch(train) [18][ 450/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 1:46:40  time: 0.3171  data_time: 0.0006  memory: 19497  loss: 0.4227  loss_cls: 0.1892  loss_bbox: 0.2335
2025/05/12 20:35:19 - mmengine - INFO - Epoch(train) [18][ 500/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 1:46:25  time: 0.3109  data_time: 0.0005  memory: 19494  loss: 0.4264  loss_cls: 0.2025  loss_bbox: 0.2239
2025/05/12 20:35:35 - mmengine - INFO - Epoch(train) [18][ 550/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 1:46:09  time: 0.3125  data_time: 0.0006  memory: 19505  loss: 0.4424  loss_cls: 0.2068  loss_bbox: 0.2356
2025/05/12 20:35:51 - mmengine - INFO - Epoch(train) [18][ 600/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 1:45:54  time: 0.3184  data_time: 0.0006  memory: 19481  loss: 0.4126  loss_cls: 0.1973  loss_bbox: 0.2153
2025/05/12 20:36:06 - mmengine - INFO - Epoch(train) [18][ 650/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 1:45:38  time: 0.3174  data_time: 0.0006  memory: 19493  loss: 0.4306  loss_cls: 0.2054  loss_bbox: 0.2252
2025/05/12 20:36:22 - mmengine - INFO - Epoch(train) [18][ 700/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 1:45:23  time: 0.3091  data_time: 0.0006  memory: 19485  loss: 0.4264  loss_cls: 0.2035  loss_bbox: 0.2229
2025/05/12 20:36:38 - mmengine - INFO - Epoch(train) [18][ 750/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 1:45:07  time: 0.3138  data_time: 0.0006  memory: 19482  loss: 0.4154  loss_cls: 0.2027  loss_bbox: 0.2127
2025/05/12 20:36:53 - mmengine - INFO - Epoch(train) [18][ 800/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 1:44:52  time: 0.3134  data_time: 0.0006  memory: 19504  loss: 0.4149  loss_cls: 0.1921  loss_bbox: 0.2228
2025/05/12 20:37:09 - mmengine - INFO - Epoch(train) [18][ 850/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 1:44:36  time: 0.3131  data_time: 0.0006  memory: 19490  loss: 0.3999  loss_cls: 0.1809  loss_bbox: 0.2190
2025/05/12 20:37:25 - mmengine - INFO - Epoch(train) [18][ 900/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 1:44:21  time: 0.3154  data_time: 0.0006  memory: 19504  loss: 0.4272  loss_cls: 0.2007  loss_bbox: 0.2265
2025/05/12 20:37:40 - mmengine - INFO - Epoch(train) [18][ 950/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 1:44:05  time: 0.3171  data_time: 0.0006  memory: 19502  loss: 0.3985  loss_cls: 0.1825  loss_bbox: 0.2160
2025/05/12 20:37:56 - mmengine - INFO - Epoch(train) [18][1000/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 1:43:50  time: 0.3146  data_time: 0.0006  memory: 19485  loss: 0.3943  loss_cls: 0.1805  loss_bbox: 0.2139
2025/05/12 20:38:11 - mmengine - INFO - Epoch(train) [18][1050/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 1:43:34  time: 0.3019  data_time: 0.0005  memory: 19509  loss: 0.3968  loss_cls: 0.1854  loss_bbox: 0.2114
2025/05/12 20:38:27 - mmengine - INFO - Epoch(train) [18][1100/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 1:43:18  time: 0.3043  data_time: 0.0005  memory: 19495  loss: 0.4165  loss_cls: 0.1947  loss_bbox: 0.2218
2025/05/12 20:38:31 - mmengine - INFO - Exp name: rtmdet_m_1x_custom_resume_20250512_185352
2025/05/12 20:38:42 - mmengine - INFO - Epoch(train) [18][1150/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 1:43:01  time: 0.3009  data_time: 0.0006  memory: 19509  loss: 0.4169  loss_cls: 0.1980  loss_bbox: 0.2189
2025/05/12 20:38:57 - mmengine - INFO - Epoch(train) [18][1200/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 1:42:45  time: 0.2994  data_time: 0.0005  memory: 19478  loss: 0.4059  loss_cls: 0.1815  loss_bbox: 0.2244
2025/05/12 20:39:12 - mmengine - INFO - Epoch(train) [18][1250/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 1:42:29  time: 0.3074  data_time: 0.0005  memory: 19512  loss: 0.4202  loss_cls: 0.1976  loss_bbox: 0.2226
2025/05/12 20:39:27 - mmengine - INFO - Epoch(train) [18][1300/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 1:42:13  time: 0.2983  data_time: 0.0005  memory: 19490  loss: 0.4388  loss_cls: 0.2115  loss_bbox: 0.2274
2025/05/12 20:39:42 - mmengine - INFO - Epoch(train) [18][1350/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 1:41:57  time: 0.3046  data_time: 0.0005  memory: 19515  loss: 0.4167  loss_cls: 0.1980  loss_bbox: 0.2187
2025/05/12 20:39:58 - mmengine - INFO - Epoch(train) [18][1400/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 1:41:42  time: 0.3158  data_time: 0.0006  memory: 19509  loss: 0.4202  loss_cls: 0.1968  loss_bbox: 0.2234
2025/05/12 20:40:14 - mmengine - INFO - Epoch(train) [18][1450/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 1:41:26  time: 0.3175  data_time: 0.0007  memory: 19477  loss: 0.4534  loss_cls: 0.2158  loss_bbox: 0.2376
2025/05/12 20:40:29 - mmengine - INFO - Epoch(train) [18][1500/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 1:41:10  time: 0.3054  data_time: 0.0006  memory: 19502  loss: 0.4265  loss_cls: 0.1979  loss_bbox: 0.2286
2025/05/12 20:40:38 - mmengine - INFO - Exp name: rtmdet_m_1x_custom_resume_20250512_185352
2025/05/12 20:40:38 - mmengine - INFO - Saving checkpoint at 18 epochs
2025/05/12 20:40:43 - mmengine - INFO - Epoch(val) [18][ 50/149]    eta: 0:00:08  time: 0.0860  data_time: 0.0037  memory: 19476  
2025/05/12 20:40:47 - mmengine - INFO - Epoch(val) [18][100/149]    eta: 0:00:04  time: 0.0829  data_time: 0.0026  memory: 1598  
2025/05/12 20:40:52 - mmengine - INFO - Evaluating bbox...
2025/05/12 20:40:55 - mmengine - INFO - bbox_mAP_copypaste: 0.772 0.943 0.862 0.468 0.667 0.814
2025/05/12 20:40:55 - mmengine - INFO - Epoch(val) [18][149/149]    coco/bbox_mAP: 0.7720  coco/bbox_mAP_50: 0.9430  coco/bbox_mAP_75: 0.8620  coco/bbox_mAP_s: 0.4680  coco/bbox_mAP_m: 0.6670  coco/bbox_mAP_l: 0.8140  data_time: 0.0029  time: 0.0828
2025/05/12 20:41:10 - mmengine - INFO - Epoch(train) [19][  50/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 1:40:46  time: 0.3054  data_time: 0.0031  memory: 19519  loss: 0.4100  loss_cls: 0.1924  loss_bbox: 0.2176
2025/05/12 20:41:26 - mmengine - INFO - Epoch(train) [19][ 100/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 1:40:30  time: 0.3157  data_time: 0.0006  memory: 19483  loss: 0.4310  loss_cls: 0.2051  loss_bbox: 0.2259
2025/05/12 20:41:41 - mmengine - INFO - Epoch(train) [19][ 150/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 1:40:15  time: 0.3124  data_time: 0.0006  memory: 19483  loss: 0.4140  loss_cls: 0.1948  loss_bbox: 0.2193
2025/05/12 20:41:57 - mmengine - INFO - Epoch(train) [19][ 200/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 1:39:59  time: 0.3196  data_time: 0.0006  memory: 19504  loss: 0.4227  loss_cls: 0.1977  loss_bbox: 0.2250
2025/05/12 20:42:13 - mmengine - INFO - Epoch(train) [19][ 250/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 1:39:44  time: 0.3179  data_time: 0.0006  memory: 19483  loss: 0.3963  loss_cls: 0.1812  loss_bbox: 0.2151
2025/05/12 20:42:29 - mmengine - INFO - Epoch(train) [19][ 300/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 1:39:28  time: 0.3080  data_time: 0.0005  memory: 19478  loss: 0.3994  loss_cls: 0.1788  loss_bbox: 0.2207
2025/05/12 20:42:45 - mmengine - INFO - Epoch(train) [19][ 350/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 1:39:13  time: 0.3222  data_time: 0.0006  memory: 19502  loss: 0.3975  loss_cls: 0.1825  loss_bbox: 0.2150
2025/05/12 20:43:01 - mmengine - INFO - Epoch(train) [19][ 400/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 1:38:58  time: 0.3166  data_time: 0.0006  memory: 19492  loss: 0.4296  loss_cls: 0.2025  loss_bbox: 0.2271
2025/05/12 20:43:16 - mmengine - INFO - Epoch(train) [19][ 450/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 1:38:42  time: 0.3116  data_time: 0.0006  memory: 19485  loss: 0.3953  loss_cls: 0.1847  loss_bbox: 0.2106
2025/05/12 20:43:31 - mmengine - INFO - Epoch(train) [19][ 500/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 1:38:26  time: 0.2985  data_time: 0.0005  memory: 19509  loss: 0.4378  loss_cls: 0.2082  loss_bbox: 0.2297
2025/05/12 20:43:46 - mmengine - INFO - Epoch(train) [19][ 550/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 1:38:10  time: 0.3024  data_time: 0.0005  memory: 19504  loss: 0.4309  loss_cls: 0.2012  loss_bbox: 0.2297
2025/05/12 20:43:57 - mmengine - INFO - Exp name: rtmdet_m_1x_custom_resume_20250512_185352
2025/05/12 20:44:02 - mmengine - INFO - Epoch(train) [19][ 600/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 1:37:54  time: 0.3117  data_time: 0.0006  memory: 19500  loss: 0.4211  loss_cls: 0.2019  loss_bbox: 0.2192
2025/05/12 20:44:17 - mmengine - INFO - Epoch(train) [19][ 650/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 1:37:38  time: 0.3015  data_time: 0.0005  memory: 19479  loss: 0.4127  loss_cls: 0.1973  loss_bbox: 0.2154
2025/05/12 20:44:32 - mmengine - INFO - Epoch(train) [19][ 700/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 1:37:22  time: 0.3014  data_time: 0.0006  memory: 19491  loss: 0.4258  loss_cls: 0.2026  loss_bbox: 0.2232
2025/05/12 20:44:47 - mmengine - INFO - Epoch(train) [19][ 750/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 1:37:06  time: 0.3082  data_time: 0.0006  memory: 19476  loss: 0.4370  loss_cls: 0.2048  loss_bbox: 0.2322
2025/05/12 20:45:03 - mmengine - INFO - Epoch(train) [19][ 800/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 1:36:50  time: 0.3048  data_time: 0.0005  memory: 19499  loss: 0.4138  loss_cls: 0.1944  loss_bbox: 0.2194
2025/05/12 20:45:19 - mmengine - INFO - Epoch(train) [19][ 850/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 1:36:35  time: 0.3183  data_time: 0.0006  memory: 19490  loss: 0.4125  loss_cls: 0.1899  loss_bbox: 0.2226
2025/05/12 20:45:34 - mmengine - INFO - Epoch(train) [19][ 900/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 1:36:20  time: 0.3193  data_time: 0.0006  memory: 19511  loss: 0.4247  loss_cls: 0.2005  loss_bbox: 0.2242
2025/05/12 20:45:50 - mmengine - INFO - Epoch(train) [19][ 950/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 1:36:04  time: 0.3161  data_time: 0.0007  memory: 19476  loss: 0.4213  loss_cls: 0.1991  loss_bbox: 0.2222
2025/05/12 20:46:06 - mmengine - INFO - Epoch(train) [19][1000/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 1:35:49  time: 0.3130  data_time: 0.0005  memory: 19491  loss: 0.4169  loss_cls: 0.1964  loss_bbox: 0.2205
2025/05/12 20:46:21 - mmengine - INFO - Epoch(train) [19][1050/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 1:35:33  time: 0.3033  data_time: 0.0006  memory: 19497  loss: 0.4263  loss_cls: 0.1971  loss_bbox: 0.2292
2025/05/12 20:46:36 - mmengine - INFO - Epoch(train) [19][1100/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 1:35:17  time: 0.2987  data_time: 0.0006  memory: 19502  loss: 0.4342  loss_cls: 0.2031  loss_bbox: 0.2310
2025/05/12 20:46:51 - mmengine - INFO - Epoch(train) [19][1150/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 1:35:01  time: 0.3047  data_time: 0.0006  memory: 19489  loss: 0.4510  loss_cls: 0.2191  loss_bbox: 0.2320
2025/05/12 20:47:07 - mmengine - INFO - Epoch(train) [19][1200/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 1:34:45  time: 0.3116  data_time: 0.0006  memory: 19481  loss: 0.3938  loss_cls: 0.1842  loss_bbox: 0.2097
2025/05/12 20:47:22 - mmengine - INFO - Epoch(train) [19][1250/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 1:34:29  time: 0.3075  data_time: 0.0005  memory: 19520  loss: 0.4333  loss_cls: 0.2002  loss_bbox: 0.2331
2025/05/12 20:47:38 - mmengine - INFO - Epoch(train) [19][1300/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 1:34:14  time: 0.3174  data_time: 0.0006  memory: 19493  loss: 0.4213  loss_cls: 0.1982  loss_bbox: 0.2232
2025/05/12 20:47:54 - mmengine - INFO - Epoch(train) [19][1350/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 1:33:58  time: 0.3121  data_time: 0.0006  memory: 19502  loss: 0.4259  loss_cls: 0.1953  loss_bbox: 0.2306
2025/05/12 20:48:09 - mmengine - INFO - Epoch(train) [19][1400/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 1:33:43  time: 0.3140  data_time: 0.0005  memory: 19475  loss: 0.4406  loss_cls: 0.2154  loss_bbox: 0.2253
2025/05/12 20:48:25 - mmengine - INFO - Epoch(train) [19][1450/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 1:33:27  time: 0.3149  data_time: 0.0006  memory: 19504  loss: 0.4342  loss_cls: 0.2039  loss_bbox: 0.2304
2025/05/12 20:48:41 - mmengine - INFO - Epoch(train) [19][1500/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 1:33:12  time: 0.3139  data_time: 0.0006  memory: 19506  loss: 0.4234  loss_cls: 0.2046  loss_bbox: 0.2188
2025/05/12 20:48:50 - mmengine - INFO - Exp name: rtmdet_m_1x_custom_resume_20250512_185352
2025/05/12 20:48:50 - mmengine - INFO - Saving checkpoint at 19 epochs
2025/05/12 20:48:54 - mmengine - INFO - Epoch(val) [19][ 50/149]    eta: 0:00:08  time: 0.0851  data_time: 0.0038  memory: 19517  
2025/05/12 20:48:58 - mmengine - INFO - Epoch(val) [19][100/149]    eta: 0:00:04  time: 0.0817  data_time: 0.0026  memory: 1598  
2025/05/12 20:49:04 - mmengine - INFO - Evaluating bbox...
2025/05/12 20:49:06 - mmengine - INFO - bbox_mAP_copypaste: 0.773 0.941 0.861 0.452 0.667 0.815
2025/05/12 20:49:07 - mmengine - INFO - Epoch(val) [19][149/149]    coco/bbox_mAP: 0.7730  coco/bbox_mAP_50: 0.9410  coco/bbox_mAP_75: 0.8610  coco/bbox_mAP_s: 0.4520  coco/bbox_mAP_m: 0.6670  coco/bbox_mAP_l: 0.8150  data_time: 0.0030  time: 0.0821
2025/05/12 20:49:07 - mmengine - INFO - the monitored metric did not improve in the last 3 records. best score: 0.775. 
