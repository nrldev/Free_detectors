2025/05/13 03:00:52 - mmengine - INFO - 
------------------------------------------------------------
System environment:
    sys.platform: linux
    Python: 3.11.11 (main, Dec 11 2024, 16:28:39) [GCC 11.2.0]
    CUDA available: True
    MUSA available: False
    numpy_random_seed: 570659036
    GPU 0: NVIDIA GeForce RTX 4090
    CUDA_HOME: /usr
    NVCC: Cuda compilation tools, release 12.0, V12.0.140
    GCC: gcc (Ubuntu 13.3.0-6ubuntu2~24.04) 13.3.0
    PyTorch: 2.4.1+cu121
    PyTorch compiling details: PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v3.4.2 (Git Hash 1137e04ec0b5251ca2b4400a4fd3c667ce843d67)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX512
  - CUDA Runtime 12.1
  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 90.1  (built against CUDA 12.4)
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=12.1, CUDNN_VERSION=9.1.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wsuggest-override -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=2.4.1, USE_CUDA=ON, USE_CUDNN=ON, USE_CUSPARSELT=1, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_GLOO=ON, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, USE_ROCM_KERNEL_ASSERT=OFF, 

    TorchVision: 0.19.1+cu121
    OpenCV: 4.11.0
    MMEngine: 0.10.7

Runtime environment:
    cudnn_benchmark: False
    dist_cfg: {'backend': 'nccl'}
    mp_cfg: {'mp_start_method': 'fork', 'opencv_num_threads': 0}
    seed: 570659036
    Distributed launcher: none
    Distributed training: False
    GPU number: 1
------------------------------------------------------------

2025/05/13 03:00:52 - mmengine - INFO - Config:
HOME = '/home/jaa/Work/Prog/BSU/Detectors'
MODEL_GROUP = 'yolo-like'
MODEL_TYPE = 'RTMDet'
WEIGHT_SIZE = 'm'
additions = 'new1'
auto_scale_lr = dict(base_batch_size=6, enable=False)
backend_args = None
base_lr = 0.004
batch_size = 6
checkpoint_config = dict(interval=1)
custom_hooks = [
    dict(type='CustomFreezeHook', unfreeze_epoch=5),
]
custom_imports = dict(
    allow_failed_imports=False, imports=[
        'custom_hooks',
    ])
data_root = '/home/jaa/Work/Prog/BSU/Detectors/mmdetection/data/Padded_GroundingDINO.v1i.yolov5pytorch/'
dataset_type = 'CocoDataset'
default_hooks = dict(
    checkpoint=dict(interval=1, max_keep_ckpts=7, type='CheckpointHook'),
    early_stopping=dict(
        min_delta=0.001,
        monitor='coco/bbox_mAP',
        patience=3,
        type='EarlyStoppingHook'),
    logger=dict(interval=50, log_metric_by_epoch=True, type='LoggerHook'),
    param_scheduler=dict(type='ParamSchedulerHook'),
    sampler_seed=dict(type='DistSamplerSeedHook'),
    timer=dict(type='IterTimerHook'),
    visualization=dict(type='DetVisualizationHook'))
default_scope = 'mmdet'
deterministic = True
env_cfg = dict(
    cudnn_benchmark=False,
    dist_cfg=dict(backend='nccl'),
    mp_cfg=dict(mp_start_method='fork', opencv_num_threads=0))
evaluation = dict(interval=1, metric='bbox')
experiment = 'RTMDet_m_30e_new1_custom'
img_scales = [
    (
        640,
        640,
    ),
    (
        320,
        320,
    ),
    (
        960,
        960,
    ),
]
interval = 10
launcher = 'none'
load_from = '/home/jaa/Work/Prog/BSU/Detectors/work_dirs/RTMDet/RTMDet_m_30e_new3_custom/epoch_5.pth'
log_level = 'INFO'
log_processor = dict(by_epoch=True, type='LogProcessor', window_size=50)
max_epochs = 300
metainfo = dict(
    classes=('cow', ), palette=[
        (
            220,
            20,
            60,
        ),
    ])
model = dict(
    backbone=dict(
        act_cfg=dict(inplace=True, type='SiLU'),
        arch='P5',
        channel_attention=True,
        deepen_factor=0.67,
        expand_ratio=0.5,
        norm_cfg=dict(type='SyncBN'),
        type='CSPNeXt',
        widen_factor=0.75),
    bbox_head=dict(
        act_cfg=dict(inplace=True, type='SiLU'),
        anchor_generator=dict(
            offset=0, strides=[
                8,
                16,
                32,
            ], type='MlvlPointGenerator'),
        bbox_coder=dict(type='DistancePointBBoxCoder'),
        exp_on_reg=True,
        feat_channels=192,
        in_channels=192,
        loss_bbox=dict(loss_weight=2.0, type='GIoULoss'),
        loss_cls=dict(
            beta=2.0,
            loss_weight=1.0,
            type='QualityFocalLoss',
            use_sigmoid=True),
        norm_cfg=dict(type='SyncBN'),
        num_classes=1,
        pred_kernel_size=1,
        share_conv=True,
        stacked_convs=2,
        type='RTMDetSepBNHead',
        with_objectness=False),
    data_preprocessor=dict(
        batch_augments=None,
        bgr_to_rgb=False,
        mean=[
            103.53,
            116.28,
            123.675,
        ],
        std=[
            57.375,
            57.12,
            58.395,
        ],
        type='DetDataPreprocessor'),
    neck=dict(
        act_cfg=dict(inplace=True, type='SiLU'),
        expand_ratio=0.5,
        in_channels=[
            192,
            384,
            768,
        ],
        norm_cfg=dict(type='SyncBN'),
        num_csp_blocks=2,
        out_channels=192,
        type='CSPNeXtPAFPN'),
    test_cfg=dict(
        max_per_img=300,
        min_bbox_size=0,
        nms=dict(iou_threshold=0.65, type='nms'),
        nms_pre=30000,
        score_thr=0.001),
    train_cfg=dict(
        allowed_border=-1,
        assigner=dict(topk=13, type='DynamicSoftLabelAssigner'),
        debug=False,
        pos_weight=-1),
    type='RTMDet')
num_classes = 1
num_epochs = 20
num_workers = 6
optim_wrapper = dict(
    optimizer=dict(lr=0.0025, momentum=0.9, type='SGD', weight_decay=0.0005),
    paramwise_cfg=dict(
        bias_decay_mult=0, bypass_duplicate=True, norm_decay_mult=0),
    type='OptimWrapper')
param_scheduler = [
    dict(
        begin=0, by_epoch=False, end=500, start_factor=0.001, type='LinearLR'),
    dict(
        begin=0,
        by_epoch=True,
        end=20,
        gamma=0.1,
        milestones=[
            7,
            14,
        ],
        type='MultiStepLR'),
    dict(T_max=20, begin=0, by_epoch=True, end=20, type='CosineAnnealingLR'),
]
resume = True
seed = 234
stage2_num_epochs = 20
test_cfg = dict(type='TestLoop')
test_dataloader = dict(
    batch_size=6,
    dataset=dict(
        ann_file=
        '/home/jaa/Work/Prog/BSU/Detectors/mmdetection/data/Padded_GroundingDINO.v1i.yolov5pytorch/test_coco.json',
        backend_args=None,
        data_prefix=dict(
            img=
            '/home/jaa/Work/Prog/BSU/Detectors/mmdetection/data/Padded_GroundingDINO.v1i.yolov5pytorch/test/images'
        ),
        data_root=
        '/home/jaa/Work/Prog/BSU/Detectors/mmdetection/data/Padded_GroundingDINO.v1i.yolov5pytorch/',
        pipeline=[
            dict(backend_args=None, type='LoadImageFromFile'),
            dict(type='LoadAnnotations', with_bbox=True),
            dict(
                keep_empty=False,
                min_gt_bbox_wh=(
                    16,
                    16,
                ),
                type='FilterAnnotations'),
            dict(keep_ratio=True, scale=(
                1280,
                1280,
            ), type='Resize'),
            dict(
                meta_keys=(
                    'img_id',
                    'img_path',
                    'ori_shape',
                    'img_shape',
                    'scale_factor',
                ),
                type='PackDetInputs'),
        ],
        test_mode=True,
        type='CocoDataset'),
    drop_last=False,
    num_workers=6,
    persistent_workers=True,
    sampler=dict(shuffle=False, type='DefaultSampler'))
test_evaluator = dict(
    ann_file=
    '/home/jaa/Work/Prog/BSU/Detectors/mmdetection/data/Padded_GroundingDINO.v1i.yolov5pytorch/test_coco.json',
    backend_args=None,
    format_only=True,
    metric='bbox',
    outfile_prefix=
    '/home/jaa/Work/Prog/BSU/Detectors/mmdetection/data/Padded_GroundingDINO.v1i.yolov5pytorch/test/images',
    proposal_nums=(
        100,
        1,
        10,
    ),
    type='CocoMetric')
test_pipeline = [
    dict(backend_args=None, type='LoadImageFromFile'),
    dict(type='LoadAnnotations', with_bbox=True),
    dict(
        keep_empty=False, min_gt_bbox_wh=(
            16,
            16,
        ), type='FilterAnnotations'),
    dict(keep_ratio=True, scale=(
        1280,
        1280,
    ), type='Resize'),
    dict(
        meta_keys=(
            'img_id',
            'img_path',
            'ori_shape',
            'img_shape',
            'scale_factor',
        ),
        type='PackDetInputs'),
]
train_cfg = dict(
    dynamic_intervals=[
        (
            280,
            1,
        ),
    ],
    max_epochs=30,
    type='EpochBasedTrainLoop',
    val_interval=1)
train_dataloader = dict(
    batch_sampler=None,
    batch_size=6,
    dataset=dict(
        ann_file=
        '/home/jaa/Work/Prog/BSU/Detectors/mmdetection/data/Padded_GroundingDINO.v1i.yolov5pytorch/train_coco.json',
        backend_args=None,
        data_prefix=dict(
            img=
            '/home/jaa/Work/Prog/BSU/Detectors/mmdetection/data/Padded_GroundingDINO.v1i.yolov5pytorch/train/images'
        ),
        data_root=
        '/home/jaa/Work/Prog/BSU/Detectors/mmdetection/data/Padded_GroundingDINO.v1i.yolov5pytorch/',
        filter_cfg=dict(filter_empty_gt=True, min_size=32),
        metainfo=dict(classes=('cow', ), palette=[
            (
                220,
                20,
                60,
            ),
        ]),
        pipeline=[
            dict(backend_args=None, type='LoadImageFromFile'),
            dict(type='LoadAnnotations', with_bbox=True),
            dict(prob=0.5, type='RandomFlip'),
            dict(level=2, prob=0.3, type='Rotate'),
            dict(
                keep_empty=False,
                min_gt_bbox_wh=(
                    16,
                    16,
                ),
                type='FilterAnnotations'),
            dict(keep_ratio=True, scale=(
                1280,
                1280,
            ), type='Resize'),
            dict(type='PackDetInputs'),
        ],
        type='CocoDataset'),
    num_workers=6,
    persistent_workers=True,
    pin_memory=True,
    sampler=dict(shuffle=True, type='DefaultSampler'))
train_pipeline = [
    dict(backend_args=None, type='LoadImageFromFile'),
    dict(type='LoadAnnotations', with_bbox=True),
    dict(prob=0.5, type='RandomFlip'),
    dict(level=2, prob=0.3, type='Rotate'),
    dict(
        keep_empty=False, min_gt_bbox_wh=(
            16,
            16,
        ), type='FilterAnnotations'),
    dict(keep_ratio=True, scale=(
        1280,
        1280,
    ), type='Resize'),
    dict(type='PackDetInputs'),
]
train_pipeline_stage2 = [
    dict(backend_args=None, type='LoadImageFromFile'),
    dict(type='LoadAnnotations', with_bbox=True),
    dict(
        keep_ratio=True,
        ratio_range=(
            0.1,
            2.0,
        ),
        scale=(
            640,
            640,
        ),
        type='RandomResize'),
    dict(crop_size=(
        640,
        640,
    ), type='RandomCrop'),
    dict(type='YOLOXHSVRandomAug'),
    dict(prob=0.5, type='RandomFlip'),
    dict(pad_val=dict(img=(
        114,
        114,
        114,
    )), size=(
        640,
        640,
    ), type='Pad'),
    dict(type='PackDetInputs'),
]
val_cfg = dict(type='ValLoop')
val_dataloader = dict(
    batch_size=5,
    dataset=dict(
        ann_file=
        '/home/jaa/Work/Prog/BSU/Detectors/mmdetection/data/Padded_GroundingDINO.v1i.yolov5pytorch/valid_coco.json',
        backend_args=None,
        data_prefix=dict(
            img=
            '/home/jaa/Work/Prog/BSU/Detectors/mmdetection/data/Padded_GroundingDINO.v1i.yolov5pytorch/valid/images'
        ),
        data_root=
        '/home/jaa/Work/Prog/BSU/Detectors/mmdetection/data/Padded_GroundingDINO.v1i.yolov5pytorch/',
        metainfo=dict(classes=('cow', ), palette=[
            (
                220,
                20,
                60,
            ),
        ]),
        pipeline=[
            dict(backend_args=None, type='LoadImageFromFile'),
            dict(type='LoadAnnotations', with_bbox=True),
            dict(
                keep_empty=False,
                min_gt_bbox_wh=(
                    16,
                    16,
                ),
                type='FilterAnnotations'),
            dict(keep_ratio=True, scale=(
                1280,
                1280,
            ), type='Resize'),
            dict(
                meta_keys=(
                    'img_id',
                    'img_path',
                    'ori_shape',
                    'img_shape',
                    'scale_factor',
                ),
                type='PackDetInputs'),
        ],
        test_mode=True,
        type='CocoDataset'),
    drop_last=False,
    num_workers=6,
    persistent_workers=True,
    sampler=dict(shuffle=False, type='DefaultSampler'))
val_evaluator = dict(
    ann_file=
    '/home/jaa/Work/Prog/BSU/Detectors/mmdetection/data/Padded_GroundingDINO.v1i.yolov5pytorch//valid_coco.json',
    backend_args=None,
    format_only=False,
    metric='bbox',
    proposal_nums=(
        100,
        1,
        10,
    ),
    type='CocoMetric')
vis_backends = [
    dict(
        init_kwargs=dict(
            group='yolo-like',
            name='RTMDet_m_30e_6b_new1',
            project='Сomparison of detectors'),
        type='WandbVisBackend'),
]
visualizer = dict(
    type='Visualizer',
    vis_backends=[
        dict(
            init_kwargs=dict(
                group='yolo-like',
                name='RTMDet_m_30e_6b_new1',
                project='Сomparison of detectors'),
            type='WandbVisBackend'),
    ])
weights = 'rtmdet_m_8xb32-300e_coco_20220719_112220-229f527c.pth'
work_dir = '/home/jaa/Work/Prog/BSU/Detectors/work_dirs/RTMDet/RTMDet_m_30e_new1_custom/'

2025/05/13 03:00:55 - mmengine - INFO - Distributed training is not used, all SyncBatchNorm (SyncBN) layers in the model will be automatically reverted to BatchNormXd layers if they are used.
2025/05/13 03:00:55 - mmengine - INFO - Hooks will be executed in the following order:
before_run:
(VERY_HIGH   ) RuntimeInfoHook                    
(BELOW_NORMAL) LoggerHook                         
(LOWEST      ) EarlyStoppingHook                  
 -------------------- 
before_train:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(NORMAL      ) CustomFreezeHook                   
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
before_train_epoch:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(NORMAL      ) DistSamplerSeedHook                
(NORMAL      ) CustomFreezeHook                   
 -------------------- 
before_train_iter:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
 -------------------- 
after_train_iter:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(BELOW_NORMAL) LoggerHook                         
(LOW         ) ParamSchedulerHook                 
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
after_train_epoch:
(NORMAL      ) IterTimerHook                      
(LOW         ) ParamSchedulerHook                 
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
before_val:
(VERY_HIGH   ) RuntimeInfoHook                    
 -------------------- 
before_val_epoch:
(NORMAL      ) IterTimerHook                      
 -------------------- 
before_val_iter:
(NORMAL      ) IterTimerHook                      
 -------------------- 
after_val_iter:
(NORMAL      ) IterTimerHook                      
(NORMAL      ) DetVisualizationHook               
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
after_val_epoch:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(BELOW_NORMAL) LoggerHook                         
(LOW         ) ParamSchedulerHook                 
(VERY_LOW    ) CheckpointHook                     
(LOWEST      ) EarlyStoppingHook                  
 -------------------- 
after_val:
(VERY_HIGH   ) RuntimeInfoHook                    
 -------------------- 
after_train:
(VERY_HIGH   ) RuntimeInfoHook                    
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
before_test:
(VERY_HIGH   ) RuntimeInfoHook                    
 -------------------- 
before_test_epoch:
(NORMAL      ) IterTimerHook                      
 -------------------- 
before_test_iter:
(NORMAL      ) IterTimerHook                      
 -------------------- 
after_test_iter:
(NORMAL      ) IterTimerHook                      
(NORMAL      ) DetVisualizationHook               
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
after_test_epoch:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
after_test:
(VERY_HIGH   ) RuntimeInfoHook                    
 -------------------- 
after_run:
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
2025/05/13 03:00:56 - mmengine - INFO - paramwise_options -- backbone.stem.0.bn.weight:weight_decay=0.0
2025/05/13 03:00:56 - mmengine - INFO - paramwise_options -- backbone.stem.0.bn.bias:weight_decay=0.0
2025/05/13 03:00:56 - mmengine - INFO - paramwise_options -- backbone.stem.1.bn.weight:weight_decay=0.0
2025/05/13 03:00:56 - mmengine - INFO - paramwise_options -- backbone.stem.1.bn.bias:weight_decay=0.0
2025/05/13 03:00:56 - mmengine - INFO - paramwise_options -- backbone.stem.2.bn.weight:weight_decay=0.0
2025/05/13 03:00:56 - mmengine - INFO - paramwise_options -- backbone.stem.2.bn.bias:weight_decay=0.0
2025/05/13 03:00:56 - mmengine - INFO - paramwise_options -- backbone.stage1.0.bn.weight:weight_decay=0.0
2025/05/13 03:00:56 - mmengine - INFO - paramwise_options -- backbone.stage1.0.bn.bias:weight_decay=0.0
2025/05/13 03:00:56 - mmengine - INFO - paramwise_options -- backbone.stage1.1.main_conv.bn.weight:weight_decay=0.0
2025/05/13 03:00:56 - mmengine - INFO - paramwise_options -- backbone.stage1.1.main_conv.bn.bias:weight_decay=0.0
2025/05/13 03:00:56 - mmengine - INFO - paramwise_options -- backbone.stage1.1.short_conv.bn.weight:weight_decay=0.0
2025/05/13 03:00:56 - mmengine - INFO - paramwise_options -- backbone.stage1.1.short_conv.bn.bias:weight_decay=0.0
2025/05/13 03:00:56 - mmengine - INFO - paramwise_options -- backbone.stage1.1.final_conv.bn.weight:weight_decay=0.0
2025/05/13 03:00:56 - mmengine - INFO - paramwise_options -- backbone.stage1.1.final_conv.bn.bias:weight_decay=0.0
2025/05/13 03:00:56 - mmengine - INFO - paramwise_options -- backbone.stage1.1.blocks.0.conv1.bn.weight:weight_decay=0.0
2025/05/13 03:00:56 - mmengine - INFO - paramwise_options -- backbone.stage1.1.blocks.0.conv1.bn.bias:weight_decay=0.0
2025/05/13 03:00:56 - mmengine - INFO - paramwise_options -- backbone.stage1.1.blocks.0.conv2.depthwise_conv.bn.weight:weight_decay=0.0
2025/05/13 03:00:56 - mmengine - INFO - paramwise_options -- backbone.stage1.1.blocks.0.conv2.depthwise_conv.bn.bias:weight_decay=0.0
2025/05/13 03:00:56 - mmengine - INFO - paramwise_options -- backbone.stage1.1.blocks.0.conv2.pointwise_conv.bn.weight:weight_decay=0.0
2025/05/13 03:00:56 - mmengine - INFO - paramwise_options -- backbone.stage1.1.blocks.0.conv2.pointwise_conv.bn.bias:weight_decay=0.0
2025/05/13 03:00:56 - mmengine - INFO - paramwise_options -- backbone.stage1.1.blocks.1.conv1.bn.weight:weight_decay=0.0
2025/05/13 03:00:56 - mmengine - INFO - paramwise_options -- backbone.stage1.1.blocks.1.conv1.bn.bias:weight_decay=0.0
2025/05/13 03:00:56 - mmengine - INFO - paramwise_options -- backbone.stage1.1.blocks.1.conv2.depthwise_conv.bn.weight:weight_decay=0.0
2025/05/13 03:00:56 - mmengine - INFO - paramwise_options -- backbone.stage1.1.blocks.1.conv2.depthwise_conv.bn.bias:weight_decay=0.0
2025/05/13 03:00:56 - mmengine - INFO - paramwise_options -- backbone.stage1.1.blocks.1.conv2.pointwise_conv.bn.weight:weight_decay=0.0
2025/05/13 03:00:56 - mmengine - INFO - paramwise_options -- backbone.stage1.1.blocks.1.conv2.pointwise_conv.bn.bias:weight_decay=0.0
2025/05/13 03:00:56 - mmengine - INFO - paramwise_options -- backbone.stage1.1.attention.fc.bias:weight_decay=0.0
2025/05/13 03:00:56 - mmengine - INFO - paramwise_options -- backbone.stage2.0.bn.weight:weight_decay=0.0
2025/05/13 03:00:56 - mmengine - INFO - paramwise_options -- backbone.stage2.0.bn.bias:weight_decay=0.0
2025/05/13 03:00:56 - mmengine - INFO - paramwise_options -- backbone.stage2.1.main_conv.bn.weight:weight_decay=0.0
2025/05/13 03:00:56 - mmengine - INFO - paramwise_options -- backbone.stage2.1.main_conv.bn.bias:weight_decay=0.0
2025/05/13 03:00:56 - mmengine - INFO - paramwise_options -- backbone.stage2.1.short_conv.bn.weight:weight_decay=0.0
2025/05/13 03:00:56 - mmengine - INFO - paramwise_options -- backbone.stage2.1.short_conv.bn.bias:weight_decay=0.0
2025/05/13 03:00:56 - mmengine - INFO - paramwise_options -- backbone.stage2.1.final_conv.bn.weight:weight_decay=0.0
2025/05/13 03:00:56 - mmengine - INFO - paramwise_options -- backbone.stage2.1.final_conv.bn.bias:weight_decay=0.0
2025/05/13 03:00:56 - mmengine - INFO - paramwise_options -- backbone.stage2.1.blocks.0.conv1.bn.weight:weight_decay=0.0
2025/05/13 03:00:56 - mmengine - INFO - paramwise_options -- backbone.stage2.1.blocks.0.conv1.bn.bias:weight_decay=0.0
2025/05/13 03:00:56 - mmengine - INFO - paramwise_options -- backbone.stage2.1.blocks.0.conv2.depthwise_conv.bn.weight:weight_decay=0.0
2025/05/13 03:00:56 - mmengine - INFO - paramwise_options -- backbone.stage2.1.blocks.0.conv2.depthwise_conv.bn.bias:weight_decay=0.0
2025/05/13 03:00:56 - mmengine - INFO - paramwise_options -- backbone.stage2.1.blocks.0.conv2.pointwise_conv.bn.weight:weight_decay=0.0
2025/05/13 03:00:56 - mmengine - INFO - paramwise_options -- backbone.stage2.1.blocks.0.conv2.pointwise_conv.bn.bias:weight_decay=0.0
2025/05/13 03:00:56 - mmengine - INFO - paramwise_options -- backbone.stage2.1.blocks.1.conv1.bn.weight:weight_decay=0.0
2025/05/13 03:00:56 - mmengine - INFO - paramwise_options -- backbone.stage2.1.blocks.1.conv1.bn.bias:weight_decay=0.0
2025/05/13 03:00:56 - mmengine - INFO - paramwise_options -- backbone.stage2.1.blocks.1.conv2.depthwise_conv.bn.weight:weight_decay=0.0
2025/05/13 03:00:56 - mmengine - INFO - paramwise_options -- backbone.stage2.1.blocks.1.conv2.depthwise_conv.bn.bias:weight_decay=0.0
2025/05/13 03:00:56 - mmengine - INFO - paramwise_options -- backbone.stage2.1.blocks.1.conv2.pointwise_conv.bn.weight:weight_decay=0.0
2025/05/13 03:00:56 - mmengine - INFO - paramwise_options -- backbone.stage2.1.blocks.1.conv2.pointwise_conv.bn.bias:weight_decay=0.0
2025/05/13 03:00:56 - mmengine - INFO - paramwise_options -- backbone.stage2.1.blocks.2.conv1.bn.weight:weight_decay=0.0
2025/05/13 03:00:56 - mmengine - INFO - paramwise_options -- backbone.stage2.1.blocks.2.conv1.bn.bias:weight_decay=0.0
2025/05/13 03:00:56 - mmengine - INFO - paramwise_options -- backbone.stage2.1.blocks.2.conv2.depthwise_conv.bn.weight:weight_decay=0.0
2025/05/13 03:00:56 - mmengine - INFO - paramwise_options -- backbone.stage2.1.blocks.2.conv2.depthwise_conv.bn.bias:weight_decay=0.0
2025/05/13 03:00:56 - mmengine - INFO - paramwise_options -- backbone.stage2.1.blocks.2.conv2.pointwise_conv.bn.weight:weight_decay=0.0
2025/05/13 03:00:56 - mmengine - INFO - paramwise_options -- backbone.stage2.1.blocks.2.conv2.pointwise_conv.bn.bias:weight_decay=0.0
2025/05/13 03:00:56 - mmengine - INFO - paramwise_options -- backbone.stage2.1.blocks.3.conv1.bn.weight:weight_decay=0.0
2025/05/13 03:00:56 - mmengine - INFO - paramwise_options -- backbone.stage2.1.blocks.3.conv1.bn.bias:weight_decay=0.0
2025/05/13 03:00:56 - mmengine - INFO - paramwise_options -- backbone.stage2.1.blocks.3.conv2.depthwise_conv.bn.weight:weight_decay=0.0
2025/05/13 03:00:56 - mmengine - INFO - paramwise_options -- backbone.stage2.1.blocks.3.conv2.depthwise_conv.bn.bias:weight_decay=0.0
2025/05/13 03:00:56 - mmengine - INFO - paramwise_options -- backbone.stage2.1.blocks.3.conv2.pointwise_conv.bn.weight:weight_decay=0.0
2025/05/13 03:00:56 - mmengine - INFO - paramwise_options -- backbone.stage2.1.blocks.3.conv2.pointwise_conv.bn.bias:weight_decay=0.0
2025/05/13 03:00:56 - mmengine - INFO - paramwise_options -- backbone.stage2.1.attention.fc.bias:weight_decay=0.0
2025/05/13 03:00:56 - mmengine - INFO - paramwise_options -- backbone.stage3.0.bn.weight:weight_decay=0.0
2025/05/13 03:00:56 - mmengine - INFO - paramwise_options -- backbone.stage3.0.bn.bias:weight_decay=0.0
2025/05/13 03:00:56 - mmengine - INFO - paramwise_options -- backbone.stage3.1.main_conv.bn.weight:weight_decay=0.0
2025/05/13 03:00:56 - mmengine - INFO - paramwise_options -- backbone.stage3.1.main_conv.bn.bias:weight_decay=0.0
2025/05/13 03:00:56 - mmengine - INFO - paramwise_options -- backbone.stage3.1.short_conv.bn.weight:weight_decay=0.0
2025/05/13 03:00:56 - mmengine - INFO - paramwise_options -- backbone.stage3.1.short_conv.bn.bias:weight_decay=0.0
2025/05/13 03:00:56 - mmengine - INFO - paramwise_options -- backbone.stage3.1.final_conv.bn.weight:weight_decay=0.0
2025/05/13 03:00:56 - mmengine - INFO - paramwise_options -- backbone.stage3.1.final_conv.bn.bias:weight_decay=0.0
2025/05/13 03:00:56 - mmengine - INFO - paramwise_options -- backbone.stage3.1.blocks.0.conv1.bn.weight:weight_decay=0.0
2025/05/13 03:00:56 - mmengine - INFO - paramwise_options -- backbone.stage3.1.blocks.0.conv1.bn.bias:weight_decay=0.0
2025/05/13 03:00:56 - mmengine - INFO - paramwise_options -- backbone.stage3.1.blocks.0.conv2.depthwise_conv.bn.weight:weight_decay=0.0
2025/05/13 03:00:56 - mmengine - INFO - paramwise_options -- backbone.stage3.1.blocks.0.conv2.depthwise_conv.bn.bias:weight_decay=0.0
2025/05/13 03:00:56 - mmengine - INFO - paramwise_options -- backbone.stage3.1.blocks.0.conv2.pointwise_conv.bn.weight:weight_decay=0.0
2025/05/13 03:00:56 - mmengine - INFO - paramwise_options -- backbone.stage3.1.blocks.0.conv2.pointwise_conv.bn.bias:weight_decay=0.0
2025/05/13 03:00:56 - mmengine - INFO - paramwise_options -- backbone.stage3.1.blocks.1.conv1.bn.weight:weight_decay=0.0
2025/05/13 03:00:56 - mmengine - INFO - paramwise_options -- backbone.stage3.1.blocks.1.conv1.bn.bias:weight_decay=0.0
2025/05/13 03:00:56 - mmengine - INFO - paramwise_options -- backbone.stage3.1.blocks.1.conv2.depthwise_conv.bn.weight:weight_decay=0.0
2025/05/13 03:00:56 - mmengine - INFO - paramwise_options -- backbone.stage3.1.blocks.1.conv2.depthwise_conv.bn.bias:weight_decay=0.0
2025/05/13 03:00:56 - mmengine - INFO - paramwise_options -- backbone.stage3.1.blocks.1.conv2.pointwise_conv.bn.weight:weight_decay=0.0
2025/05/13 03:00:56 - mmengine - INFO - paramwise_options -- backbone.stage3.1.blocks.1.conv2.pointwise_conv.bn.bias:weight_decay=0.0
2025/05/13 03:00:56 - mmengine - INFO - paramwise_options -- backbone.stage3.1.blocks.2.conv1.bn.weight:weight_decay=0.0
2025/05/13 03:00:56 - mmengine - INFO - paramwise_options -- backbone.stage3.1.blocks.2.conv1.bn.bias:weight_decay=0.0
2025/05/13 03:00:56 - mmengine - INFO - paramwise_options -- backbone.stage3.1.blocks.2.conv2.depthwise_conv.bn.weight:weight_decay=0.0
2025/05/13 03:00:56 - mmengine - INFO - paramwise_options -- backbone.stage3.1.blocks.2.conv2.depthwise_conv.bn.bias:weight_decay=0.0
2025/05/13 03:00:56 - mmengine - INFO - paramwise_options -- backbone.stage3.1.blocks.2.conv2.pointwise_conv.bn.weight:weight_decay=0.0
2025/05/13 03:00:56 - mmengine - INFO - paramwise_options -- backbone.stage3.1.blocks.2.conv2.pointwise_conv.bn.bias:weight_decay=0.0
2025/05/13 03:00:56 - mmengine - INFO - paramwise_options -- backbone.stage3.1.blocks.3.conv1.bn.weight:weight_decay=0.0
2025/05/13 03:00:56 - mmengine - INFO - paramwise_options -- backbone.stage3.1.blocks.3.conv1.bn.bias:weight_decay=0.0
2025/05/13 03:00:56 - mmengine - INFO - paramwise_options -- backbone.stage3.1.blocks.3.conv2.depthwise_conv.bn.weight:weight_decay=0.0
2025/05/13 03:00:56 - mmengine - INFO - paramwise_options -- backbone.stage3.1.blocks.3.conv2.depthwise_conv.bn.bias:weight_decay=0.0
2025/05/13 03:00:56 - mmengine - INFO - paramwise_options -- backbone.stage3.1.blocks.3.conv2.pointwise_conv.bn.weight:weight_decay=0.0
2025/05/13 03:00:56 - mmengine - INFO - paramwise_options -- backbone.stage3.1.blocks.3.conv2.pointwise_conv.bn.bias:weight_decay=0.0
2025/05/13 03:00:56 - mmengine - INFO - paramwise_options -- backbone.stage3.1.attention.fc.bias:weight_decay=0.0
2025/05/13 03:00:56 - mmengine - INFO - paramwise_options -- backbone.stage4.0.bn.weight:weight_decay=0.0
2025/05/13 03:00:56 - mmengine - INFO - paramwise_options -- backbone.stage4.0.bn.bias:weight_decay=0.0
2025/05/13 03:00:56 - mmengine - INFO - paramwise_options -- backbone.stage4.1.conv1.bn.weight:weight_decay=0.0
2025/05/13 03:00:56 - mmengine - INFO - paramwise_options -- backbone.stage4.1.conv1.bn.bias:weight_decay=0.0
2025/05/13 03:00:56 - mmengine - INFO - paramwise_options -- backbone.stage4.1.conv2.bn.weight:weight_decay=0.0
2025/05/13 03:00:56 - mmengine - INFO - paramwise_options -- backbone.stage4.1.conv2.bn.bias:weight_decay=0.0
2025/05/13 03:00:56 - mmengine - INFO - paramwise_options -- backbone.stage4.2.main_conv.bn.weight:weight_decay=0.0
2025/05/13 03:00:56 - mmengine - INFO - paramwise_options -- backbone.stage4.2.main_conv.bn.bias:weight_decay=0.0
2025/05/13 03:00:56 - mmengine - INFO - paramwise_options -- backbone.stage4.2.short_conv.bn.weight:weight_decay=0.0
2025/05/13 03:00:56 - mmengine - INFO - paramwise_options -- backbone.stage4.2.short_conv.bn.bias:weight_decay=0.0
2025/05/13 03:00:56 - mmengine - INFO - paramwise_options -- backbone.stage4.2.final_conv.bn.weight:weight_decay=0.0
2025/05/13 03:00:56 - mmengine - INFO - paramwise_options -- backbone.stage4.2.final_conv.bn.bias:weight_decay=0.0
2025/05/13 03:00:56 - mmengine - INFO - paramwise_options -- backbone.stage4.2.blocks.0.conv1.bn.weight:weight_decay=0.0
2025/05/13 03:00:56 - mmengine - INFO - paramwise_options -- backbone.stage4.2.blocks.0.conv1.bn.bias:weight_decay=0.0
2025/05/13 03:00:56 - mmengine - INFO - paramwise_options -- backbone.stage4.2.blocks.0.conv2.depthwise_conv.bn.weight:weight_decay=0.0
2025/05/13 03:00:56 - mmengine - INFO - paramwise_options -- backbone.stage4.2.blocks.0.conv2.depthwise_conv.bn.bias:weight_decay=0.0
2025/05/13 03:00:56 - mmengine - INFO - paramwise_options -- backbone.stage4.2.blocks.0.conv2.pointwise_conv.bn.weight:weight_decay=0.0
2025/05/13 03:00:56 - mmengine - INFO - paramwise_options -- backbone.stage4.2.blocks.0.conv2.pointwise_conv.bn.bias:weight_decay=0.0
2025/05/13 03:00:56 - mmengine - INFO - paramwise_options -- backbone.stage4.2.blocks.1.conv1.bn.weight:weight_decay=0.0
2025/05/13 03:00:56 - mmengine - INFO - paramwise_options -- backbone.stage4.2.blocks.1.conv1.bn.bias:weight_decay=0.0
2025/05/13 03:00:56 - mmengine - INFO - paramwise_options -- backbone.stage4.2.blocks.1.conv2.depthwise_conv.bn.weight:weight_decay=0.0
2025/05/13 03:00:56 - mmengine - INFO - paramwise_options -- backbone.stage4.2.blocks.1.conv2.depthwise_conv.bn.bias:weight_decay=0.0
2025/05/13 03:00:56 - mmengine - INFO - paramwise_options -- backbone.stage4.2.blocks.1.conv2.pointwise_conv.bn.weight:weight_decay=0.0
2025/05/13 03:00:56 - mmengine - INFO - paramwise_options -- backbone.stage4.2.blocks.1.conv2.pointwise_conv.bn.bias:weight_decay=0.0
2025/05/13 03:00:56 - mmengine - INFO - paramwise_options -- backbone.stage4.2.attention.fc.bias:weight_decay=0.0
2025/05/13 03:00:56 - mmengine - INFO - paramwise_options -- neck.reduce_layers.0.bn.weight:weight_decay=0.0
2025/05/13 03:00:56 - mmengine - INFO - paramwise_options -- neck.reduce_layers.0.bn.bias:weight_decay=0.0
2025/05/13 03:00:56 - mmengine - INFO - paramwise_options -- neck.reduce_layers.1.bn.weight:weight_decay=0.0
2025/05/13 03:00:56 - mmengine - INFO - paramwise_options -- neck.reduce_layers.1.bn.bias:weight_decay=0.0
2025/05/13 03:00:56 - mmengine - INFO - paramwise_options -- neck.top_down_blocks.0.main_conv.bn.weight:weight_decay=0.0
2025/05/13 03:00:56 - mmengine - INFO - paramwise_options -- neck.top_down_blocks.0.main_conv.bn.bias:weight_decay=0.0
2025/05/13 03:00:56 - mmengine - INFO - paramwise_options -- neck.top_down_blocks.0.short_conv.bn.weight:weight_decay=0.0
2025/05/13 03:00:56 - mmengine - INFO - paramwise_options -- neck.top_down_blocks.0.short_conv.bn.bias:weight_decay=0.0
2025/05/13 03:00:56 - mmengine - INFO - paramwise_options -- neck.top_down_blocks.0.final_conv.bn.weight:weight_decay=0.0
2025/05/13 03:00:56 - mmengine - INFO - paramwise_options -- neck.top_down_blocks.0.final_conv.bn.bias:weight_decay=0.0
2025/05/13 03:00:56 - mmengine - INFO - paramwise_options -- neck.top_down_blocks.0.blocks.0.conv1.bn.weight:weight_decay=0.0
2025/05/13 03:00:56 - mmengine - INFO - paramwise_options -- neck.top_down_blocks.0.blocks.0.conv1.bn.bias:weight_decay=0.0
2025/05/13 03:00:56 - mmengine - INFO - paramwise_options -- neck.top_down_blocks.0.blocks.0.conv2.depthwise_conv.bn.weight:weight_decay=0.0
2025/05/13 03:00:56 - mmengine - INFO - paramwise_options -- neck.top_down_blocks.0.blocks.0.conv2.depthwise_conv.bn.bias:weight_decay=0.0
2025/05/13 03:00:56 - mmengine - INFO - paramwise_options -- neck.top_down_blocks.0.blocks.0.conv2.pointwise_conv.bn.weight:weight_decay=0.0
2025/05/13 03:00:56 - mmengine - INFO - paramwise_options -- neck.top_down_blocks.0.blocks.0.conv2.pointwise_conv.bn.bias:weight_decay=0.0
2025/05/13 03:00:56 - mmengine - INFO - paramwise_options -- neck.top_down_blocks.0.blocks.1.conv1.bn.weight:weight_decay=0.0
2025/05/13 03:00:56 - mmengine - INFO - paramwise_options -- neck.top_down_blocks.0.blocks.1.conv1.bn.bias:weight_decay=0.0
2025/05/13 03:00:56 - mmengine - INFO - paramwise_options -- neck.top_down_blocks.0.blocks.1.conv2.depthwise_conv.bn.weight:weight_decay=0.0
2025/05/13 03:00:56 - mmengine - INFO - paramwise_options -- neck.top_down_blocks.0.blocks.1.conv2.depthwise_conv.bn.bias:weight_decay=0.0
2025/05/13 03:00:56 - mmengine - INFO - paramwise_options -- neck.top_down_blocks.0.blocks.1.conv2.pointwise_conv.bn.weight:weight_decay=0.0
2025/05/13 03:00:56 - mmengine - INFO - paramwise_options -- neck.top_down_blocks.0.blocks.1.conv2.pointwise_conv.bn.bias:weight_decay=0.0
2025/05/13 03:00:56 - mmengine - INFO - paramwise_options -- neck.top_down_blocks.1.main_conv.bn.weight:weight_decay=0.0
2025/05/13 03:00:56 - mmengine - INFO - paramwise_options -- neck.top_down_blocks.1.main_conv.bn.bias:weight_decay=0.0
2025/05/13 03:00:56 - mmengine - INFO - paramwise_options -- neck.top_down_blocks.1.short_conv.bn.weight:weight_decay=0.0
2025/05/13 03:00:56 - mmengine - INFO - paramwise_options -- neck.top_down_blocks.1.short_conv.bn.bias:weight_decay=0.0
2025/05/13 03:00:56 - mmengine - INFO - paramwise_options -- neck.top_down_blocks.1.final_conv.bn.weight:weight_decay=0.0
2025/05/13 03:00:56 - mmengine - INFO - paramwise_options -- neck.top_down_blocks.1.final_conv.bn.bias:weight_decay=0.0
2025/05/13 03:00:56 - mmengine - INFO - paramwise_options -- neck.top_down_blocks.1.blocks.0.conv1.bn.weight:weight_decay=0.0
2025/05/13 03:00:56 - mmengine - INFO - paramwise_options -- neck.top_down_blocks.1.blocks.0.conv1.bn.bias:weight_decay=0.0
2025/05/13 03:00:56 - mmengine - INFO - paramwise_options -- neck.top_down_blocks.1.blocks.0.conv2.depthwise_conv.bn.weight:weight_decay=0.0
2025/05/13 03:00:56 - mmengine - INFO - paramwise_options -- neck.top_down_blocks.1.blocks.0.conv2.depthwise_conv.bn.bias:weight_decay=0.0
2025/05/13 03:00:56 - mmengine - INFO - paramwise_options -- neck.top_down_blocks.1.blocks.0.conv2.pointwise_conv.bn.weight:weight_decay=0.0
2025/05/13 03:00:56 - mmengine - INFO - paramwise_options -- neck.top_down_blocks.1.blocks.0.conv2.pointwise_conv.bn.bias:weight_decay=0.0
2025/05/13 03:00:56 - mmengine - INFO - paramwise_options -- neck.top_down_blocks.1.blocks.1.conv1.bn.weight:weight_decay=0.0
2025/05/13 03:00:56 - mmengine - INFO - paramwise_options -- neck.top_down_blocks.1.blocks.1.conv1.bn.bias:weight_decay=0.0
2025/05/13 03:00:56 - mmengine - INFO - paramwise_options -- neck.top_down_blocks.1.blocks.1.conv2.depthwise_conv.bn.weight:weight_decay=0.0
2025/05/13 03:00:56 - mmengine - INFO - paramwise_options -- neck.top_down_blocks.1.blocks.1.conv2.depthwise_conv.bn.bias:weight_decay=0.0
2025/05/13 03:00:56 - mmengine - INFO - paramwise_options -- neck.top_down_blocks.1.blocks.1.conv2.pointwise_conv.bn.weight:weight_decay=0.0
2025/05/13 03:00:56 - mmengine - INFO - paramwise_options -- neck.top_down_blocks.1.blocks.1.conv2.pointwise_conv.bn.bias:weight_decay=0.0
2025/05/13 03:00:56 - mmengine - INFO - paramwise_options -- neck.downsamples.0.bn.weight:weight_decay=0.0
2025/05/13 03:00:56 - mmengine - INFO - paramwise_options -- neck.downsamples.0.bn.bias:weight_decay=0.0
2025/05/13 03:00:56 - mmengine - INFO - paramwise_options -- neck.downsamples.1.bn.weight:weight_decay=0.0
2025/05/13 03:00:56 - mmengine - INFO - paramwise_options -- neck.downsamples.1.bn.bias:weight_decay=0.0
2025/05/13 03:00:56 - mmengine - INFO - paramwise_options -- neck.bottom_up_blocks.0.main_conv.bn.weight:weight_decay=0.0
2025/05/13 03:00:56 - mmengine - INFO - paramwise_options -- neck.bottom_up_blocks.0.main_conv.bn.bias:weight_decay=0.0
2025/05/13 03:00:56 - mmengine - INFO - paramwise_options -- neck.bottom_up_blocks.0.short_conv.bn.weight:weight_decay=0.0
2025/05/13 03:00:56 - mmengine - INFO - paramwise_options -- neck.bottom_up_blocks.0.short_conv.bn.bias:weight_decay=0.0
2025/05/13 03:00:56 - mmengine - INFO - paramwise_options -- neck.bottom_up_blocks.0.final_conv.bn.weight:weight_decay=0.0
2025/05/13 03:00:56 - mmengine - INFO - paramwise_options -- neck.bottom_up_blocks.0.final_conv.bn.bias:weight_decay=0.0
2025/05/13 03:00:56 - mmengine - INFO - paramwise_options -- neck.bottom_up_blocks.0.blocks.0.conv1.bn.weight:weight_decay=0.0
2025/05/13 03:00:56 - mmengine - INFO - paramwise_options -- neck.bottom_up_blocks.0.blocks.0.conv1.bn.bias:weight_decay=0.0
2025/05/13 03:00:56 - mmengine - INFO - paramwise_options -- neck.bottom_up_blocks.0.blocks.0.conv2.depthwise_conv.bn.weight:weight_decay=0.0
2025/05/13 03:00:56 - mmengine - INFO - paramwise_options -- neck.bottom_up_blocks.0.blocks.0.conv2.depthwise_conv.bn.bias:weight_decay=0.0
2025/05/13 03:00:56 - mmengine - INFO - paramwise_options -- neck.bottom_up_blocks.0.blocks.0.conv2.pointwise_conv.bn.weight:weight_decay=0.0
2025/05/13 03:00:56 - mmengine - INFO - paramwise_options -- neck.bottom_up_blocks.0.blocks.0.conv2.pointwise_conv.bn.bias:weight_decay=0.0
2025/05/13 03:00:56 - mmengine - INFO - paramwise_options -- neck.bottom_up_blocks.0.blocks.1.conv1.bn.weight:weight_decay=0.0
2025/05/13 03:00:56 - mmengine - INFO - paramwise_options -- neck.bottom_up_blocks.0.blocks.1.conv1.bn.bias:weight_decay=0.0
2025/05/13 03:00:56 - mmengine - INFO - paramwise_options -- neck.bottom_up_blocks.0.blocks.1.conv2.depthwise_conv.bn.weight:weight_decay=0.0
2025/05/13 03:00:56 - mmengine - INFO - paramwise_options -- neck.bottom_up_blocks.0.blocks.1.conv2.depthwise_conv.bn.bias:weight_decay=0.0
2025/05/13 03:00:56 - mmengine - INFO - paramwise_options -- neck.bottom_up_blocks.0.blocks.1.conv2.pointwise_conv.bn.weight:weight_decay=0.0
2025/05/13 03:00:56 - mmengine - INFO - paramwise_options -- neck.bottom_up_blocks.0.blocks.1.conv2.pointwise_conv.bn.bias:weight_decay=0.0
2025/05/13 03:00:56 - mmengine - INFO - paramwise_options -- neck.bottom_up_blocks.1.main_conv.bn.weight:weight_decay=0.0
2025/05/13 03:00:56 - mmengine - INFO - paramwise_options -- neck.bottom_up_blocks.1.main_conv.bn.bias:weight_decay=0.0
2025/05/13 03:00:56 - mmengine - INFO - paramwise_options -- neck.bottom_up_blocks.1.short_conv.bn.weight:weight_decay=0.0
2025/05/13 03:00:56 - mmengine - INFO - paramwise_options -- neck.bottom_up_blocks.1.short_conv.bn.bias:weight_decay=0.0
2025/05/13 03:00:56 - mmengine - INFO - paramwise_options -- neck.bottom_up_blocks.1.final_conv.bn.weight:weight_decay=0.0
2025/05/13 03:00:56 - mmengine - INFO - paramwise_options -- neck.bottom_up_blocks.1.final_conv.bn.bias:weight_decay=0.0
2025/05/13 03:00:56 - mmengine - INFO - paramwise_options -- neck.bottom_up_blocks.1.blocks.0.conv1.bn.weight:weight_decay=0.0
2025/05/13 03:00:56 - mmengine - INFO - paramwise_options -- neck.bottom_up_blocks.1.blocks.0.conv1.bn.bias:weight_decay=0.0
2025/05/13 03:00:56 - mmengine - INFO - paramwise_options -- neck.bottom_up_blocks.1.blocks.0.conv2.depthwise_conv.bn.weight:weight_decay=0.0
2025/05/13 03:00:56 - mmengine - INFO - paramwise_options -- neck.bottom_up_blocks.1.blocks.0.conv2.depthwise_conv.bn.bias:weight_decay=0.0
2025/05/13 03:00:56 - mmengine - INFO - paramwise_options -- neck.bottom_up_blocks.1.blocks.0.conv2.pointwise_conv.bn.weight:weight_decay=0.0
2025/05/13 03:00:56 - mmengine - INFO - paramwise_options -- neck.bottom_up_blocks.1.blocks.0.conv2.pointwise_conv.bn.bias:weight_decay=0.0
2025/05/13 03:00:56 - mmengine - INFO - paramwise_options -- neck.bottom_up_blocks.1.blocks.1.conv1.bn.weight:weight_decay=0.0
2025/05/13 03:00:56 - mmengine - INFO - paramwise_options -- neck.bottom_up_blocks.1.blocks.1.conv1.bn.bias:weight_decay=0.0
2025/05/13 03:00:56 - mmengine - INFO - paramwise_options -- neck.bottom_up_blocks.1.blocks.1.conv2.depthwise_conv.bn.weight:weight_decay=0.0
2025/05/13 03:00:56 - mmengine - INFO - paramwise_options -- neck.bottom_up_blocks.1.blocks.1.conv2.depthwise_conv.bn.bias:weight_decay=0.0
2025/05/13 03:00:56 - mmengine - INFO - paramwise_options -- neck.bottom_up_blocks.1.blocks.1.conv2.pointwise_conv.bn.weight:weight_decay=0.0
2025/05/13 03:00:56 - mmengine - INFO - paramwise_options -- neck.bottom_up_blocks.1.blocks.1.conv2.pointwise_conv.bn.bias:weight_decay=0.0
2025/05/13 03:00:56 - mmengine - INFO - paramwise_options -- neck.out_convs.0.bn.weight:weight_decay=0.0
2025/05/13 03:00:56 - mmengine - INFO - paramwise_options -- neck.out_convs.0.bn.bias:weight_decay=0.0
2025/05/13 03:00:56 - mmengine - INFO - paramwise_options -- neck.out_convs.1.bn.weight:weight_decay=0.0
2025/05/13 03:00:56 - mmengine - INFO - paramwise_options -- neck.out_convs.1.bn.bias:weight_decay=0.0
2025/05/13 03:00:56 - mmengine - INFO - paramwise_options -- neck.out_convs.2.bn.weight:weight_decay=0.0
2025/05/13 03:00:56 - mmengine - INFO - paramwise_options -- neck.out_convs.2.bn.bias:weight_decay=0.0
2025/05/13 03:00:56 - mmengine - INFO - paramwise_options -- bbox_head.cls_convs.0.0.bn.weight:weight_decay=0.0
2025/05/13 03:00:56 - mmengine - INFO - paramwise_options -- bbox_head.cls_convs.0.0.bn.bias:weight_decay=0.0
2025/05/13 03:00:56 - mmengine - INFO - paramwise_options -- bbox_head.cls_convs.0.1.bn.weight:weight_decay=0.0
2025/05/13 03:00:56 - mmengine - INFO - paramwise_options -- bbox_head.cls_convs.0.1.bn.bias:weight_decay=0.0
2025/05/13 03:00:56 - mmengine - WARNING - bbox_head.cls_convs.1.0.conv is duplicate. It is skipped since bypass_duplicate=True
2025/05/13 03:00:56 - mmengine - INFO - paramwise_options -- bbox_head.cls_convs.1.0.bn.weight:weight_decay=0.0
2025/05/13 03:00:56 - mmengine - INFO - paramwise_options -- bbox_head.cls_convs.1.0.bn.bias:weight_decay=0.0
2025/05/13 03:00:56 - mmengine - WARNING - bbox_head.cls_convs.1.1.conv is duplicate. It is skipped since bypass_duplicate=True
2025/05/13 03:00:56 - mmengine - INFO - paramwise_options -- bbox_head.cls_convs.1.1.bn.weight:weight_decay=0.0
2025/05/13 03:00:56 - mmengine - INFO - paramwise_options -- bbox_head.cls_convs.1.1.bn.bias:weight_decay=0.0
2025/05/13 03:00:56 - mmengine - WARNING - bbox_head.cls_convs.2.0.conv is duplicate. It is skipped since bypass_duplicate=True
2025/05/13 03:00:56 - mmengine - INFO - paramwise_options -- bbox_head.cls_convs.2.0.bn.weight:weight_decay=0.0
2025/05/13 03:00:56 - mmengine - INFO - paramwise_options -- bbox_head.cls_convs.2.0.bn.bias:weight_decay=0.0
2025/05/13 03:00:56 - mmengine - WARNING - bbox_head.cls_convs.2.1.conv is duplicate. It is skipped since bypass_duplicate=True
2025/05/13 03:00:56 - mmengine - INFO - paramwise_options -- bbox_head.cls_convs.2.1.bn.weight:weight_decay=0.0
2025/05/13 03:00:56 - mmengine - INFO - paramwise_options -- bbox_head.cls_convs.2.1.bn.bias:weight_decay=0.0
2025/05/13 03:00:56 - mmengine - INFO - paramwise_options -- bbox_head.reg_convs.0.0.bn.weight:weight_decay=0.0
2025/05/13 03:00:56 - mmengine - INFO - paramwise_options -- bbox_head.reg_convs.0.0.bn.bias:weight_decay=0.0
2025/05/13 03:00:56 - mmengine - INFO - paramwise_options -- bbox_head.reg_convs.0.1.bn.weight:weight_decay=0.0
2025/05/13 03:00:56 - mmengine - INFO - paramwise_options -- bbox_head.reg_convs.0.1.bn.bias:weight_decay=0.0
2025/05/13 03:00:56 - mmengine - WARNING - bbox_head.reg_convs.1.0.conv is duplicate. It is skipped since bypass_duplicate=True
2025/05/13 03:00:56 - mmengine - INFO - paramwise_options -- bbox_head.reg_convs.1.0.bn.weight:weight_decay=0.0
2025/05/13 03:00:56 - mmengine - INFO - paramwise_options -- bbox_head.reg_convs.1.0.bn.bias:weight_decay=0.0
2025/05/13 03:00:56 - mmengine - WARNING - bbox_head.reg_convs.1.1.conv is duplicate. It is skipped since bypass_duplicate=True
2025/05/13 03:00:56 - mmengine - INFO - paramwise_options -- bbox_head.reg_convs.1.1.bn.weight:weight_decay=0.0
2025/05/13 03:00:56 - mmengine - INFO - paramwise_options -- bbox_head.reg_convs.1.1.bn.bias:weight_decay=0.0
2025/05/13 03:00:56 - mmengine - WARNING - bbox_head.reg_convs.2.0.conv is duplicate. It is skipped since bypass_duplicate=True
2025/05/13 03:00:56 - mmengine - INFO - paramwise_options -- bbox_head.reg_convs.2.0.bn.weight:weight_decay=0.0
2025/05/13 03:00:56 - mmengine - INFO - paramwise_options -- bbox_head.reg_convs.2.0.bn.bias:weight_decay=0.0
2025/05/13 03:00:56 - mmengine - WARNING - bbox_head.reg_convs.2.1.conv is duplicate. It is skipped since bypass_duplicate=True
2025/05/13 03:00:56 - mmengine - INFO - paramwise_options -- bbox_head.reg_convs.2.1.bn.weight:weight_decay=0.0
2025/05/13 03:00:56 - mmengine - INFO - paramwise_options -- bbox_head.reg_convs.2.1.bn.bias:weight_decay=0.0
2025/05/13 03:00:56 - mmengine - INFO - paramwise_options -- bbox_head.rtm_cls.0.bias:weight_decay=0.0
2025/05/13 03:00:56 - mmengine - INFO - paramwise_options -- bbox_head.rtm_cls.1.bias:weight_decay=0.0
2025/05/13 03:00:56 - mmengine - INFO - paramwise_options -- bbox_head.rtm_cls.2.bias:weight_decay=0.0
2025/05/13 03:00:56 - mmengine - INFO - paramwise_options -- bbox_head.rtm_reg.0.bias:weight_decay=0.0
2025/05/13 03:00:56 - mmengine - INFO - paramwise_options -- bbox_head.rtm_reg.1.bias:weight_decay=0.0
2025/05/13 03:00:56 - mmengine - INFO - paramwise_options -- bbox_head.rtm_reg.2.bias:weight_decay=0.0
Name of parameter - Initialization information

backbone.stem.0.conv.weight - torch.Size([24, 3, 3, 3]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stem.0.bn.weight - torch.Size([24]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stem.0.bn.bias - torch.Size([24]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stem.1.conv.weight - torch.Size([24, 24, 3, 3]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stem.1.bn.weight - torch.Size([24]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stem.1.bn.bias - torch.Size([24]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stem.2.conv.weight - torch.Size([48, 24, 3, 3]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stem.2.bn.weight - torch.Size([48]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stem.2.bn.bias - torch.Size([48]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage1.0.conv.weight - torch.Size([96, 48, 3, 3]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage1.0.bn.weight - torch.Size([96]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage1.0.bn.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage1.1.main_conv.conv.weight - torch.Size([48, 96, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage1.1.main_conv.bn.weight - torch.Size([48]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage1.1.main_conv.bn.bias - torch.Size([48]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage1.1.short_conv.conv.weight - torch.Size([48, 96, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage1.1.short_conv.bn.weight - torch.Size([48]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage1.1.short_conv.bn.bias - torch.Size([48]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage1.1.final_conv.conv.weight - torch.Size([96, 96, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage1.1.final_conv.bn.weight - torch.Size([96]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage1.1.final_conv.bn.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage1.1.blocks.0.conv1.conv.weight - torch.Size([48, 48, 3, 3]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage1.1.blocks.0.conv1.bn.weight - torch.Size([48]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage1.1.blocks.0.conv1.bn.bias - torch.Size([48]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage1.1.blocks.0.conv2.depthwise_conv.conv.weight - torch.Size([48, 1, 5, 5]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage1.1.blocks.0.conv2.depthwise_conv.bn.weight - torch.Size([48]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage1.1.blocks.0.conv2.depthwise_conv.bn.bias - torch.Size([48]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage1.1.blocks.0.conv2.pointwise_conv.conv.weight - torch.Size([48, 48, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage1.1.blocks.0.conv2.pointwise_conv.bn.weight - torch.Size([48]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage1.1.blocks.0.conv2.pointwise_conv.bn.bias - torch.Size([48]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage1.1.blocks.1.conv1.conv.weight - torch.Size([48, 48, 3, 3]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage1.1.blocks.1.conv1.bn.weight - torch.Size([48]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage1.1.blocks.1.conv1.bn.bias - torch.Size([48]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage1.1.blocks.1.conv2.depthwise_conv.conv.weight - torch.Size([48, 1, 5, 5]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage1.1.blocks.1.conv2.depthwise_conv.bn.weight - torch.Size([48]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage1.1.blocks.1.conv2.depthwise_conv.bn.bias - torch.Size([48]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage1.1.blocks.1.conv2.pointwise_conv.conv.weight - torch.Size([48, 48, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage1.1.blocks.1.conv2.pointwise_conv.bn.weight - torch.Size([48]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage1.1.blocks.1.conv2.pointwise_conv.bn.bias - torch.Size([48]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage1.1.attention.fc.weight - torch.Size([96, 96, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage1.1.attention.fc.bias - torch.Size([96]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage2.0.conv.weight - torch.Size([192, 96, 3, 3]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage2.0.bn.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage2.0.bn.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage2.1.main_conv.conv.weight - torch.Size([96, 192, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage2.1.main_conv.bn.weight - torch.Size([96]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage2.1.main_conv.bn.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage2.1.short_conv.conv.weight - torch.Size([96, 192, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage2.1.short_conv.bn.weight - torch.Size([96]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage2.1.short_conv.bn.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage2.1.final_conv.conv.weight - torch.Size([192, 192, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage2.1.final_conv.bn.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage2.1.final_conv.bn.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage2.1.blocks.0.conv1.conv.weight - torch.Size([96, 96, 3, 3]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage2.1.blocks.0.conv1.bn.weight - torch.Size([96]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage2.1.blocks.0.conv1.bn.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage2.1.blocks.0.conv2.depthwise_conv.conv.weight - torch.Size([96, 1, 5, 5]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage2.1.blocks.0.conv2.depthwise_conv.bn.weight - torch.Size([96]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage2.1.blocks.0.conv2.depthwise_conv.bn.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage2.1.blocks.0.conv2.pointwise_conv.conv.weight - torch.Size([96, 96, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage2.1.blocks.0.conv2.pointwise_conv.bn.weight - torch.Size([96]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage2.1.blocks.0.conv2.pointwise_conv.bn.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage2.1.blocks.1.conv1.conv.weight - torch.Size([96, 96, 3, 3]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage2.1.blocks.1.conv1.bn.weight - torch.Size([96]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage2.1.blocks.1.conv1.bn.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage2.1.blocks.1.conv2.depthwise_conv.conv.weight - torch.Size([96, 1, 5, 5]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage2.1.blocks.1.conv2.depthwise_conv.bn.weight - torch.Size([96]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage2.1.blocks.1.conv2.depthwise_conv.bn.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage2.1.blocks.1.conv2.pointwise_conv.conv.weight - torch.Size([96, 96, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage2.1.blocks.1.conv2.pointwise_conv.bn.weight - torch.Size([96]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage2.1.blocks.1.conv2.pointwise_conv.bn.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage2.1.blocks.2.conv1.conv.weight - torch.Size([96, 96, 3, 3]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage2.1.blocks.2.conv1.bn.weight - torch.Size([96]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage2.1.blocks.2.conv1.bn.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage2.1.blocks.2.conv2.depthwise_conv.conv.weight - torch.Size([96, 1, 5, 5]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage2.1.blocks.2.conv2.depthwise_conv.bn.weight - torch.Size([96]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage2.1.blocks.2.conv2.depthwise_conv.bn.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage2.1.blocks.2.conv2.pointwise_conv.conv.weight - torch.Size([96, 96, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage2.1.blocks.2.conv2.pointwise_conv.bn.weight - torch.Size([96]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage2.1.blocks.2.conv2.pointwise_conv.bn.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage2.1.blocks.3.conv1.conv.weight - torch.Size([96, 96, 3, 3]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage2.1.blocks.3.conv1.bn.weight - torch.Size([96]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage2.1.blocks.3.conv1.bn.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage2.1.blocks.3.conv2.depthwise_conv.conv.weight - torch.Size([96, 1, 5, 5]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage2.1.blocks.3.conv2.depthwise_conv.bn.weight - torch.Size([96]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage2.1.blocks.3.conv2.depthwise_conv.bn.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage2.1.blocks.3.conv2.pointwise_conv.conv.weight - torch.Size([96, 96, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage2.1.blocks.3.conv2.pointwise_conv.bn.weight - torch.Size([96]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage2.1.blocks.3.conv2.pointwise_conv.bn.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage2.1.attention.fc.weight - torch.Size([192, 192, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage2.1.attention.fc.bias - torch.Size([192]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage3.0.conv.weight - torch.Size([384, 192, 3, 3]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage3.0.bn.weight - torch.Size([384]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage3.0.bn.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage3.1.main_conv.conv.weight - torch.Size([192, 384, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage3.1.main_conv.bn.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage3.1.main_conv.bn.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage3.1.short_conv.conv.weight - torch.Size([192, 384, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage3.1.short_conv.bn.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage3.1.short_conv.bn.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage3.1.final_conv.conv.weight - torch.Size([384, 384, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage3.1.final_conv.bn.weight - torch.Size([384]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage3.1.final_conv.bn.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage3.1.blocks.0.conv1.conv.weight - torch.Size([192, 192, 3, 3]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage3.1.blocks.0.conv1.bn.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage3.1.blocks.0.conv1.bn.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage3.1.blocks.0.conv2.depthwise_conv.conv.weight - torch.Size([192, 1, 5, 5]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage3.1.blocks.0.conv2.depthwise_conv.bn.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage3.1.blocks.0.conv2.depthwise_conv.bn.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage3.1.blocks.0.conv2.pointwise_conv.conv.weight - torch.Size([192, 192, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage3.1.blocks.0.conv2.pointwise_conv.bn.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage3.1.blocks.0.conv2.pointwise_conv.bn.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage3.1.blocks.1.conv1.conv.weight - torch.Size([192, 192, 3, 3]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage3.1.blocks.1.conv1.bn.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage3.1.blocks.1.conv1.bn.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage3.1.blocks.1.conv2.depthwise_conv.conv.weight - torch.Size([192, 1, 5, 5]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage3.1.blocks.1.conv2.depthwise_conv.bn.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage3.1.blocks.1.conv2.depthwise_conv.bn.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage3.1.blocks.1.conv2.pointwise_conv.conv.weight - torch.Size([192, 192, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage3.1.blocks.1.conv2.pointwise_conv.bn.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage3.1.blocks.1.conv2.pointwise_conv.bn.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage3.1.blocks.2.conv1.conv.weight - torch.Size([192, 192, 3, 3]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage3.1.blocks.2.conv1.bn.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage3.1.blocks.2.conv1.bn.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage3.1.blocks.2.conv2.depthwise_conv.conv.weight - torch.Size([192, 1, 5, 5]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage3.1.blocks.2.conv2.depthwise_conv.bn.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage3.1.blocks.2.conv2.depthwise_conv.bn.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage3.1.blocks.2.conv2.pointwise_conv.conv.weight - torch.Size([192, 192, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage3.1.blocks.2.conv2.pointwise_conv.bn.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage3.1.blocks.2.conv2.pointwise_conv.bn.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage3.1.blocks.3.conv1.conv.weight - torch.Size([192, 192, 3, 3]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage3.1.blocks.3.conv1.bn.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage3.1.blocks.3.conv1.bn.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage3.1.blocks.3.conv2.depthwise_conv.conv.weight - torch.Size([192, 1, 5, 5]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage3.1.blocks.3.conv2.depthwise_conv.bn.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage3.1.blocks.3.conv2.depthwise_conv.bn.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage3.1.blocks.3.conv2.pointwise_conv.conv.weight - torch.Size([192, 192, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage3.1.blocks.3.conv2.pointwise_conv.bn.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage3.1.blocks.3.conv2.pointwise_conv.bn.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage3.1.attention.fc.weight - torch.Size([384, 384, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage3.1.attention.fc.bias - torch.Size([384]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage4.0.conv.weight - torch.Size([768, 384, 3, 3]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage4.0.bn.weight - torch.Size([768]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage4.0.bn.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage4.1.conv1.conv.weight - torch.Size([384, 768, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage4.1.conv1.bn.weight - torch.Size([384]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage4.1.conv1.bn.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage4.1.conv2.conv.weight - torch.Size([768, 1536, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage4.1.conv2.bn.weight - torch.Size([768]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage4.1.conv2.bn.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage4.2.main_conv.conv.weight - torch.Size([384, 768, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage4.2.main_conv.bn.weight - torch.Size([384]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage4.2.main_conv.bn.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage4.2.short_conv.conv.weight - torch.Size([384, 768, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage4.2.short_conv.bn.weight - torch.Size([384]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage4.2.short_conv.bn.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage4.2.final_conv.conv.weight - torch.Size([768, 768, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage4.2.final_conv.bn.weight - torch.Size([768]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage4.2.final_conv.bn.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage4.2.blocks.0.conv1.conv.weight - torch.Size([384, 384, 3, 3]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage4.2.blocks.0.conv1.bn.weight - torch.Size([384]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage4.2.blocks.0.conv1.bn.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage4.2.blocks.0.conv2.depthwise_conv.conv.weight - torch.Size([384, 1, 5, 5]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage4.2.blocks.0.conv2.depthwise_conv.bn.weight - torch.Size([384]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage4.2.blocks.0.conv2.depthwise_conv.bn.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage4.2.blocks.0.conv2.pointwise_conv.conv.weight - torch.Size([384, 384, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage4.2.blocks.0.conv2.pointwise_conv.bn.weight - torch.Size([384]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage4.2.blocks.0.conv2.pointwise_conv.bn.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage4.2.blocks.1.conv1.conv.weight - torch.Size([384, 384, 3, 3]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage4.2.blocks.1.conv1.bn.weight - torch.Size([384]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage4.2.blocks.1.conv1.bn.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage4.2.blocks.1.conv2.depthwise_conv.conv.weight - torch.Size([384, 1, 5, 5]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage4.2.blocks.1.conv2.depthwise_conv.bn.weight - torch.Size([384]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage4.2.blocks.1.conv2.depthwise_conv.bn.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage4.2.blocks.1.conv2.pointwise_conv.conv.weight - torch.Size([384, 384, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage4.2.blocks.1.conv2.pointwise_conv.bn.weight - torch.Size([384]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage4.2.blocks.1.conv2.pointwise_conv.bn.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage4.2.attention.fc.weight - torch.Size([768, 768, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage4.2.attention.fc.bias - torch.Size([768]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

neck.reduce_layers.0.conv.weight - torch.Size([384, 768, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

neck.reduce_layers.0.bn.weight - torch.Size([384]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.reduce_layers.0.bn.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.reduce_layers.1.conv.weight - torch.Size([192, 384, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

neck.reduce_layers.1.bn.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.reduce_layers.1.bn.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.top_down_blocks.0.main_conv.conv.weight - torch.Size([192, 768, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

neck.top_down_blocks.0.main_conv.bn.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.top_down_blocks.0.main_conv.bn.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.top_down_blocks.0.short_conv.conv.weight - torch.Size([192, 768, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

neck.top_down_blocks.0.short_conv.bn.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.top_down_blocks.0.short_conv.bn.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.top_down_blocks.0.final_conv.conv.weight - torch.Size([384, 384, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

neck.top_down_blocks.0.final_conv.bn.weight - torch.Size([384]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.top_down_blocks.0.final_conv.bn.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.top_down_blocks.0.blocks.0.conv1.conv.weight - torch.Size([192, 192, 3, 3]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

neck.top_down_blocks.0.blocks.0.conv1.bn.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.top_down_blocks.0.blocks.0.conv1.bn.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.top_down_blocks.0.blocks.0.conv2.depthwise_conv.conv.weight - torch.Size([192, 1, 5, 5]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

neck.top_down_blocks.0.blocks.0.conv2.depthwise_conv.bn.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.top_down_blocks.0.blocks.0.conv2.depthwise_conv.bn.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.top_down_blocks.0.blocks.0.conv2.pointwise_conv.conv.weight - torch.Size([192, 192, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

neck.top_down_blocks.0.blocks.0.conv2.pointwise_conv.bn.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.top_down_blocks.0.blocks.0.conv2.pointwise_conv.bn.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.top_down_blocks.0.blocks.1.conv1.conv.weight - torch.Size([192, 192, 3, 3]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

neck.top_down_blocks.0.blocks.1.conv1.bn.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.top_down_blocks.0.blocks.1.conv1.bn.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.top_down_blocks.0.blocks.1.conv2.depthwise_conv.conv.weight - torch.Size([192, 1, 5, 5]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

neck.top_down_blocks.0.blocks.1.conv2.depthwise_conv.bn.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.top_down_blocks.0.blocks.1.conv2.depthwise_conv.bn.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.top_down_blocks.0.blocks.1.conv2.pointwise_conv.conv.weight - torch.Size([192, 192, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

neck.top_down_blocks.0.blocks.1.conv2.pointwise_conv.bn.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.top_down_blocks.0.blocks.1.conv2.pointwise_conv.bn.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.top_down_blocks.1.main_conv.conv.weight - torch.Size([96, 384, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

neck.top_down_blocks.1.main_conv.bn.weight - torch.Size([96]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.top_down_blocks.1.main_conv.bn.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.top_down_blocks.1.short_conv.conv.weight - torch.Size([96, 384, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

neck.top_down_blocks.1.short_conv.bn.weight - torch.Size([96]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.top_down_blocks.1.short_conv.bn.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.top_down_blocks.1.final_conv.conv.weight - torch.Size([192, 192, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

neck.top_down_blocks.1.final_conv.bn.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.top_down_blocks.1.final_conv.bn.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.top_down_blocks.1.blocks.0.conv1.conv.weight - torch.Size([96, 96, 3, 3]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

neck.top_down_blocks.1.blocks.0.conv1.bn.weight - torch.Size([96]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.top_down_blocks.1.blocks.0.conv1.bn.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.top_down_blocks.1.blocks.0.conv2.depthwise_conv.conv.weight - torch.Size([96, 1, 5, 5]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

neck.top_down_blocks.1.blocks.0.conv2.depthwise_conv.bn.weight - torch.Size([96]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.top_down_blocks.1.blocks.0.conv2.depthwise_conv.bn.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.top_down_blocks.1.blocks.0.conv2.pointwise_conv.conv.weight - torch.Size([96, 96, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

neck.top_down_blocks.1.blocks.0.conv2.pointwise_conv.bn.weight - torch.Size([96]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.top_down_blocks.1.blocks.0.conv2.pointwise_conv.bn.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.top_down_blocks.1.blocks.1.conv1.conv.weight - torch.Size([96, 96, 3, 3]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

neck.top_down_blocks.1.blocks.1.conv1.bn.weight - torch.Size([96]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.top_down_blocks.1.blocks.1.conv1.bn.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.top_down_blocks.1.blocks.1.conv2.depthwise_conv.conv.weight - torch.Size([96, 1, 5, 5]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

neck.top_down_blocks.1.blocks.1.conv2.depthwise_conv.bn.weight - torch.Size([96]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.top_down_blocks.1.blocks.1.conv2.depthwise_conv.bn.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.top_down_blocks.1.blocks.1.conv2.pointwise_conv.conv.weight - torch.Size([96, 96, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

neck.top_down_blocks.1.blocks.1.conv2.pointwise_conv.bn.weight - torch.Size([96]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.top_down_blocks.1.blocks.1.conv2.pointwise_conv.bn.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.downsamples.0.conv.weight - torch.Size([192, 192, 3, 3]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

neck.downsamples.0.bn.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.downsamples.0.bn.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.downsamples.1.conv.weight - torch.Size([384, 384, 3, 3]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

neck.downsamples.1.bn.weight - torch.Size([384]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.downsamples.1.bn.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.bottom_up_blocks.0.main_conv.conv.weight - torch.Size([192, 384, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

neck.bottom_up_blocks.0.main_conv.bn.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.bottom_up_blocks.0.main_conv.bn.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.bottom_up_blocks.0.short_conv.conv.weight - torch.Size([192, 384, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

neck.bottom_up_blocks.0.short_conv.bn.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.bottom_up_blocks.0.short_conv.bn.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.bottom_up_blocks.0.final_conv.conv.weight - torch.Size([384, 384, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

neck.bottom_up_blocks.0.final_conv.bn.weight - torch.Size([384]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.bottom_up_blocks.0.final_conv.bn.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.bottom_up_blocks.0.blocks.0.conv1.conv.weight - torch.Size([192, 192, 3, 3]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

neck.bottom_up_blocks.0.blocks.0.conv1.bn.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.bottom_up_blocks.0.blocks.0.conv1.bn.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.bottom_up_blocks.0.blocks.0.conv2.depthwise_conv.conv.weight - torch.Size([192, 1, 5, 5]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

neck.bottom_up_blocks.0.blocks.0.conv2.depthwise_conv.bn.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.bottom_up_blocks.0.blocks.0.conv2.depthwise_conv.bn.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.bottom_up_blocks.0.blocks.0.conv2.pointwise_conv.conv.weight - torch.Size([192, 192, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

neck.bottom_up_blocks.0.blocks.0.conv2.pointwise_conv.bn.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.bottom_up_blocks.0.blocks.0.conv2.pointwise_conv.bn.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.bottom_up_blocks.0.blocks.1.conv1.conv.weight - torch.Size([192, 192, 3, 3]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

neck.bottom_up_blocks.0.blocks.1.conv1.bn.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.bottom_up_blocks.0.blocks.1.conv1.bn.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.bottom_up_blocks.0.blocks.1.conv2.depthwise_conv.conv.weight - torch.Size([192, 1, 5, 5]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

neck.bottom_up_blocks.0.blocks.1.conv2.depthwise_conv.bn.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.bottom_up_blocks.0.blocks.1.conv2.depthwise_conv.bn.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.bottom_up_blocks.0.blocks.1.conv2.pointwise_conv.conv.weight - torch.Size([192, 192, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

neck.bottom_up_blocks.0.blocks.1.conv2.pointwise_conv.bn.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.bottom_up_blocks.0.blocks.1.conv2.pointwise_conv.bn.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.bottom_up_blocks.1.main_conv.conv.weight - torch.Size([384, 768, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

neck.bottom_up_blocks.1.main_conv.bn.weight - torch.Size([384]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.bottom_up_blocks.1.main_conv.bn.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.bottom_up_blocks.1.short_conv.conv.weight - torch.Size([384, 768, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

neck.bottom_up_blocks.1.short_conv.bn.weight - torch.Size([384]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.bottom_up_blocks.1.short_conv.bn.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.bottom_up_blocks.1.final_conv.conv.weight - torch.Size([768, 768, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

neck.bottom_up_blocks.1.final_conv.bn.weight - torch.Size([768]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.bottom_up_blocks.1.final_conv.bn.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.bottom_up_blocks.1.blocks.0.conv1.conv.weight - torch.Size([384, 384, 3, 3]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

neck.bottom_up_blocks.1.blocks.0.conv1.bn.weight - torch.Size([384]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.bottom_up_blocks.1.blocks.0.conv1.bn.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.bottom_up_blocks.1.blocks.0.conv2.depthwise_conv.conv.weight - torch.Size([384, 1, 5, 5]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

neck.bottom_up_blocks.1.blocks.0.conv2.depthwise_conv.bn.weight - torch.Size([384]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.bottom_up_blocks.1.blocks.0.conv2.depthwise_conv.bn.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.bottom_up_blocks.1.blocks.0.conv2.pointwise_conv.conv.weight - torch.Size([384, 384, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

neck.bottom_up_blocks.1.blocks.0.conv2.pointwise_conv.bn.weight - torch.Size([384]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.bottom_up_blocks.1.blocks.0.conv2.pointwise_conv.bn.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.bottom_up_blocks.1.blocks.1.conv1.conv.weight - torch.Size([384, 384, 3, 3]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

neck.bottom_up_blocks.1.blocks.1.conv1.bn.weight - torch.Size([384]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.bottom_up_blocks.1.blocks.1.conv1.bn.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.bottom_up_blocks.1.blocks.1.conv2.depthwise_conv.conv.weight - torch.Size([384, 1, 5, 5]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

neck.bottom_up_blocks.1.blocks.1.conv2.depthwise_conv.bn.weight - torch.Size([384]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.bottom_up_blocks.1.blocks.1.conv2.depthwise_conv.bn.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.bottom_up_blocks.1.blocks.1.conv2.pointwise_conv.conv.weight - torch.Size([384, 384, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

neck.bottom_up_blocks.1.blocks.1.conv2.pointwise_conv.bn.weight - torch.Size([384]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.bottom_up_blocks.1.blocks.1.conv2.pointwise_conv.bn.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.out_convs.0.conv.weight - torch.Size([192, 192, 3, 3]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

neck.out_convs.0.bn.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.out_convs.0.bn.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.out_convs.1.conv.weight - torch.Size([192, 384, 3, 3]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

neck.out_convs.1.bn.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.out_convs.1.bn.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.out_convs.2.conv.weight - torch.Size([192, 768, 3, 3]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

neck.out_convs.2.bn.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.out_convs.2.bn.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

bbox_head.cls_convs.0.0.conv.weight - torch.Size([192, 192, 3, 3]): 
Initialized by user-defined `init_weights` in RTMDetSepBNHead  

bbox_head.cls_convs.0.0.bn.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

bbox_head.cls_convs.0.0.bn.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

bbox_head.cls_convs.0.1.conv.weight - torch.Size([192, 192, 3, 3]): 
Initialized by user-defined `init_weights` in RTMDetSepBNHead  

bbox_head.cls_convs.0.1.bn.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

bbox_head.cls_convs.0.1.bn.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

bbox_head.cls_convs.1.0.bn.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

bbox_head.cls_convs.1.0.bn.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

bbox_head.cls_convs.1.1.bn.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

bbox_head.cls_convs.1.1.bn.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

bbox_head.cls_convs.2.0.bn.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

bbox_head.cls_convs.2.0.bn.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

bbox_head.cls_convs.2.1.bn.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

bbox_head.cls_convs.2.1.bn.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

bbox_head.reg_convs.0.0.conv.weight - torch.Size([192, 192, 3, 3]): 
Initialized by user-defined `init_weights` in RTMDetSepBNHead  

bbox_head.reg_convs.0.0.bn.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

bbox_head.reg_convs.0.0.bn.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

bbox_head.reg_convs.0.1.conv.weight - torch.Size([192, 192, 3, 3]): 
Initialized by user-defined `init_weights` in RTMDetSepBNHead  

bbox_head.reg_convs.0.1.bn.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

bbox_head.reg_convs.0.1.bn.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

bbox_head.reg_convs.1.0.bn.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

bbox_head.reg_convs.1.0.bn.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

bbox_head.reg_convs.1.1.bn.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

bbox_head.reg_convs.1.1.bn.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

bbox_head.reg_convs.2.0.bn.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

bbox_head.reg_convs.2.0.bn.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

bbox_head.reg_convs.2.1.bn.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

bbox_head.reg_convs.2.1.bn.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

bbox_head.rtm_cls.0.weight - torch.Size([1, 192, 1, 1]): 
Initialized by user-defined `init_weights` in RTMDetSepBNHead  

bbox_head.rtm_cls.0.bias - torch.Size([1]): 
Initialized by user-defined `init_weights` in RTMDetSepBNHead  

bbox_head.rtm_cls.1.weight - torch.Size([1, 192, 1, 1]): 
Initialized by user-defined `init_weights` in RTMDetSepBNHead  

bbox_head.rtm_cls.1.bias - torch.Size([1]): 
Initialized by user-defined `init_weights` in RTMDetSepBNHead  

bbox_head.rtm_cls.2.weight - torch.Size([1, 192, 1, 1]): 
Initialized by user-defined `init_weights` in RTMDetSepBNHead  

bbox_head.rtm_cls.2.bias - torch.Size([1]): 
Initialized by user-defined `init_weights` in RTMDetSepBNHead  

bbox_head.rtm_reg.0.weight - torch.Size([4, 192, 1, 1]): 
Initialized by user-defined `init_weights` in RTMDetSepBNHead  

bbox_head.rtm_reg.0.bias - torch.Size([4]): 
Initialized by user-defined `init_weights` in RTMDetSepBNHead  

bbox_head.rtm_reg.1.weight - torch.Size([4, 192, 1, 1]): 
Initialized by user-defined `init_weights` in RTMDetSepBNHead  

bbox_head.rtm_reg.1.bias - torch.Size([4]): 
Initialized by user-defined `init_weights` in RTMDetSepBNHead  

bbox_head.rtm_reg.2.weight - torch.Size([4, 192, 1, 1]): 
Initialized by user-defined `init_weights` in RTMDetSepBNHead  

bbox_head.rtm_reg.2.bias - torch.Size([4]): 
Initialized by user-defined `init_weights` in RTMDetSepBNHead  
2025/05/13 03:00:56 - mmengine - INFO - Load checkpoint from /home/jaa/Work/Prog/BSU/Detectors/work_dirs/RTMDet/RTMDet_m_30e_new3_custom/epoch_5.pth
2025/05/13 03:00:56 - mmengine - INFO - resumed epoch: 5, iter: 6550
2025/05/13 03:00:56 - mmengine - INFO - Backbone frozen before training.
2025/05/13 03:00:56 - mmengine - WARNING - "FileClient" will be deprecated in future. Please use io functions in https://mmengine.readthedocs.io/en/latest/api/fileio.html#file-io
2025/05/13 03:00:56 - mmengine - WARNING - "HardDiskBackend" is the alias of "LocalBackend" and the former will be deprecated in future.
2025/05/13 03:00:56 - mmengine - INFO - Checkpoints will be saved to /home/jaa/Work/Prog/BSU/Detectors/work_dirs/RTMDet/RTMDet_m_30e_new1_custom.
2025/05/13 03:00:56 - mmengine - INFO - Backbone was unfrozen at epoch 5
2025/05/13 03:01:12 - mmengine - INFO - Epoch(train)  [6][  50/1528]  base_lr: 1.2500e-03 lr: 1.2500e-03  eta: 3:25:15  time: 0.3139  data_time: 0.0045  memory: 19484  loss: 0.7682  loss_cls: 0.4260  loss_bbox: 0.3422
2025/05/13 03:01:27 - mmengine - INFO - Epoch(train)  [6][ 100/1528]  base_lr: 1.2500e-03 lr: 1.2500e-03  eta: 3:21:47  time: 0.3041  data_time: 0.0005  memory: 19511  loss: 0.8197  loss_cls: 0.4585  loss_bbox: 0.3613
2025/05/13 03:01:42 - mmengine - INFO - Epoch(train)  [6][ 150/1528]  base_lr: 1.2500e-03 lr: 1.2500e-03  eta: 3:20:18  time: 0.3033  data_time: 0.0006  memory: 19485  loss: 0.6323  loss_cls: 0.3352  loss_bbox: 0.2971
2025/05/13 03:01:57 - mmengine - INFO - Epoch(train)  [6][ 200/1528]  base_lr: 1.2500e-03 lr: 1.2500e-03  eta: 3:19:26  time: 0.3033  data_time: 0.0005  memory: 19500  loss: 0.6149  loss_cls: 0.3190  loss_bbox: 0.2958
2025/05/13 03:02:13 - mmengine - INFO - Epoch(train)  [6][ 250/1528]  base_lr: 1.2500e-03 lr: 1.2500e-03  eta: 3:19:15  time: 0.3067  data_time: 0.0005  memory: 19487  loss: 0.5795  loss_cls: 0.3116  loss_bbox: 0.2679
2025/05/13 03:02:28 - mmengine - INFO - Epoch(train)  [6][ 300/1528]  base_lr: 1.2500e-03 lr: 1.2500e-03  eta: 3:18:43  time: 0.3036  data_time: 0.0005  memory: 19513  loss: 0.5396  loss_cls: 0.2749  loss_bbox: 0.2647
2025/05/13 03:02:43 - mmengine - INFO - Epoch(train)  [6][ 350/1528]  base_lr: 1.2500e-03 lr: 1.2500e-03  eta: 3:18:20  time: 0.3044  data_time: 0.0005  memory: 19504  loss: 0.6043  loss_cls: 0.3173  loss_bbox: 0.2871
2025/05/13 03:02:58 - mmengine - INFO - Epoch(train)  [6][ 400/1528]  base_lr: 1.2500e-03 lr: 1.2500e-03  eta: 3:17:51  time: 0.3029  data_time: 0.0005  memory: 19481  loss: 0.5613  loss_cls: 0.2918  loss_bbox: 0.2695
2025/05/13 03:03:14 - mmengine - INFO - Exp name: rtmdet_m_1x_custom_resume_20250513_030051
2025/05/13 03:03:14 - mmengine - INFO - Epoch(train)  [6][ 450/1528]  base_lr: 1.2500e-03 lr: 1.2500e-03  eta: 3:17:29  time: 0.3037  data_time: 0.0005  memory: 19510  loss: 0.5360  loss_cls: 0.2671  loss_bbox: 0.2689
2025/05/13 03:03:29 - mmengine - INFO - Epoch(train)  [6][ 500/1528]  base_lr: 1.2500e-03 lr: 1.2500e-03  eta: 3:17:13  time: 0.3048  data_time: 0.0006  memory: 19503  loss: 0.4963  loss_cls: 0.2391  loss_bbox: 0.2572
2025/05/13 03:03:44 - mmengine - INFO - Epoch(train)  [6][ 550/1528]  base_lr: 1.2500e-03 lr: 1.2500e-03  eta: 3:16:53  time: 0.3038  data_time: 0.0006  memory: 19482  loss: 0.4934  loss_cls: 0.2410  loss_bbox: 0.2524
2025/05/13 03:03:59 - mmengine - INFO - Epoch(train)  [6][ 600/1528]  base_lr: 1.2500e-03 lr: 1.2500e-03  eta: 3:16:35  time: 0.3040  data_time: 0.0005  memory: 19500  loss: 0.5337  loss_cls: 0.2616  loss_bbox: 0.2721
2025/05/13 03:04:14 - mmengine - INFO - Epoch(train)  [6][ 650/1528]  base_lr: 1.2500e-03 lr: 1.2500e-03  eta: 3:16:14  time: 0.3028  data_time: 0.0005  memory: 19474  loss: 0.5033  loss_cls: 0.2494  loss_bbox: 0.2538
2025/05/13 03:04:30 - mmengine - INFO - Epoch(train)  [6][ 700/1528]  base_lr: 1.2500e-03 lr: 1.2500e-03  eta: 3:16:03  time: 0.3062  data_time: 0.0005  memory: 19484  loss: 0.5191  loss_cls: 0.2573  loss_bbox: 0.2618
2025/05/13 03:04:45 - mmengine - INFO - Epoch(train)  [6][ 750/1528]  base_lr: 1.2500e-03 lr: 1.2500e-03  eta: 3:15:40  time: 0.3018  data_time: 0.0005  memory: 19491  loss: 0.5105  loss_cls: 0.2485  loss_bbox: 0.2620
2025/05/13 03:05:00 - mmengine - INFO - Epoch(train)  [6][ 800/1528]  base_lr: 1.2500e-03 lr: 1.2500e-03  eta: 3:15:29  time: 0.3065  data_time: 0.0006  memory: 19493  loss: 0.5317  loss_cls: 0.2657  loss_bbox: 0.2660
2025/05/13 03:05:15 - mmengine - INFO - Epoch(train)  [6][ 850/1528]  base_lr: 1.2500e-03 lr: 1.2500e-03  eta: 3:15:06  time: 0.3015  data_time: 0.0005  memory: 19485  loss: 0.5162  loss_cls: 0.2558  loss_bbox: 0.2603
2025/05/13 03:05:31 - mmengine - INFO - Epoch(train)  [6][ 900/1528]  base_lr: 1.2500e-03 lr: 1.2500e-03  eta: 3:14:59  time: 0.3081  data_time: 0.0006  memory: 19487  loss: 0.5259  loss_cls: 0.2546  loss_bbox: 0.2713
2025/05/13 03:05:46 - mmengine - INFO - Epoch(train)  [6][ 950/1528]  base_lr: 1.2500e-03 lr: 1.2500e-03  eta: 3:14:38  time: 0.3022  data_time: 0.0005  memory: 19475  loss: 0.4931  loss_cls: 0.2379  loss_bbox: 0.2553
2025/05/13 03:06:01 - mmengine - INFO - Epoch(train)  [6][1000/1528]  base_lr: 1.2500e-03 lr: 1.2500e-03  eta: 3:14:38  time: 0.3124  data_time: 0.0005  memory: 19512  loss: 0.4786  loss_cls: 0.2236  loss_bbox: 0.2551
2025/05/13 03:06:16 - mmengine - INFO - Epoch(train)  [6][1050/1528]  base_lr: 1.2500e-03 lr: 1.2500e-03  eta: 3:14:23  time: 0.3051  data_time: 0.0005  memory: 19482  loss: 0.4689  loss_cls: 0.2251  loss_bbox: 0.2438
2025/05/13 03:06:32 - mmengine - INFO - Epoch(train)  [6][1100/1528]  base_lr: 1.2500e-03 lr: 1.2500e-03  eta: 3:14:04  time: 0.3028  data_time: 0.0005  memory: 19492  loss: 0.5076  loss_cls: 0.2435  loss_bbox: 0.2640
2025/05/13 03:06:47 - mmengine - INFO - Epoch(train)  [6][1150/1528]  base_lr: 1.2500e-03 lr: 1.2500e-03  eta: 3:13:42  time: 0.3007  data_time: 0.0005  memory: 19512  loss: 0.5260  loss_cls: 0.2533  loss_bbox: 0.2727
2025/05/13 03:07:02 - mmengine - INFO - Epoch(train)  [6][1200/1528]  base_lr: 1.2500e-03 lr: 1.2500e-03  eta: 3:13:25  time: 0.3037  data_time: 0.0005  memory: 19504  loss: 0.4860  loss_cls: 0.2348  loss_bbox: 0.2512
2025/05/13 03:07:17 - mmengine - INFO - Epoch(train)  [6][1250/1528]  base_lr: 1.2500e-03 lr: 1.2500e-03  eta: 3:13:04  time: 0.3009  data_time: 0.0005  memory: 19500  loss: 0.5067  loss_cls: 0.2500  loss_bbox: 0.2566
2025/05/13 03:07:32 - mmengine - INFO - Epoch(train)  [6][1300/1528]  base_lr: 1.2500e-03 lr: 1.2500e-03  eta: 3:12:47  time: 0.3034  data_time: 0.0005  memory: 19505  loss: 0.4848  loss_cls: 0.2316  loss_bbox: 0.2533
2025/05/13 03:07:47 - mmengine - INFO - Epoch(train)  [6][1350/1528]  base_lr: 1.2500e-03 lr: 1.2500e-03  eta: 3:12:26  time: 0.3006  data_time: 0.0005  memory: 19502  loss: 0.4999  loss_cls: 0.2523  loss_bbox: 0.2476
2025/05/13 03:08:02 - mmengine - INFO - Epoch(train)  [6][1400/1528]  base_lr: 1.2500e-03 lr: 1.2500e-03  eta: 3:12:10  time: 0.3037  data_time: 0.0005  memory: 19490  loss: 0.4580  loss_cls: 0.2163  loss_bbox: 0.2417
2025/05/13 03:08:17 - mmengine - INFO - Exp name: rtmdet_m_1x_custom_resume_20250513_030051
2025/05/13 03:08:17 - mmengine - INFO - Epoch(train)  [6][1450/1528]  base_lr: 1.2500e-03 lr: 1.2500e-03  eta: 3:11:51  time: 0.3010  data_time: 0.0005  memory: 19487  loss: 0.4870  loss_cls: 0.2402  loss_bbox: 0.2468
2025/05/13 03:08:33 - mmengine - INFO - Epoch(train)  [6][1500/1528]  base_lr: 1.2500e-03 lr: 1.2500e-03  eta: 3:11:36  time: 0.3046  data_time: 0.0005  memory: 19511  loss: 0.4840  loss_cls: 0.2274  loss_bbox: 0.2567
2025/05/13 03:08:41 - mmengine - INFO - Exp name: rtmdet_m_1x_custom_resume_20250513_030051
2025/05/13 03:08:41 - mmengine - INFO - Saving checkpoint at 6 epochs
2025/05/13 03:08:46 - mmengine - INFO - Epoch(val)  [6][ 50/149]    eta: 0:00:08  time: 0.0841  data_time: 0.0057  memory: 19481  
2025/05/13 03:08:50 - mmengine - INFO - Epoch(val)  [6][100/149]    eta: 0:00:04  time: 0.0811  data_time: 0.0025  memory: 1598  
2025/05/13 03:08:55 - mmengine - INFO - Evaluating bbox...
2025/05/13 03:08:57 - mmengine - INFO - bbox_mAP_copypaste: 0.734 0.931 0.830 0.392 0.637 0.776
2025/05/13 03:08:57 - mmengine - INFO - Epoch(val) [6][149/149]    coco/bbox_mAP: 0.7340  coco/bbox_mAP_50: 0.9310  coco/bbox_mAP_75: 0.8300  coco/bbox_mAP_s: 0.3920  coco/bbox_mAP_m: 0.6370  coco/bbox_mAP_l: 0.7760  data_time: 0.0036  time: 0.0814
2025/05/13 03:09:13 - mmengine - INFO - Epoch(train)  [7][  50/1528]  base_lr: 8.6373e-04 lr: 8.6373e-04  eta: 3:11:08  time: 0.3042  data_time: 0.0025  memory: 19511  loss: 0.4724  loss_cls: 0.2233  loss_bbox: 0.2491
2025/05/13 03:09:28 - mmengine - INFO - Epoch(train)  [7][ 100/1528]  base_lr: 8.6373e-04 lr: 8.6373e-04  eta: 3:10:50  time: 0.3021  data_time: 0.0005  memory: 19490  loss: 0.4585  loss_cls: 0.2180  loss_bbox: 0.2405
2025/05/13 03:09:43 - mmengine - INFO - Epoch(train)  [7][ 150/1528]  base_lr: 8.6373e-04 lr: 8.6373e-04  eta: 3:10:33  time: 0.3019  data_time: 0.0005  memory: 19509  loss: 0.4568  loss_cls: 0.2211  loss_bbox: 0.2358
2025/05/13 03:09:58 - mmengine - INFO - Epoch(train)  [7][ 200/1528]  base_lr: 8.6373e-04 lr: 8.6373e-04  eta: 3:10:15  time: 0.3017  data_time: 0.0005  memory: 19491  loss: 0.4861  loss_cls: 0.2326  loss_bbox: 0.2536
2025/05/13 03:10:13 - mmengine - INFO - Epoch(train)  [7][ 250/1528]  base_lr: 8.6373e-04 lr: 8.6373e-04  eta: 3:10:04  time: 0.3073  data_time: 0.0005  memory: 19485  loss: 0.4610  loss_cls: 0.2201  loss_bbox: 0.2409
2025/05/13 03:10:28 - mmengine - INFO - Epoch(train)  [7][ 300/1528]  base_lr: 8.6373e-04 lr: 8.6373e-04  eta: 3:09:45  time: 0.3006  data_time: 0.0005  memory: 19504  loss: 0.4463  loss_cls: 0.2015  loss_bbox: 0.2448
2025/05/13 03:10:44 - mmengine - INFO - Epoch(train)  [7][ 350/1528]  base_lr: 8.6373e-04 lr: 8.6373e-04  eta: 3:09:29  time: 0.3036  data_time: 0.0005  memory: 19484  loss: 0.4410  loss_cls: 0.2062  loss_bbox: 0.2348
2025/05/13 03:10:59 - mmengine - INFO - Epoch(train)  [7][ 400/1528]  base_lr: 8.6373e-04 lr: 8.6373e-04  eta: 3:09:12  time: 0.3014  data_time: 0.0005  memory: 19488  loss: 0.4471  loss_cls: 0.2124  loss_bbox: 0.2347
2025/05/13 03:11:14 - mmengine - INFO - Epoch(train)  [7][ 450/1528]  base_lr: 8.6373e-04 lr: 8.6373e-04  eta: 3:08:56  time: 0.3030  data_time: 0.0005  memory: 19491  loss: 0.4423  loss_cls: 0.2081  loss_bbox: 0.2342
2025/05/13 03:11:29 - mmengine - INFO - Epoch(train)  [7][ 500/1528]  base_lr: 8.6373e-04 lr: 8.6373e-04  eta: 3:08:38  time: 0.3010  data_time: 0.0005  memory: 19511  loss: 0.4743  loss_cls: 0.2241  loss_bbox: 0.2503
2025/05/13 03:11:44 - mmengine - INFO - Epoch(train)  [7][ 550/1528]  base_lr: 8.6373e-04 lr: 8.6373e-04  eta: 3:08:22  time: 0.3032  data_time: 0.0005  memory: 19483  loss: 0.4705  loss_cls: 0.2267  loss_bbox: 0.2437
2025/05/13 03:11:59 - mmengine - INFO - Epoch(train)  [7][ 600/1528]  base_lr: 8.6373e-04 lr: 8.6373e-04  eta: 3:08:05  time: 0.3014  data_time: 0.0005  memory: 19504  loss: 0.4416  loss_cls: 0.2038  loss_bbox: 0.2379
2025/05/13 03:12:14 - mmengine - INFO - Epoch(train)  [7][ 650/1528]  base_lr: 8.6373e-04 lr: 8.6373e-04  eta: 3:07:50  time: 0.3033  data_time: 0.0006  memory: 19502  loss: 0.4494  loss_cls: 0.2053  loss_bbox: 0.2441
2025/05/13 03:12:29 - mmengine - INFO - Epoch(train)  [7][ 700/1528]  base_lr: 8.6373e-04 lr: 8.6373e-04  eta: 3:07:33  time: 0.3016  data_time: 0.0005  memory: 19506  loss: 0.4828  loss_cls: 0.2305  loss_bbox: 0.2523
2025/05/13 03:12:44 - mmengine - INFO - Epoch(train)  [7][ 750/1528]  base_lr: 8.6373e-04 lr: 8.6373e-04  eta: 3:07:18  time: 0.3038  data_time: 0.0005  memory: 19493  loss: 0.4843  loss_cls: 0.2327  loss_bbox: 0.2517
2025/05/13 03:13:00 - mmengine - INFO - Epoch(train)  [7][ 800/1528]  base_lr: 8.6373e-04 lr: 8.6373e-04  eta: 3:07:01  time: 0.3013  data_time: 0.0005  memory: 19495  loss: 0.4850  loss_cls: 0.2310  loss_bbox: 0.2539
2025/05/13 03:13:15 - mmengine - INFO - Epoch(train)  [7][ 850/1528]  base_lr: 8.6373e-04 lr: 8.6373e-04  eta: 3:06:46  time: 0.3044  data_time: 0.0006  memory: 19477  loss: 0.4733  loss_cls: 0.2304  loss_bbox: 0.2429
2025/05/13 03:13:30 - mmengine - INFO - Epoch(train)  [7][ 900/1528]  base_lr: 8.6373e-04 lr: 8.6373e-04  eta: 3:06:29  time: 0.3011  data_time: 0.0005  memory: 19483  loss: 0.4340  loss_cls: 0.2034  loss_bbox: 0.2306
2025/05/13 03:13:36 - mmengine - INFO - Exp name: rtmdet_m_1x_custom_resume_20250513_030051
2025/05/13 03:13:45 - mmengine - INFO - Epoch(train)  [7][ 950/1528]  base_lr: 8.6373e-04 lr: 8.6373e-04  eta: 3:06:14  time: 0.3040  data_time: 0.0005  memory: 19481  loss: 0.4264  loss_cls: 0.1994  loss_bbox: 0.2269
2025/05/13 03:14:00 - mmengine - INFO - Epoch(train)  [7][1000/1528]  base_lr: 8.6373e-04 lr: 8.6373e-04  eta: 3:05:58  time: 0.3024  data_time: 0.0006  memory: 19493  loss: 0.4574  loss_cls: 0.2228  loss_bbox: 0.2346
2025/05/13 03:14:15 - mmengine - INFO - Epoch(train)  [7][1050/1528]  base_lr: 8.6373e-04 lr: 8.6373e-04  eta: 3:05:45  time: 0.3070  data_time: 0.0005  memory: 19497  loss: 0.4532  loss_cls: 0.2034  loss_bbox: 0.2497
2025/05/13 03:14:31 - mmengine - INFO - Epoch(train)  [7][1100/1528]  base_lr: 8.6373e-04 lr: 8.6373e-04  eta: 3:05:28  time: 0.3013  data_time: 0.0005  memory: 19477  loss: 0.4361  loss_cls: 0.2026  loss_bbox: 0.2335
2025/05/13 03:14:46 - mmengine - INFO - Epoch(train)  [7][1150/1528]  base_lr: 8.6373e-04 lr: 8.6373e-04  eta: 3:05:13  time: 0.3031  data_time: 0.0005  memory: 19511  loss: 0.4786  loss_cls: 0.2290  loss_bbox: 0.2495
2025/05/13 03:15:01 - mmengine - INFO - Epoch(train)  [7][1200/1528]  base_lr: 8.6373e-04 lr: 8.6373e-04  eta: 3:04:56  time: 0.3014  data_time: 0.0005  memory: 19493  loss: 0.4295  loss_cls: 0.2023  loss_bbox: 0.2272
2025/05/13 03:15:16 - mmengine - INFO - Epoch(train)  [7][1250/1528]  base_lr: 8.6373e-04 lr: 8.6373e-04  eta: 3:04:41  time: 0.3026  data_time: 0.0005  memory: 19492  loss: 0.4643  loss_cls: 0.2235  loss_bbox: 0.2408
2025/05/13 03:15:31 - mmengine - INFO - Epoch(train)  [7][1300/1528]  base_lr: 8.6373e-04 lr: 8.6373e-04  eta: 3:04:25  time: 0.3025  data_time: 0.0005  memory: 19503  loss: 0.4269  loss_cls: 0.2028  loss_bbox: 0.2241
2025/05/13 03:15:46 - mmengine - INFO - Epoch(train)  [7][1350/1528]  base_lr: 8.6373e-04 lr: 8.6373e-04  eta: 3:04:08  time: 0.3010  data_time: 0.0005  memory: 19491  loss: 0.4560  loss_cls: 0.2093  loss_bbox: 0.2468
2025/05/13 03:16:01 - mmengine - INFO - Epoch(train)  [7][1400/1528]  base_lr: 8.6373e-04 lr: 8.6373e-04  eta: 3:03:53  time: 0.3027  data_time: 0.0005  memory: 19483  loss: 0.4594  loss_cls: 0.2233  loss_bbox: 0.2361
2025/05/13 03:16:16 - mmengine - INFO - Epoch(train)  [7][1450/1528]  base_lr: 8.6373e-04 lr: 8.6373e-04  eta: 3:03:36  time: 0.3017  data_time: 0.0005  memory: 19517  loss: 0.4483  loss_cls: 0.2070  loss_bbox: 0.2413
2025/05/13 03:16:31 - mmengine - INFO - Epoch(train)  [7][1500/1528]  base_lr: 8.6373e-04 lr: 8.6373e-04  eta: 3:03:20  time: 0.3023  data_time: 0.0005  memory: 19521  loss: 0.4130  loss_cls: 0.1811  loss_bbox: 0.2320
2025/05/13 03:16:40 - mmengine - INFO - Exp name: rtmdet_m_1x_custom_resume_20250513_030051
2025/05/13 03:16:40 - mmengine - INFO - Saving checkpoint at 7 epochs
2025/05/13 03:16:44 - mmengine - INFO - Epoch(val)  [7][ 50/149]    eta: 0:00:08  time: 0.0821  data_time: 0.0036  memory: 19487  
2025/05/13 03:16:48 - mmengine - INFO - Epoch(val)  [7][100/149]    eta: 0:00:04  time: 0.0818  data_time: 0.0026  memory: 1598  
2025/05/13 03:16:54 - mmengine - INFO - Evaluating bbox...
2025/05/13 03:16:56 - mmengine - INFO - bbox_mAP_copypaste: 0.758 0.937 0.851 0.419 0.656 0.802
2025/05/13 03:16:56 - mmengine - INFO - Epoch(val) [7][149/149]    coco/bbox_mAP: 0.7580  coco/bbox_mAP_50: 0.9370  coco/bbox_mAP_75: 0.8510  coco/bbox_mAP_s: 0.4190  coco/bbox_mAP_m: 0.6560  coco/bbox_mAP_l: 0.8020  data_time: 0.0029  time: 0.0809
2025/05/13 03:17:12 - mmengine - INFO - Epoch(train)  [8][  50/1528]  base_lr: 5.1527e-05 lr: 5.1527e-05  eta: 3:02:56  time: 0.3076  data_time: 0.0018  memory: 19511  loss: 0.4383  loss_cls: 0.1986  loss_bbox: 0.2397
2025/05/13 03:17:27 - mmengine - INFO - Epoch(train)  [8][ 100/1528]  base_lr: 5.1527e-05 lr: 5.1527e-05  eta: 3:02:40  time: 0.3017  data_time: 0.0005  memory: 19485  loss: 0.4149  loss_cls: 0.1957  loss_bbox: 0.2193
2025/05/13 03:17:42 - mmengine - INFO - Epoch(train)  [8][ 150/1528]  base_lr: 5.1527e-05 lr: 5.1527e-05  eta: 3:02:24  time: 0.3020  data_time: 0.0005  memory: 19504  loss: 0.4386  loss_cls: 0.2026  loss_bbox: 0.2360
2025/05/13 03:17:57 - mmengine - INFO - Epoch(train)  [8][ 200/1528]  base_lr: 5.1527e-05 lr: 5.1527e-05  eta: 3:02:08  time: 0.3020  data_time: 0.0005  memory: 19498  loss: 0.4536  loss_cls: 0.2111  loss_bbox: 0.2424
2025/05/13 03:18:12 - mmengine - INFO - Epoch(train)  [8][ 250/1528]  base_lr: 5.1527e-05 lr: 5.1527e-05  eta: 3:01:53  time: 0.3022  data_time: 0.0005  memory: 19483  loss: 0.4369  loss_cls: 0.2118  loss_bbox: 0.2251
2025/05/13 03:18:27 - mmengine - INFO - Epoch(train)  [8][ 300/1528]  base_lr: 5.1527e-05 lr: 5.1527e-05  eta: 3:01:37  time: 0.3019  data_time: 0.0005  memory: 19511  loss: 0.4328  loss_cls: 0.2088  loss_bbox: 0.2240
2025/05/13 03:18:42 - mmengine - INFO - Epoch(train)  [8][ 350/1528]  base_lr: 5.1527e-05 lr: 5.1527e-05  eta: 3:01:21  time: 0.3023  data_time: 0.0005  memory: 19507  loss: 0.4545  loss_cls: 0.2172  loss_bbox: 0.2372
2025/05/13 03:18:55 - mmengine - INFO - Exp name: rtmdet_m_1x_custom_resume_20250513_030051
2025/05/13 03:18:57 - mmengine - INFO - Epoch(train)  [8][ 400/1528]  base_lr: 5.1527e-05 lr: 5.1527e-05  eta: 3:01:05  time: 0.3013  data_time: 0.0005  memory: 19496  loss: 0.4204  loss_cls: 0.1939  loss_bbox: 0.2265
2025/05/13 03:19:12 - mmengine - INFO - Epoch(train)  [8][ 450/1528]  base_lr: 5.1527e-05 lr: 5.1527e-05  eta: 3:00:49  time: 0.3015  data_time: 0.0005  memory: 19501  loss: 0.4445  loss_cls: 0.2163  loss_bbox: 0.2283
2025/05/13 03:19:27 - mmengine - INFO - Epoch(train)  [8][ 500/1528]  base_lr: 5.1527e-05 lr: 5.1527e-05  eta: 3:00:33  time: 0.3015  data_time: 0.0005  memory: 19494  loss: 0.4437  loss_cls: 0.2094  loss_bbox: 0.2343
2025/05/13 03:19:43 - mmengine - INFO - Epoch(train)  [8][ 550/1528]  base_lr: 5.1527e-05 lr: 5.1527e-05  eta: 3:00:17  time: 0.3023  data_time: 0.0005  memory: 19502  loss: 0.4029  loss_cls: 0.1834  loss_bbox: 0.2195
2025/05/13 03:19:58 - mmengine - INFO - Epoch(train)  [8][ 600/1528]  base_lr: 5.1527e-05 lr: 5.1527e-05  eta: 3:00:01  time: 0.3012  data_time: 0.0005  memory: 19484  loss: 0.4315  loss_cls: 0.1996  loss_bbox: 0.2320
2025/05/13 03:20:13 - mmengine - INFO - Epoch(train)  [8][ 650/1528]  base_lr: 5.1527e-05 lr: 5.1527e-05  eta: 2:59:45  time: 0.3021  data_time: 0.0006  memory: 19485  loss: 0.4013  loss_cls: 0.1892  loss_bbox: 0.2121
2025/05/13 03:20:28 - mmengine - INFO - Epoch(train)  [8][ 700/1528]  base_lr: 5.1527e-05 lr: 5.1527e-05  eta: 2:59:30  time: 0.3029  data_time: 0.0007  memory: 19507  loss: 0.4479  loss_cls: 0.2164  loss_bbox: 0.2315
2025/05/13 03:20:43 - mmengine - INFO - Epoch(train)  [8][ 750/1528]  base_lr: 5.1527e-05 lr: 5.1527e-05  eta: 2:59:15  time: 0.3029  data_time: 0.0007  memory: 19511  loss: 0.4450  loss_cls: 0.2242  loss_bbox: 0.2209
2025/05/13 03:20:58 - mmengine - INFO - Epoch(train)  [8][ 800/1528]  base_lr: 5.1527e-05 lr: 5.1527e-05  eta: 2:58:59  time: 0.3015  data_time: 0.0005  memory: 19474  loss: 0.4272  loss_cls: 0.2028  loss_bbox: 0.2244
2025/05/13 03:21:13 - mmengine - INFO - Epoch(train)  [8][ 850/1528]  base_lr: 5.1527e-05 lr: 5.1527e-05  eta: 2:58:46  time: 0.3074  data_time: 0.0005  memory: 19487  loss: 0.4288  loss_cls: 0.1976  loss_bbox: 0.2312
2025/05/13 03:21:28 - mmengine - INFO - Epoch(train)  [8][ 900/1528]  base_lr: 5.1527e-05 lr: 5.1527e-05  eta: 2:58:30  time: 0.3007  data_time: 0.0005  memory: 19515  loss: 0.4073  loss_cls: 0.1883  loss_bbox: 0.2190
2025/05/13 03:21:44 - mmengine - INFO - Epoch(train)  [8][ 950/1528]  base_lr: 5.1527e-05 lr: 5.1527e-05  eta: 2:58:14  time: 0.3030  data_time: 0.0005  memory: 19504  loss: 0.3951  loss_cls: 0.1821  loss_bbox: 0.2130
2025/05/13 03:21:59 - mmengine - INFO - Epoch(train)  [8][1000/1528]  base_lr: 5.1527e-05 lr: 5.1527e-05  eta: 2:57:58  time: 0.3006  data_time: 0.0005  memory: 19483  loss: 0.4378  loss_cls: 0.2095  loss_bbox: 0.2283
2025/05/13 03:22:14 - mmengine - INFO - Epoch(train)  [8][1050/1528]  base_lr: 5.1527e-05 lr: 5.1527e-05  eta: 2:57:43  time: 0.3032  data_time: 0.0006  memory: 19510  loss: 0.4265  loss_cls: 0.1960  loss_bbox: 0.2305
2025/05/13 03:22:29 - mmengine - INFO - Epoch(train)  [8][1100/1528]  base_lr: 5.1527e-05 lr: 5.1527e-05  eta: 2:57:27  time: 0.3004  data_time: 0.0005  memory: 19482  loss: 0.4314  loss_cls: 0.1987  loss_bbox: 0.2327
2025/05/13 03:22:44 - mmengine - INFO - Epoch(train)  [8][1150/1528]  base_lr: 5.1527e-05 lr: 5.1527e-05  eta: 2:57:11  time: 0.3028  data_time: 0.0005  memory: 19510  loss: 0.4057  loss_cls: 0.1870  loss_bbox: 0.2188
2025/05/13 03:22:59 - mmengine - INFO - Epoch(train)  [8][1200/1528]  base_lr: 5.1527e-05 lr: 5.1527e-05  eta: 2:56:55  time: 0.3009  data_time: 0.0005  memory: 19495  loss: 0.4276  loss_cls: 0.1993  loss_bbox: 0.2283
2025/05/13 03:23:14 - mmengine - INFO - Epoch(train)  [8][1250/1528]  base_lr: 5.1527e-05 lr: 5.1527e-05  eta: 2:56:40  time: 0.3031  data_time: 0.0005  memory: 19491  loss: 0.4226  loss_cls: 0.1995  loss_bbox: 0.2231
2025/05/13 03:23:29 - mmengine - INFO - Epoch(train)  [8][1300/1528]  base_lr: 5.1527e-05 lr: 5.1527e-05  eta: 2:56:24  time: 0.3014  data_time: 0.0005  memory: 19518  loss: 0.4228  loss_cls: 0.1969  loss_bbox: 0.2259
2025/05/13 03:23:44 - mmengine - INFO - Epoch(train)  [8][1350/1528]  base_lr: 5.1527e-05 lr: 5.1527e-05  eta: 2:56:09  time: 0.3032  data_time: 0.0005  memory: 19503  loss: 0.4268  loss_cls: 0.2050  loss_bbox: 0.2218
2025/05/13 03:23:58 - mmengine - INFO - Exp name: rtmdet_m_1x_custom_resume_20250513_030051
2025/05/13 03:23:59 - mmengine - INFO - Epoch(train)  [8][1400/1528]  base_lr: 5.1527e-05 lr: 5.1527e-05  eta: 2:55:54  time: 0.3013  data_time: 0.0005  memory: 19484  loss: 0.4170  loss_cls: 0.1974  loss_bbox: 0.2196
2025/05/13 03:24:15 - mmengine - INFO - Epoch(train)  [8][1450/1528]  base_lr: 5.1527e-05 lr: 5.1527e-05  eta: 2:55:39  time: 0.3045  data_time: 0.0006  memory: 19509  loss: 0.4291  loss_cls: 0.1990  loss_bbox: 0.2301
2025/05/13 03:24:30 - mmengine - INFO - Epoch(train)  [8][1500/1528]  base_lr: 5.1527e-05 lr: 5.1527e-05  eta: 2:55:23  time: 0.3010  data_time: 0.0005  memory: 19508  loss: 0.4180  loss_cls: 0.1981  loss_bbox: 0.2199
2025/05/13 03:24:38 - mmengine - INFO - Exp name: rtmdet_m_1x_custom_resume_20250513_030051
2025/05/13 03:24:38 - mmengine - INFO - Saving checkpoint at 8 epochs
2025/05/13 03:24:43 - mmengine - INFO - Epoch(val)  [8][ 50/149]    eta: 0:00:08  time: 0.0837  data_time: 0.0038  memory: 19485  
2025/05/13 03:24:47 - mmengine - INFO - Epoch(val)  [8][100/149]    eta: 0:00:04  time: 0.0820  data_time: 0.0027  memory: 1598  
2025/05/13 03:24:52 - mmengine - INFO - Evaluating bbox...
2025/05/13 03:24:55 - mmengine - INFO - bbox_mAP_copypaste: 0.763 0.940 0.861 0.425 0.657 0.806
2025/05/13 03:24:55 - mmengine - INFO - Epoch(val) [8][149/149]    coco/bbox_mAP: 0.7630  coco/bbox_mAP_50: 0.9400  coco/bbox_mAP_75: 0.8610  coco/bbox_mAP_s: 0.4250  coco/bbox_mAP_m: 0.6570  coco/bbox_mAP_l: 0.8060  data_time: 0.0031  time: 0.0817
2025/05/13 03:25:10 - mmengine - INFO - Epoch(train)  [9][  50/1528]  base_lr: 2.3873e-05 lr: 2.3873e-05  eta: 2:54:58  time: 0.3038  data_time: 0.0025  memory: 19482  loss: 0.4146  loss_cls: 0.1926  loss_bbox: 0.2220
2025/05/13 03:25:25 - mmengine - INFO - Epoch(train)  [9][ 100/1528]  base_lr: 2.3873e-05 lr: 2.3873e-05  eta: 2:54:42  time: 0.2994  data_time: 0.0005  memory: 19499  loss: 0.4352  loss_cls: 0.2042  loss_bbox: 0.2309
2025/05/13 03:25:40 - mmengine - INFO - Epoch(train)  [9][ 150/1528]  base_lr: 2.3873e-05 lr: 2.3873e-05  eta: 2:54:26  time: 0.3012  data_time: 0.0005  memory: 19483  loss: 0.4034  loss_cls: 0.1933  loss_bbox: 0.2102
2025/05/13 03:25:55 - mmengine - INFO - Epoch(train)  [9][ 200/1528]  base_lr: 2.3873e-05 lr: 2.3873e-05  eta: 2:54:10  time: 0.2996  data_time: 0.0005  memory: 19491  loss: 0.4069  loss_cls: 0.1879  loss_bbox: 0.2190
2025/05/13 03:26:10 - mmengine - INFO - Epoch(train)  [9][ 250/1528]  base_lr: 2.3873e-05 lr: 2.3873e-05  eta: 2:53:54  time: 0.3018  data_time: 0.0005  memory: 19493  loss: 0.4205  loss_cls: 0.1958  loss_bbox: 0.2247
2025/05/13 03:26:25 - mmengine - INFO - Epoch(train)  [9][ 300/1528]  base_lr: 2.3873e-05 lr: 2.3873e-05  eta: 2:53:38  time: 0.2993  data_time: 0.0005  memory: 19507  loss: 0.4326  loss_cls: 0.2048  loss_bbox: 0.2278
2025/05/13 03:26:40 - mmengine - INFO - Epoch(train)  [9][ 350/1528]  base_lr: 2.3873e-05 lr: 2.3873e-05  eta: 2:53:22  time: 0.3010  data_time: 0.0005  memory: 19507  loss: 0.3905  loss_cls: 0.1814  loss_bbox: 0.2091
2025/05/13 03:26:55 - mmengine - INFO - Epoch(train)  [9][ 400/1528]  base_lr: 2.3873e-05 lr: 2.3873e-05  eta: 2:53:06  time: 0.2994  data_time: 0.0005  memory: 19483  loss: 0.4256  loss_cls: 0.2048  loss_bbox: 0.2207
2025/05/13 03:27:10 - mmengine - INFO - Epoch(train)  [9][ 450/1528]  base_lr: 2.3873e-05 lr: 2.3873e-05  eta: 2:52:50  time: 0.3012  data_time: 0.0005  memory: 19486  loss: 0.4273  loss_cls: 0.2032  loss_bbox: 0.2241
2025/05/13 03:27:25 - mmengine - INFO - Epoch(train)  [9][ 500/1528]  base_lr: 2.3873e-05 lr: 2.3873e-05  eta: 2:52:34  time: 0.2999  data_time: 0.0005  memory: 19508  loss: 0.4030  loss_cls: 0.1855  loss_bbox: 0.2175
2025/05/13 03:27:40 - mmengine - INFO - Epoch(train)  [9][ 550/1528]  base_lr: 2.3873e-05 lr: 2.3873e-05  eta: 2:52:18  time: 0.3017  data_time: 0.0005  memory: 19507  loss: 0.4507  loss_cls: 0.2162  loss_bbox: 0.2346
2025/05/13 03:27:55 - mmengine - INFO - Epoch(train)  [9][ 600/1528]  base_lr: 2.3873e-05 lr: 2.3873e-05  eta: 2:52:03  time: 0.3024  data_time: 0.0005  memory: 19482  loss: 0.4360  loss_cls: 0.2045  loss_bbox: 0.2315
2025/05/13 03:28:10 - mmengine - INFO - Epoch(train)  [9][ 650/1528]  base_lr: 2.3873e-05 lr: 2.3873e-05  eta: 2:51:48  time: 0.3023  data_time: 0.0006  memory: 19502  loss: 0.4437  loss_cls: 0.2142  loss_bbox: 0.2295
2025/05/13 03:28:26 - mmengine - INFO - Epoch(train)  [9][ 700/1528]  base_lr: 2.3873e-05 lr: 2.3873e-05  eta: 2:51:33  time: 0.3027  data_time: 0.0005  memory: 19495  loss: 0.4244  loss_cls: 0.1978  loss_bbox: 0.2265
2025/05/13 03:28:41 - mmengine - INFO - Epoch(train)  [9][ 750/1528]  base_lr: 2.3873e-05 lr: 2.3873e-05  eta: 2:51:18  time: 0.3024  data_time: 0.0005  memory: 19508  loss: 0.4277  loss_cls: 0.2044  loss_bbox: 0.2233
2025/05/13 03:28:56 - mmengine - INFO - Epoch(train)  [9][ 800/1528]  base_lr: 2.3873e-05 lr: 2.3873e-05  eta: 2:51:02  time: 0.3023  data_time: 0.0006  memory: 19475  loss: 0.4119  loss_cls: 0.1922  loss_bbox: 0.2197
2025/05/13 03:29:11 - mmengine - INFO - Epoch(train)  [9][ 850/1528]  base_lr: 2.3873e-05 lr: 2.3873e-05  eta: 2:50:47  time: 0.3028  data_time: 0.0006  memory: 19502  loss: 0.4282  loss_cls: 0.2028  loss_bbox: 0.2254
2025/05/13 03:29:16 - mmengine - INFO - Exp name: rtmdet_m_1x_custom_resume_20250513_030051
2025/05/13 03:29:26 - mmengine - INFO - Epoch(train)  [9][ 900/1528]  base_lr: 2.3873e-05 lr: 2.3873e-05  eta: 2:50:32  time: 0.3021  data_time: 0.0006  memory: 19479  loss: 0.4124  loss_cls: 0.1957  loss_bbox: 0.2167
2025/05/13 03:29:41 - mmengine - INFO - Epoch(train)  [9][ 950/1528]  base_lr: 2.3873e-05 lr: 2.3873e-05  eta: 2:50:17  time: 0.3019  data_time: 0.0006  memory: 19517  loss: 0.4548  loss_cls: 0.2126  loss_bbox: 0.2422
2025/05/13 03:29:56 - mmengine - INFO - Epoch(train)  [9][1000/1528]  base_lr: 2.3873e-05 lr: 2.3873e-05  eta: 2:50:01  time: 0.3021  data_time: 0.0005  memory: 19511  loss: 0.4176  loss_cls: 0.1959  loss_bbox: 0.2217
2025/05/13 03:30:11 - mmengine - INFO - Epoch(train)  [9][1050/1528]  base_lr: 2.3873e-05 lr: 2.3873e-05  eta: 2:49:46  time: 0.3016  data_time: 0.0005  memory: 19508  loss: 0.4059  loss_cls: 0.1862  loss_bbox: 0.2197
2025/05/13 03:30:26 - mmengine - INFO - Epoch(train)  [9][1100/1528]  base_lr: 2.3873e-05 lr: 2.3873e-05  eta: 2:49:31  time: 0.3021  data_time: 0.0005  memory: 19492  loss: 0.4501  loss_cls: 0.2081  loss_bbox: 0.2420
2025/05/13 03:30:42 - mmengine - INFO - Epoch(train)  [9][1150/1528]  base_lr: 2.3873e-05 lr: 2.3873e-05  eta: 2:49:15  time: 0.3023  data_time: 0.0005  memory: 19479  loss: 0.4238  loss_cls: 0.2017  loss_bbox: 0.2221
2025/05/13 03:30:57 - mmengine - INFO - Epoch(train)  [9][1200/1528]  base_lr: 2.3873e-05 lr: 2.3873e-05  eta: 2:49:00  time: 0.3012  data_time: 0.0005  memory: 19491  loss: 0.3924  loss_cls: 0.1790  loss_bbox: 0.2134
2025/05/13 03:31:12 - mmengine - INFO - Epoch(train)  [9][1250/1528]  base_lr: 2.3873e-05 lr: 2.3873e-05  eta: 2:48:45  time: 0.3055  data_time: 0.0005  memory: 19498  loss: 0.4078  loss_cls: 0.1856  loss_bbox: 0.2222
2025/05/13 03:31:27 - mmengine - INFO - Epoch(train)  [9][1300/1528]  base_lr: 2.3873e-05 lr: 2.3873e-05  eta: 2:48:30  time: 0.3012  data_time: 0.0005  memory: 19488  loss: 0.4257  loss_cls: 0.2040  loss_bbox: 0.2217
2025/05/13 03:31:42 - mmengine - INFO - Epoch(train)  [9][1350/1528]  base_lr: 2.3873e-05 lr: 2.3873e-05  eta: 2:48:14  time: 0.3008  data_time: 0.0005  memory: 19487  loss: 0.4026  loss_cls: 0.1844  loss_bbox: 0.2182
2025/05/13 03:31:57 - mmengine - INFO - Epoch(train)  [9][1400/1528]  base_lr: 2.3873e-05 lr: 2.3873e-05  eta: 2:47:59  time: 0.3008  data_time: 0.0005  memory: 19489  loss: 0.4155  loss_cls: 0.1945  loss_bbox: 0.2211
2025/05/13 03:32:12 - mmengine - INFO - Epoch(train)  [9][1450/1528]  base_lr: 2.3873e-05 lr: 2.3873e-05  eta: 2:47:43  time: 0.3008  data_time: 0.0005  memory: 19472  loss: 0.4136  loss_cls: 0.1943  loss_bbox: 0.2194
2025/05/13 03:32:27 - mmengine - INFO - Epoch(train)  [9][1500/1528]  base_lr: 2.3873e-05 lr: 2.3873e-05  eta: 2:47:27  time: 0.3006  data_time: 0.0005  memory: 19510  loss: 0.4138  loss_cls: 0.1889  loss_bbox: 0.2249
2025/05/13 03:32:35 - mmengine - INFO - Exp name: rtmdet_m_1x_custom_resume_20250513_030051
2025/05/13 03:32:35 - mmengine - INFO - Saving checkpoint at 9 epochs
2025/05/13 03:32:40 - mmengine - INFO - Epoch(val)  [9][ 50/149]    eta: 0:00:08  time: 0.0821  data_time: 0.0038  memory: 19495  
2025/05/13 03:32:44 - mmengine - INFO - Epoch(val)  [9][100/149]    eta: 0:00:04  time: 0.0825  data_time: 0.0029  memory: 1598  
2025/05/13 03:32:49 - mmengine - INFO - Evaluating bbox...
2025/05/13 03:32:52 - mmengine - INFO - bbox_mAP_copypaste: 0.770 0.941 0.860 0.431 0.660 0.814
2025/05/13 03:32:52 - mmengine - INFO - Epoch(val) [9][149/149]    coco/bbox_mAP: 0.7700  coco/bbox_mAP_50: 0.9410  coco/bbox_mAP_75: 0.8600  coco/bbox_mAP_s: 0.4310  coco/bbox_mAP_m: 0.6600  coco/bbox_mAP_l: 0.8140  data_time: 0.0032  time: 0.0813
2025/05/13 03:33:07 - mmengine - INFO - Epoch(train) [10][  50/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:47:02  time: 0.3024  data_time: 0.0021  memory: 19509  loss: 0.4301  loss_cls: 0.2011  loss_bbox: 0.2290
2025/05/13 03:33:22 - mmengine - INFO - Epoch(train) [10][ 100/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:46:47  time: 0.3004  data_time: 0.0005  memory: 19509  loss: 0.4199  loss_cls: 0.1905  loss_bbox: 0.2294
2025/05/13 03:33:37 - mmengine - INFO - Epoch(train) [10][ 150/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:46:31  time: 0.2997  data_time: 0.0005  memory: 19498  loss: 0.4069  loss_cls: 0.1892  loss_bbox: 0.2177
2025/05/13 03:33:52 - mmengine - INFO - Epoch(train) [10][ 200/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:46:15  time: 0.3006  data_time: 0.0005  memory: 19507  loss: 0.4296  loss_cls: 0.2029  loss_bbox: 0.2267
2025/05/13 03:34:07 - mmengine - INFO - Epoch(train) [10][ 250/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:45:59  time: 0.3005  data_time: 0.0005  memory: 19515  loss: 0.4008  loss_cls: 0.1852  loss_bbox: 0.2156
2025/05/13 03:34:22 - mmengine - INFO - Epoch(train) [10][ 300/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:45:44  time: 0.3001  data_time: 0.0005  memory: 19493  loss: 0.4191  loss_cls: 0.1980  loss_bbox: 0.2211
2025/05/13 03:34:33 - mmengine - INFO - Exp name: rtmdet_m_1x_custom_resume_20250513_030051
2025/05/13 03:34:37 - mmengine - INFO - Epoch(train) [10][ 350/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:45:28  time: 0.3007  data_time: 0.0005  memory: 19488  loss: 0.4175  loss_cls: 0.1982  loss_bbox: 0.2193
2025/05/13 03:34:52 - mmengine - INFO - Epoch(train) [10][ 400/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:45:13  time: 0.3012  data_time: 0.0006  memory: 19483  loss: 0.4073  loss_cls: 0.1924  loss_bbox: 0.2149
2025/05/13 03:35:07 - mmengine - INFO - Epoch(train) [10][ 450/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:44:57  time: 0.3014  data_time: 0.0006  memory: 19481  loss: 0.4020  loss_cls: 0.1892  loss_bbox: 0.2127
2025/05/13 03:35:22 - mmengine - INFO - Epoch(train) [10][ 500/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:44:42  time: 0.3002  data_time: 0.0005  memory: 19475  loss: 0.4274  loss_cls: 0.2044  loss_bbox: 0.2230
2025/05/13 03:35:37 - mmengine - INFO - Epoch(train) [10][ 550/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:44:26  time: 0.3005  data_time: 0.0005  memory: 19509  loss: 0.4251  loss_cls: 0.1998  loss_bbox: 0.2252
2025/05/13 03:35:52 - mmengine - INFO - Epoch(train) [10][ 600/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:44:11  time: 0.3048  data_time: 0.0005  memory: 19495  loss: 0.4203  loss_cls: 0.1876  loss_bbox: 0.2327
2025/05/13 03:36:07 - mmengine - INFO - Epoch(train) [10][ 650/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:43:56  time: 0.3010  data_time: 0.0005  memory: 19487  loss: 0.4587  loss_cls: 0.2206  loss_bbox: 0.2381
2025/05/13 03:36:22 - mmengine - INFO - Epoch(train) [10][ 700/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:43:40  time: 0.3001  data_time: 0.0005  memory: 19510  loss: 0.4197  loss_cls: 0.1997  loss_bbox: 0.2199
2025/05/13 03:36:37 - mmengine - INFO - Epoch(train) [10][ 750/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:43:25  time: 0.3003  data_time: 0.0005  memory: 19498  loss: 0.4284  loss_cls: 0.2012  loss_bbox: 0.2272
2025/05/13 03:36:52 - mmengine - INFO - Epoch(train) [10][ 800/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:43:09  time: 0.3008  data_time: 0.0005  memory: 19490  loss: 0.4221  loss_cls: 0.1992  loss_bbox: 0.2230
2025/05/13 03:37:08 - mmengine - INFO - Epoch(train) [10][ 850/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:42:54  time: 0.3010  data_time: 0.0005  memory: 19482  loss: 0.4061  loss_cls: 0.1846  loss_bbox: 0.2215
2025/05/13 03:37:23 - mmengine - INFO - Epoch(train) [10][ 900/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:42:38  time: 0.3007  data_time: 0.0005  memory: 19513  loss: 0.4321  loss_cls: 0.2037  loss_bbox: 0.2285
2025/05/13 03:37:38 - mmengine - INFO - Epoch(train) [10][ 950/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:42:23  time: 0.3008  data_time: 0.0005  memory: 19509  loss: 0.4209  loss_cls: 0.1938  loss_bbox: 0.2271
2025/05/13 03:37:53 - mmengine - INFO - Epoch(train) [10][1000/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:42:07  time: 0.3012  data_time: 0.0005  memory: 19503  loss: 0.4245  loss_cls: 0.2045  loss_bbox: 0.2200
2025/05/13 03:38:08 - mmengine - INFO - Epoch(train) [10][1050/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:41:52  time: 0.3010  data_time: 0.0005  memory: 19479  loss: 0.4243  loss_cls: 0.1997  loss_bbox: 0.2246
2025/05/13 03:38:23 - mmengine - INFO - Epoch(train) [10][1100/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:41:37  time: 0.3014  data_time: 0.0005  memory: 19481  loss: 0.4224  loss_cls: 0.2022  loss_bbox: 0.2201
2025/05/13 03:38:38 - mmengine - INFO - Epoch(train) [10][1150/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:41:21  time: 0.3009  data_time: 0.0005  memory: 19510  loss: 0.4224  loss_cls: 0.2042  loss_bbox: 0.2181
2025/05/13 03:38:53 - mmengine - INFO - Epoch(train) [10][1200/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:41:06  time: 0.3007  data_time: 0.0005  memory: 19484  loss: 0.4219  loss_cls: 0.2020  loss_bbox: 0.2199
2025/05/13 03:39:08 - mmengine - INFO - Epoch(train) [10][1250/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:40:50  time: 0.3009  data_time: 0.0005  memory: 19490  loss: 0.3881  loss_cls: 0.1807  loss_bbox: 0.2073
2025/05/13 03:39:23 - mmengine - INFO - Epoch(train) [10][1300/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:40:35  time: 0.3012  data_time: 0.0005  memory: 19500  loss: 0.4311  loss_cls: 0.2051  loss_bbox: 0.2260
2025/05/13 03:39:34 - mmengine - INFO - Exp name: rtmdet_m_1x_custom_resume_20250513_030051
2025/05/13 03:39:38 - mmengine - INFO - Epoch(train) [10][1350/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:40:20  time: 0.3019  data_time: 0.0005  memory: 19491  loss: 0.4251  loss_cls: 0.2028  loss_bbox: 0.2223
2025/05/13 03:39:53 - mmengine - INFO - Epoch(train) [10][1400/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:40:05  time: 0.3051  data_time: 0.0005  memory: 19474  loss: 0.4065  loss_cls: 0.1948  loss_bbox: 0.2117
2025/05/13 03:40:08 - mmengine - INFO - Epoch(train) [10][1450/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:39:50  time: 0.3013  data_time: 0.0005  memory: 19499  loss: 0.4050  loss_cls: 0.1893  loss_bbox: 0.2157
2025/05/13 03:40:23 - mmengine - INFO - Epoch(train) [10][1500/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:39:35  time: 0.3006  data_time: 0.0005  memory: 19509  loss: 0.4297  loss_cls: 0.2004  loss_bbox: 0.2293
2025/05/13 03:40:32 - mmengine - INFO - Exp name: rtmdet_m_1x_custom_resume_20250513_030051
2025/05/13 03:40:32 - mmengine - INFO - Saving checkpoint at 10 epochs
2025/05/13 03:40:36 - mmengine - INFO - Epoch(val) [10][ 50/149]    eta: 0:00:08  time: 0.0814  data_time: 0.0038  memory: 19476  
2025/05/13 03:40:40 - mmengine - INFO - Epoch(val) [10][100/149]    eta: 0:00:03  time: 0.0805  data_time: 0.0028  memory: 1598  
2025/05/13 03:40:46 - mmengine - INFO - Evaluating bbox...
2025/05/13 03:40:48 - mmengine - INFO - bbox_mAP_copypaste: 0.769 0.939 0.858 0.409 0.658 0.815
2025/05/13 03:40:48 - mmengine - INFO - Epoch(val) [10][149/149]    coco/bbox_mAP: 0.7690  coco/bbox_mAP_50: 0.9390  coco/bbox_mAP_75: 0.8580  coco/bbox_mAP_s: 0.4090  coco/bbox_mAP_m: 0.6580  coco/bbox_mAP_l: 0.8150  data_time: 0.0032  time: 0.0807
2025/05/13 03:41:03 - mmengine - INFO - Epoch(train) [11][  50/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:39:11  time: 0.3035  data_time: 0.0031  memory: 19515  loss: 0.4362  loss_cls: 0.2159  loss_bbox: 0.2203
2025/05/13 03:41:18 - mmengine - INFO - Epoch(train) [11][ 100/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:38:55  time: 0.2995  data_time: 0.0005  memory: 19507  loss: 0.4163  loss_cls: 0.1957  loss_bbox: 0.2206
2025/05/13 03:41:33 - mmengine - INFO - Epoch(train) [11][ 150/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:38:40  time: 0.3004  data_time: 0.0005  memory: 19481  loss: 0.4066  loss_cls: 0.1919  loss_bbox: 0.2146
2025/05/13 03:41:48 - mmengine - INFO - Epoch(train) [11][ 200/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:38:24  time: 0.2999  data_time: 0.0005  memory: 19506  loss: 0.4275  loss_cls: 0.2041  loss_bbox: 0.2235
2025/05/13 03:42:04 - mmengine - INFO - Epoch(train) [11][ 250/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:38:09  time: 0.3007  data_time: 0.0005  memory: 19478  loss: 0.4259  loss_cls: 0.1997  loss_bbox: 0.2262
2025/05/13 03:42:19 - mmengine - INFO - Epoch(train) [11][ 300/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:37:53  time: 0.3008  data_time: 0.0006  memory: 19473  loss: 0.3995  loss_cls: 0.1828  loss_bbox: 0.2166
2025/05/13 03:42:34 - mmengine - INFO - Epoch(train) [11][ 350/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:37:38  time: 0.3001  data_time: 0.0005  memory: 19485  loss: 0.4341  loss_cls: 0.2049  loss_bbox: 0.2293
2025/05/13 03:42:49 - mmengine - INFO - Epoch(train) [11][ 400/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:37:22  time: 0.2998  data_time: 0.0005  memory: 19491  loss: 0.3903  loss_cls: 0.1783  loss_bbox: 0.2120
2025/05/13 03:43:04 - mmengine - INFO - Epoch(train) [11][ 450/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:37:07  time: 0.3004  data_time: 0.0005  memory: 19493  loss: 0.4032  loss_cls: 0.1818  loss_bbox: 0.2214
2025/05/13 03:43:19 - mmengine - INFO - Epoch(train) [11][ 500/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:36:51  time: 0.3006  data_time: 0.0006  memory: 19485  loss: 0.4314  loss_cls: 0.2002  loss_bbox: 0.2312
2025/05/13 03:43:34 - mmengine - INFO - Epoch(train) [11][ 550/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:36:36  time: 0.3010  data_time: 0.0006  memory: 19509  loss: 0.4139  loss_cls: 0.1957  loss_bbox: 0.2182
2025/05/13 03:43:49 - mmengine - INFO - Epoch(train) [11][ 600/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:36:21  time: 0.3020  data_time: 0.0006  memory: 19502  loss: 0.4134  loss_cls: 0.1897  loss_bbox: 0.2237
2025/05/13 03:44:04 - mmengine - INFO - Epoch(train) [11][ 650/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:36:05  time: 0.3001  data_time: 0.0005  memory: 19476  loss: 0.4231  loss_cls: 0.2029  loss_bbox: 0.2202
2025/05/13 03:44:19 - mmengine - INFO - Epoch(train) [11][ 700/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:35:50  time: 0.2995  data_time: 0.0005  memory: 19502  loss: 0.3989  loss_cls: 0.1864  loss_bbox: 0.2125
2025/05/13 03:44:34 - mmengine - INFO - Epoch(train) [11][ 750/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:35:34  time: 0.2998  data_time: 0.0005  memory: 19477  loss: 0.4089  loss_cls: 0.1902  loss_bbox: 0.2187
2025/05/13 03:44:49 - mmengine - INFO - Epoch(train) [11][ 800/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:35:19  time: 0.3004  data_time: 0.0005  memory: 19495  loss: 0.4179  loss_cls: 0.1996  loss_bbox: 0.2183
2025/05/13 03:44:52 - mmengine - INFO - Exp name: rtmdet_m_1x_custom_resume_20250513_030051
2025/05/13 03:45:04 - mmengine - INFO - Epoch(train) [11][ 850/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:35:03  time: 0.3005  data_time: 0.0005  memory: 19488  loss: 0.4368  loss_cls: 0.2039  loss_bbox: 0.2329
2025/05/13 03:45:19 - mmengine - INFO - Epoch(train) [11][ 900/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:34:48  time: 0.2999  data_time: 0.0005  memory: 19508  loss: 0.4044  loss_cls: 0.1912  loss_bbox: 0.2131
2025/05/13 03:45:34 - mmengine - INFO - Epoch(train) [11][ 950/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:34:32  time: 0.3002  data_time: 0.0005  memory: 19500  loss: 0.4467  loss_cls: 0.2178  loss_bbox: 0.2289
2025/05/13 03:45:49 - mmengine - INFO - Epoch(train) [11][1000/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:34:17  time: 0.3024  data_time: 0.0005  memory: 19488  loss: 0.4140  loss_cls: 0.1923  loss_bbox: 0.2218
2025/05/13 03:46:04 - mmengine - INFO - Epoch(train) [11][1050/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:34:02  time: 0.3012  data_time: 0.0005  memory: 19491  loss: 0.4007  loss_cls: 0.1907  loss_bbox: 0.2100
2025/05/13 03:46:19 - mmengine - INFO - Epoch(train) [11][1100/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:33:47  time: 0.3009  data_time: 0.0005  memory: 19514  loss: 0.4204  loss_cls: 0.1934  loss_bbox: 0.2270
2025/05/13 03:46:34 - mmengine - INFO - Epoch(train) [11][1150/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:33:31  time: 0.3006  data_time: 0.0005  memory: 19478  loss: 0.4219  loss_cls: 0.1994  loss_bbox: 0.2225
2025/05/13 03:46:49 - mmengine - INFO - Epoch(train) [11][1200/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:33:16  time: 0.3013  data_time: 0.0005  memory: 19475  loss: 0.4023  loss_cls: 0.1814  loss_bbox: 0.2209
2025/05/13 03:47:04 - mmengine - INFO - Epoch(train) [11][1250/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:33:01  time: 0.3012  data_time: 0.0006  memory: 19515  loss: 0.4035  loss_cls: 0.1855  loss_bbox: 0.2180
2025/05/13 03:47:19 - mmengine - INFO - Epoch(train) [11][1300/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:32:46  time: 0.3052  data_time: 0.0005  memory: 19497  loss: 0.4296  loss_cls: 0.1998  loss_bbox: 0.2298
2025/05/13 03:47:34 - mmengine - INFO - Epoch(train) [11][1350/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:32:31  time: 0.3001  data_time: 0.0005  memory: 19500  loss: 0.4348  loss_cls: 0.2102  loss_bbox: 0.2246
2025/05/13 03:47:49 - mmengine - INFO - Epoch(train) [11][1400/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:32:16  time: 0.3002  data_time: 0.0005  memory: 19486  loss: 0.3970  loss_cls: 0.1885  loss_bbox: 0.2086
2025/05/13 03:48:04 - mmengine - INFO - Epoch(train) [11][1450/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:32:00  time: 0.3009  data_time: 0.0005  memory: 19487  loss: 0.4181  loss_cls: 0.1957  loss_bbox: 0.2225
2025/05/13 03:48:20 - mmengine - INFO - Epoch(train) [11][1500/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:31:45  time: 0.3008  data_time: 0.0005  memory: 19506  loss: 0.4236  loss_cls: 0.1981  loss_bbox: 0.2255
2025/05/13 03:48:28 - mmengine - INFO - Exp name: rtmdet_m_1x_custom_resume_20250513_030051
2025/05/13 03:48:28 - mmengine - INFO - Saving checkpoint at 11 epochs
2025/05/13 03:48:32 - mmengine - INFO - Epoch(val) [11][ 50/149]    eta: 0:00:08  time: 0.0825  data_time: 0.0039  memory: 19498  
2025/05/13 03:48:36 - mmengine - INFO - Epoch(val) [11][100/149]    eta: 0:00:04  time: 0.0813  data_time: 0.0030  memory: 1598  
2025/05/13 03:48:42 - mmengine - INFO - Evaluating bbox...
2025/05/13 03:48:44 - mmengine - INFO - bbox_mAP_copypaste: 0.774 0.941 0.863 0.429 0.667 0.818
2025/05/13 03:48:44 - mmengine - INFO - Epoch(val) [11][149/149]    coco/bbox_mAP: 0.7740  coco/bbox_mAP_50: 0.9410  coco/bbox_mAP_75: 0.8630  coco/bbox_mAP_s: 0.4290  coco/bbox_mAP_m: 0.6670  coco/bbox_mAP_l: 0.8180  data_time: 0.0033  time: 0.0811
2025/05/13 03:49:00 - mmengine - INFO - Epoch(train) [12][  50/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:31:21  time: 0.3040  data_time: 0.0031  memory: 19495  loss: 0.4569  loss_cls: 0.2145  loss_bbox: 0.2425
2025/05/13 03:49:15 - mmengine - INFO - Epoch(train) [12][ 100/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:31:06  time: 0.3006  data_time: 0.0005  memory: 19490  loss: 0.3987  loss_cls: 0.1871  loss_bbox: 0.2116
2025/05/13 03:49:30 - mmengine - INFO - Epoch(train) [12][ 150/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:30:51  time: 0.3009  data_time: 0.0005  memory: 19480  loss: 0.3934  loss_cls: 0.1824  loss_bbox: 0.2110
2025/05/13 03:49:45 - mmengine - INFO - Epoch(train) [12][ 200/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:30:35  time: 0.3011  data_time: 0.0005  memory: 19485  loss: 0.3920  loss_cls: 0.1812  loss_bbox: 0.2109
2025/05/13 03:50:00 - mmengine - INFO - Epoch(train) [12][ 250/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:30:20  time: 0.3013  data_time: 0.0005  memory: 19505  loss: 0.4233  loss_cls: 0.2010  loss_bbox: 0.2223
2025/05/13 03:50:09 - mmengine - INFO - Exp name: rtmdet_m_1x_custom_resume_20250513_030051
2025/05/13 03:50:15 - mmengine - INFO - Epoch(train) [12][ 300/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:30:05  time: 0.3012  data_time: 0.0005  memory: 19500  loss: 0.4233  loss_cls: 0.1962  loss_bbox: 0.2271
2025/05/13 03:50:30 - mmengine - INFO - Epoch(train) [12][ 350/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:29:50  time: 0.3012  data_time: 0.0005  memory: 19500  loss: 0.4292  loss_cls: 0.2011  loss_bbox: 0.2281
2025/05/13 03:50:45 - mmengine - INFO - Epoch(train) [12][ 400/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:29:34  time: 0.3004  data_time: 0.0005  memory: 19476  loss: 0.4042  loss_cls: 0.1913  loss_bbox: 0.2130
2025/05/13 03:51:00 - mmengine - INFO - Epoch(train) [12][ 450/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:29:19  time: 0.3007  data_time: 0.0005  memory: 19492  loss: 0.4274  loss_cls: 0.2006  loss_bbox: 0.2268
2025/05/13 03:51:15 - mmengine - INFO - Epoch(train) [12][ 500/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:29:04  time: 0.3014  data_time: 0.0005  memory: 19507  loss: 0.4301  loss_cls: 0.2041  loss_bbox: 0.2260
2025/05/13 03:51:30 - mmengine - INFO - Epoch(train) [12][ 550/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:28:49  time: 0.3013  data_time: 0.0005  memory: 19517  loss: 0.4181  loss_cls: 0.1937  loss_bbox: 0.2245
2025/05/13 03:51:45 - mmengine - INFO - Epoch(train) [12][ 600/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:28:34  time: 0.3014  data_time: 0.0005  memory: 19507  loss: 0.3981  loss_cls: 0.1893  loss_bbox: 0.2087
2025/05/13 03:52:00 - mmengine - INFO - Epoch(train) [12][ 650/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:28:18  time: 0.3009  data_time: 0.0005  memory: 19505  loss: 0.4466  loss_cls: 0.2132  loss_bbox: 0.2334
2025/05/13 03:52:15 - mmengine - INFO - Epoch(train) [12][ 700/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:28:03  time: 0.3010  data_time: 0.0005  memory: 19504  loss: 0.4229  loss_cls: 0.1961  loss_bbox: 0.2268
2025/05/13 03:52:30 - mmengine - INFO - Epoch(train) [12][ 750/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:27:48  time: 0.3005  data_time: 0.0005  memory: 19502  loss: 0.4276  loss_cls: 0.2054  loss_bbox: 0.2222
2025/05/13 03:52:45 - mmengine - INFO - Epoch(train) [12][ 800/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:27:33  time: 0.3008  data_time: 0.0005  memory: 19491  loss: 0.4101  loss_cls: 0.1937  loss_bbox: 0.2164
2025/05/13 03:53:00 - mmengine - INFO - Epoch(train) [12][ 850/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:27:17  time: 0.3005  data_time: 0.0005  memory: 19517  loss: 0.3914  loss_cls: 0.1780  loss_bbox: 0.2134
2025/05/13 03:53:15 - mmengine - INFO - Epoch(train) [12][ 900/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:27:02  time: 0.3003  data_time: 0.0005  memory: 19486  loss: 0.4290  loss_cls: 0.1989  loss_bbox: 0.2301
2025/05/13 03:53:30 - mmengine - INFO - Epoch(train) [12][ 950/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:26:47  time: 0.3009  data_time: 0.0005  memory: 19497  loss: 0.4208  loss_cls: 0.1918  loss_bbox: 0.2290
2025/05/13 03:53:46 - mmengine - INFO - Epoch(train) [12][1000/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:26:31  time: 0.3010  data_time: 0.0005  memory: 19503  loss: 0.4159  loss_cls: 0.1927  loss_bbox: 0.2232
2025/05/13 03:54:01 - mmengine - INFO - Epoch(train) [12][1050/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:26:17  time: 0.3046  data_time: 0.0006  memory: 19490  loss: 0.4175  loss_cls: 0.1962  loss_bbox: 0.2212
2025/05/13 03:54:16 - mmengine - INFO - Epoch(train) [12][1100/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:26:01  time: 0.3008  data_time: 0.0005  memory: 19506  loss: 0.4255  loss_cls: 0.2035  loss_bbox: 0.2220
2025/05/13 03:54:31 - mmengine - INFO - Epoch(train) [12][1150/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:25:46  time: 0.3012  data_time: 0.0005  memory: 19488  loss: 0.4164  loss_cls: 0.1974  loss_bbox: 0.2190
2025/05/13 03:54:46 - mmengine - INFO - Epoch(train) [12][1200/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:25:31  time: 0.3013  data_time: 0.0005  memory: 19511  loss: 0.4125  loss_cls: 0.1951  loss_bbox: 0.2174
2025/05/13 03:55:01 - mmengine - INFO - Epoch(train) [12][1250/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:25:16  time: 0.3010  data_time: 0.0006  memory: 19499  loss: 0.4182  loss_cls: 0.1941  loss_bbox: 0.2240
2025/05/13 03:55:11 - mmengine - INFO - Exp name: rtmdet_m_1x_custom_resume_20250513_030051
2025/05/13 03:55:16 - mmengine - INFO - Epoch(train) [12][1300/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:25:01  time: 0.3016  data_time: 0.0005  memory: 19474  loss: 0.3997  loss_cls: 0.1801  loss_bbox: 0.2196
2025/05/13 03:55:31 - mmengine - INFO - Epoch(train) [12][1350/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:24:46  time: 0.3007  data_time: 0.0005  memory: 19487  loss: 0.4243  loss_cls: 0.2029  loss_bbox: 0.2213
2025/05/13 03:55:46 - mmengine - INFO - Epoch(train) [12][1400/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:24:30  time: 0.3008  data_time: 0.0005  memory: 19482  loss: 0.4383  loss_cls: 0.2026  loss_bbox: 0.2357
2025/05/13 03:56:01 - mmengine - INFO - Epoch(train) [12][1450/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:24:15  time: 0.3009  data_time: 0.0005  memory: 19512  loss: 0.4270  loss_cls: 0.1942  loss_bbox: 0.2328
2025/05/13 03:56:16 - mmengine - INFO - Epoch(train) [12][1500/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:24:00  time: 0.3012  data_time: 0.0005  memory: 19489  loss: 0.4308  loss_cls: 0.2054  loss_bbox: 0.2254
2025/05/13 03:56:24 - mmengine - INFO - Exp name: rtmdet_m_1x_custom_resume_20250513_030051
2025/05/13 03:56:24 - mmengine - INFO - Saving checkpoint at 12 epochs
2025/05/13 03:56:29 - mmengine - INFO - Epoch(val) [12][ 50/149]    eta: 0:00:08  time: 0.0825  data_time: 0.0032  memory: 19485  
2025/05/13 03:56:33 - mmengine - INFO - Epoch(val) [12][100/149]    eta: 0:00:03  time: 0.0804  data_time: 0.0026  memory: 1598  
2025/05/13 03:56:38 - mmengine - INFO - Evaluating bbox...
2025/05/13 03:56:41 - mmengine - INFO - bbox_mAP_copypaste: 0.771 0.942 0.862 0.427 0.662 0.814
2025/05/13 03:56:41 - mmengine - INFO - Epoch(val) [12][149/149]    coco/bbox_mAP: 0.7710  coco/bbox_mAP_50: 0.9420  coco/bbox_mAP_75: 0.8620  coco/bbox_mAP_s: 0.4270  coco/bbox_mAP_m: 0.6620  coco/bbox_mAP_l: 0.8140  data_time: 0.0028  time: 0.0805
2025/05/13 03:56:56 - mmengine - INFO - Epoch(train) [13][  50/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:23:36  time: 0.3029  data_time: 0.0026  memory: 19498  loss: 0.4112  loss_cls: 0.1976  loss_bbox: 0.2136
2025/05/13 03:57:11 - mmengine - INFO - Epoch(train) [13][ 100/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:23:21  time: 0.3015  data_time: 0.0005  memory: 19511  loss: 0.4174  loss_cls: 0.1929  loss_bbox: 0.2245
2025/05/13 03:57:26 - mmengine - INFO - Epoch(train) [13][ 150/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:23:06  time: 0.3010  data_time: 0.0005  memory: 19481  loss: 0.3979  loss_cls: 0.1872  loss_bbox: 0.2107
2025/05/13 03:57:41 - mmengine - INFO - Epoch(train) [13][ 200/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:22:50  time: 0.3009  data_time: 0.0005  memory: 19514  loss: 0.4168  loss_cls: 0.1928  loss_bbox: 0.2240
2025/05/13 03:57:56 - mmengine - INFO - Epoch(train) [13][ 250/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:22:36  time: 0.3053  data_time: 0.0006  memory: 19491  loss: 0.4398  loss_cls: 0.2085  loss_bbox: 0.2313
2025/05/13 03:58:12 - mmengine - INFO - Epoch(train) [13][ 300/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:22:20  time: 0.3008  data_time: 0.0005  memory: 19493  loss: 0.4298  loss_cls: 0.1980  loss_bbox: 0.2318
2025/05/13 03:58:27 - mmengine - INFO - Epoch(train) [13][ 350/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:22:05  time: 0.3009  data_time: 0.0006  memory: 19485  loss: 0.4043  loss_cls: 0.1892  loss_bbox: 0.2152
2025/05/13 03:58:42 - mmengine - INFO - Epoch(train) [13][ 400/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:21:50  time: 0.3005  data_time: 0.0005  memory: 19484  loss: 0.4287  loss_cls: 0.2053  loss_bbox: 0.2234
2025/05/13 03:58:57 - mmengine - INFO - Epoch(train) [13][ 450/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:21:35  time: 0.3003  data_time: 0.0005  memory: 19505  loss: 0.4042  loss_cls: 0.1845  loss_bbox: 0.2198
2025/05/13 03:59:12 - mmengine - INFO - Epoch(train) [13][ 500/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:21:19  time: 0.3003  data_time: 0.0005  memory: 19504  loss: 0.4181  loss_cls: 0.1912  loss_bbox: 0.2269
2025/05/13 03:59:27 - mmengine - INFO - Epoch(train) [13][ 550/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:21:04  time: 0.3003  data_time: 0.0005  memory: 19520  loss: 0.4195  loss_cls: 0.1931  loss_bbox: 0.2264
2025/05/13 03:59:42 - mmengine - INFO - Epoch(train) [13][ 600/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:20:49  time: 0.3002  data_time: 0.0005  memory: 19509  loss: 0.4070  loss_cls: 0.1889  loss_bbox: 0.2182
2025/05/13 03:59:57 - mmengine - INFO - Epoch(train) [13][ 650/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:20:33  time: 0.3000  data_time: 0.0005  memory: 19493  loss: 0.4108  loss_cls: 0.1973  loss_bbox: 0.2135
2025/05/13 04:00:12 - mmengine - INFO - Epoch(train) [13][ 700/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:20:18  time: 0.3002  data_time: 0.0005  memory: 19502  loss: 0.4684  loss_cls: 0.2357  loss_bbox: 0.2327
2025/05/13 04:00:27 - mmengine - INFO - Epoch(train) [13][ 750/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:20:03  time: 0.3006  data_time: 0.0005  memory: 19509  loss: 0.4369  loss_cls: 0.2098  loss_bbox: 0.2271
2025/05/13 04:00:28 - mmengine - INFO - Exp name: rtmdet_m_1x_custom_resume_20250513_030051
2025/05/13 04:00:42 - mmengine - INFO - Epoch(train) [13][ 800/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:19:48  time: 0.3028  data_time: 0.0005  memory: 19479  loss: 0.4078  loss_cls: 0.1942  loss_bbox: 0.2135
2025/05/13 04:00:57 - mmengine - INFO - Epoch(train) [13][ 850/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:19:33  time: 0.3006  data_time: 0.0005  memory: 19498  loss: 0.3928  loss_cls: 0.1798  loss_bbox: 0.2130
2025/05/13 04:01:12 - mmengine - INFO - Epoch(train) [13][ 900/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:19:18  time: 0.3009  data_time: 0.0005  memory: 19508  loss: 0.3944  loss_cls: 0.1863  loss_bbox: 0.2080
2025/05/13 04:01:27 - mmengine - INFO - Epoch(train) [13][ 950/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:19:02  time: 0.3015  data_time: 0.0005  memory: 19511  loss: 0.4085  loss_cls: 0.1844  loss_bbox: 0.2240
2025/05/13 04:01:42 - mmengine - INFO - Epoch(train) [13][1000/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:18:47  time: 0.3003  data_time: 0.0005  memory: 19482  loss: 0.4024  loss_cls: 0.1899  loss_bbox: 0.2124
2025/05/13 04:01:57 - mmengine - INFO - Epoch(train) [13][1050/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:18:32  time: 0.3054  data_time: 0.0005  memory: 19494  loss: 0.4201  loss_cls: 0.1911  loss_bbox: 0.2290
2025/05/13 04:02:12 - mmengine - INFO - Epoch(train) [13][1100/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:18:17  time: 0.3007  data_time: 0.0005  memory: 19500  loss: 0.4143  loss_cls: 0.1961  loss_bbox: 0.2182
2025/05/13 04:02:27 - mmengine - INFO - Epoch(train) [13][1150/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:18:02  time: 0.3013  data_time: 0.0005  memory: 19509  loss: 0.4165  loss_cls: 0.1947  loss_bbox: 0.2219
2025/05/13 04:02:42 - mmengine - INFO - Epoch(train) [13][1200/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:17:47  time: 0.3008  data_time: 0.0005  memory: 19479  loss: 0.4069  loss_cls: 0.1964  loss_bbox: 0.2105
2025/05/13 04:02:57 - mmengine - INFO - Epoch(train) [13][1250/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:17:32  time: 0.3009  data_time: 0.0005  memory: 19492  loss: 0.4339  loss_cls: 0.2070  loss_bbox: 0.2269
2025/05/13 04:03:13 - mmengine - INFO - Epoch(train) [13][1300/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:17:17  time: 0.3017  data_time: 0.0005  memory: 19480  loss: 0.4301  loss_cls: 0.2028  loss_bbox: 0.2273
2025/05/13 04:03:28 - mmengine - INFO - Epoch(train) [13][1350/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:17:01  time: 0.3011  data_time: 0.0005  memory: 19510  loss: 0.4141  loss_cls: 0.1910  loss_bbox: 0.2232
2025/05/13 04:03:43 - mmengine - INFO - Epoch(train) [13][1400/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:16:46  time: 0.3009  data_time: 0.0005  memory: 19479  loss: 0.4173  loss_cls: 0.1875  loss_bbox: 0.2298
2025/05/13 04:03:58 - mmengine - INFO - Epoch(train) [13][1450/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:16:31  time: 0.3011  data_time: 0.0005  memory: 19485  loss: 0.4146  loss_cls: 0.1980  loss_bbox: 0.2166
2025/05/13 04:04:13 - mmengine - INFO - Epoch(train) [13][1500/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:16:16  time: 0.3015  data_time: 0.0005  memory: 19477  loss: 0.4001  loss_cls: 0.1869  loss_bbox: 0.2132
2025/05/13 04:04:21 - mmengine - INFO - Exp name: rtmdet_m_1x_custom_resume_20250513_030051
2025/05/13 04:04:21 - mmengine - INFO - Saving checkpoint at 13 epochs
2025/05/13 04:04:26 - mmengine - INFO - Epoch(val) [13][ 50/149]    eta: 0:00:08  time: 0.0819  data_time: 0.0037  memory: 19490  
2025/05/13 04:04:30 - mmengine - INFO - Epoch(val) [13][100/149]    eta: 0:00:04  time: 0.0861  data_time: 0.0027  memory: 1598  
2025/05/13 04:04:35 - mmengine - INFO - Evaluating bbox...
2025/05/13 04:04:38 - mmengine - INFO - bbox_mAP_copypaste: 0.772 0.940 0.861 0.424 0.662 0.816
2025/05/13 04:04:38 - mmengine - INFO - Epoch(val) [13][149/149]    coco/bbox_mAP: 0.7720  coco/bbox_mAP_50: 0.9400  coco/bbox_mAP_75: 0.8610  coco/bbox_mAP_s: 0.4240  coco/bbox_mAP_m: 0.6620  coco/bbox_mAP_l: 0.8160  data_time: 0.0030  time: 0.0823
2025/05/13 04:04:53 - mmengine - INFO - Epoch(train) [14][  50/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:15:52  time: 0.3024  data_time: 0.0024  memory: 19513  loss: 0.4168  loss_cls: 0.1905  loss_bbox: 0.2263
2025/05/13 04:05:08 - mmengine - INFO - Epoch(train) [14][ 100/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:15:37  time: 0.2998  data_time: 0.0005  memory: 19476  loss: 0.4271  loss_cls: 0.1995  loss_bbox: 0.2277
2025/05/13 04:05:23 - mmengine - INFO - Epoch(train) [14][ 150/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:15:22  time: 0.3041  data_time: 0.0005  memory: 19506  loss: 0.3934  loss_cls: 0.1870  loss_bbox: 0.2064
2025/05/13 04:05:38 - mmengine - INFO - Epoch(train) [14][ 200/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:15:07  time: 0.3001  data_time: 0.0005  memory: 19508  loss: 0.4149  loss_cls: 0.1883  loss_bbox: 0.2266
2025/05/13 04:05:46 - mmengine - INFO - Exp name: rtmdet_m_1x_custom_resume_20250513_030051
2025/05/13 04:05:53 - mmengine - INFO - Epoch(train) [14][ 250/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:14:52  time: 0.3020  data_time: 0.0006  memory: 19509  loss: 0.4167  loss_cls: 0.1949  loss_bbox: 0.2218
2025/05/13 04:06:08 - mmengine - INFO - Epoch(train) [14][ 300/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:14:36  time: 0.3020  data_time: 0.0006  memory: 19510  loss: 0.4170  loss_cls: 0.1887  loss_bbox: 0.2283
2025/05/13 04:06:23 - mmengine - INFO - Epoch(train) [14][ 350/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:14:21  time: 0.3010  data_time: 0.0005  memory: 19491  loss: 0.3972  loss_cls: 0.1789  loss_bbox: 0.2184
2025/05/13 04:06:38 - mmengine - INFO - Epoch(train) [14][ 400/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:14:06  time: 0.3009  data_time: 0.0005  memory: 19491  loss: 0.4204  loss_cls: 0.2007  loss_bbox: 0.2197
2025/05/13 04:06:53 - mmengine - INFO - Epoch(train) [14][ 450/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:13:51  time: 0.3014  data_time: 0.0005  memory: 19507  loss: 0.4316  loss_cls: 0.1978  loss_bbox: 0.2337
2025/05/13 04:07:08 - mmengine - INFO - Epoch(train) [14][ 500/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:13:36  time: 0.3008  data_time: 0.0005  memory: 19483  loss: 0.4248  loss_cls: 0.2009  loss_bbox: 0.2239
2025/05/13 04:07:23 - mmengine - INFO - Epoch(train) [14][ 550/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:13:21  time: 0.3010  data_time: 0.0005  memory: 19497  loss: 0.3881  loss_cls: 0.1814  loss_bbox: 0.2066
2025/05/13 04:07:39 - mmengine - INFO - Epoch(train) [14][ 600/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:13:05  time: 0.3009  data_time: 0.0005  memory: 19505  loss: 0.4341  loss_cls: 0.2062  loss_bbox: 0.2279
2025/05/13 04:07:54 - mmengine - INFO - Epoch(train) [14][ 650/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:12:50  time: 0.3010  data_time: 0.0005  memory: 19495  loss: 0.4362  loss_cls: 0.2017  loss_bbox: 0.2346
2025/05/13 04:08:09 - mmengine - INFO - Epoch(train) [14][ 700/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:12:35  time: 0.3010  data_time: 0.0005  memory: 19510  loss: 0.4178  loss_cls: 0.2034  loss_bbox: 0.2144
2025/05/13 04:08:24 - mmengine - INFO - Epoch(train) [14][ 750/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:12:20  time: 0.3010  data_time: 0.0005  memory: 19493  loss: 0.4180  loss_cls: 0.1938  loss_bbox: 0.2241
2025/05/13 04:08:39 - mmengine - INFO - Epoch(train) [14][ 800/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:12:05  time: 0.3014  data_time: 0.0005  memory: 19496  loss: 0.4302  loss_cls: 0.2014  loss_bbox: 0.2289
2025/05/13 04:08:54 - mmengine - INFO - Epoch(train) [14][ 850/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:11:50  time: 0.3008  data_time: 0.0005  memory: 19488  loss: 0.4106  loss_cls: 0.1939  loss_bbox: 0.2167
2025/05/13 04:09:09 - mmengine - INFO - Epoch(train) [14][ 900/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:11:35  time: 0.3013  data_time: 0.0005  memory: 19507  loss: 0.4261  loss_cls: 0.1959  loss_bbox: 0.2302
2025/05/13 04:09:24 - mmengine - INFO - Epoch(train) [14][ 950/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:11:20  time: 0.3050  data_time: 0.0005  memory: 19477  loss: 0.4130  loss_cls: 0.1946  loss_bbox: 0.2184
2025/05/13 04:09:39 - mmengine - INFO - Epoch(train) [14][1000/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:11:05  time: 0.3012  data_time: 0.0005  memory: 19502  loss: 0.4316  loss_cls: 0.2071  loss_bbox: 0.2245
2025/05/13 04:09:54 - mmengine - INFO - Epoch(train) [14][1050/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:10:49  time: 0.3007  data_time: 0.0005  memory: 19474  loss: 0.4064  loss_cls: 0.1916  loss_bbox: 0.2148
2025/05/13 04:10:09 - mmengine - INFO - Epoch(train) [14][1100/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:10:34  time: 0.3009  data_time: 0.0005  memory: 19484  loss: 0.4247  loss_cls: 0.1903  loss_bbox: 0.2345
2025/05/13 04:10:24 - mmengine - INFO - Epoch(train) [14][1150/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:10:19  time: 0.3007  data_time: 0.0005  memory: 19503  loss: 0.4394  loss_cls: 0.2061  loss_bbox: 0.2333
2025/05/13 04:10:39 - mmengine - INFO - Epoch(train) [14][1200/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:10:04  time: 0.3002  data_time: 0.0005  memory: 19502  loss: 0.4240  loss_cls: 0.2004  loss_bbox: 0.2236
2025/05/13 04:10:47 - mmengine - INFO - Exp name: rtmdet_m_1x_custom_resume_20250513_030051
2025/05/13 04:10:54 - mmengine - INFO - Epoch(train) [14][1250/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:09:49  time: 0.3022  data_time: 0.0006  memory: 19481  loss: 0.4140  loss_cls: 0.1954  loss_bbox: 0.2186
2025/05/13 04:11:09 - mmengine - INFO - Epoch(train) [14][1300/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:09:34  time: 0.3011  data_time: 0.0005  memory: 19487  loss: 0.4085  loss_cls: 0.1928  loss_bbox: 0.2157
2025/05/13 04:11:24 - mmengine - INFO - Epoch(train) [14][1350/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:09:18  time: 0.3003  data_time: 0.0005  memory: 19488  loss: 0.4075  loss_cls: 0.1929  loss_bbox: 0.2146
2025/05/13 04:11:40 - mmengine - INFO - Epoch(train) [14][1400/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:09:03  time: 0.3006  data_time: 0.0005  memory: 19502  loss: 0.3999  loss_cls: 0.1764  loss_bbox: 0.2234
2025/05/13 04:11:55 - mmengine - INFO - Epoch(train) [14][1450/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:08:48  time: 0.3012  data_time: 0.0005  memory: 19512  loss: 0.4359  loss_cls: 0.2044  loss_bbox: 0.2314
2025/05/13 04:12:10 - mmengine - INFO - Epoch(train) [14][1500/1528]  base_lr: 6.1179e-06 lr: 6.1179e-06  eta: 2:08:33  time: 0.3012  data_time: 0.0005  memory: 19477  loss: 0.4182  loss_cls: 0.1992  loss_bbox: 0.2190
2025/05/13 04:12:18 - mmengine - INFO - Exp name: rtmdet_m_1x_custom_resume_20250513_030051
2025/05/13 04:12:18 - mmengine - INFO - Saving checkpoint at 14 epochs
2025/05/13 04:12:23 - mmengine - INFO - Epoch(val) [14][ 50/149]    eta: 0:00:08  time: 0.0828  data_time: 0.0042  memory: 19511  
2025/05/13 04:12:27 - mmengine - INFO - Epoch(val) [14][100/149]    eta: 0:00:04  time: 0.0832  data_time: 0.0030  memory: 1598  
2025/05/13 04:12:32 - mmengine - INFO - Evaluating bbox...
2025/05/13 04:12:35 - mmengine - INFO - bbox_mAP_copypaste: 0.772 0.942 0.862 0.428 0.665 0.816
2025/05/13 04:12:35 - mmengine - INFO - Epoch(val) [14][149/149]    coco/bbox_mAP: 0.7720  coco/bbox_mAP_50: 0.9420  coco/bbox_mAP_75: 0.8620  coco/bbox_mAP_s: 0.4280  coco/bbox_mAP_m: 0.6650  coco/bbox_mAP_l: 0.8160  data_time: 0.0034  time: 0.0829
2025/05/13 04:12:35 - mmengine - INFO - the monitored metric did not improve in the last 3 records. best score: 0.774. 
