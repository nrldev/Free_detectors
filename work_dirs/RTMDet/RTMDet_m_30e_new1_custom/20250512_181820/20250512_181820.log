2025/05/12 18:18:20 - mmengine - INFO - 
------------------------------------------------------------
System environment:
    sys.platform: linux
    Python: 3.11.11 (main, Dec 11 2024, 16:28:39) [GCC 11.2.0]
    CUDA available: True
    MUSA available: False
    numpy_random_seed: 558238071
    GPU 0: NVIDIA GeForce RTX 4090
    CUDA_HOME: /usr
    NVCC: Cuda compilation tools, release 12.0, V12.0.140
    GCC: gcc (Ubuntu 13.3.0-6ubuntu2~24.04) 13.3.0
    PyTorch: 2.4.1+cu121
    PyTorch compiling details: PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v3.4.2 (Git Hash 1137e04ec0b5251ca2b4400a4fd3c667ce843d67)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX512
  - CUDA Runtime 12.1
  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 90.1  (built against CUDA 12.4)
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=12.1, CUDNN_VERSION=9.1.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wsuggest-override -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=2.4.1, USE_CUDA=ON, USE_CUDNN=ON, USE_CUSPARSELT=1, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_GLOO=ON, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, USE_ROCM_KERNEL_ASSERT=OFF, 

    TorchVision: 0.19.1+cu121
    OpenCV: 4.11.0
    MMEngine: 0.10.7

Runtime environment:
    cudnn_benchmark: False
    dist_cfg: {'backend': 'nccl'}
    mp_cfg: {'mp_start_method': 'fork', 'opencv_num_threads': 0}
    seed: 558238071
    Distributed launcher: none
    Distributed training: False
    GPU number: 1
------------------------------------------------------------

2025/05/12 18:18:20 - mmengine - INFO - Config:
HOME = '/home/jaa/Work/Prog/BSU/Detectors'
MODEL_GROUP = 'yolo-like'
MODEL_TYPE = 'RTMDet'
WEIGHT_SIZE = 'm'
additions = 'new1'
auto_scale_lr = dict(base_batch_size=6, enable=False)
backend_args = None
base_lr = 0.004
batch_size = 6
checkpoint_config = dict(interval=1)
custom_hooks = [
    dict(type='CustomFreezeHook', unfreeze_epoch=5),
]
custom_imports = dict(
    allow_failed_imports=False, imports=[
        'custom_hooks',
    ])
data_root = '/home/jaa/Work/Prog/BSU/Detectors/mmdetection/data/Padded_GroundingDINO.v1i.yolov5pytorch/'
dataset_type = 'CocoDataset'
default_hooks = dict(
    checkpoint=dict(interval=1, max_keep_ckpts=3, type='CheckpointHook'),
    early_stopping=dict(
        min_delta=0.001,
        monitor='coco/bbox_mAP',
        patience=3,
        type='EarlyStoppingHook'),
    logger=dict(interval=50, log_metric_by_epoch=True, type='LoggerHook'),
    param_scheduler=dict(type='ParamSchedulerHook'),
    sampler_seed=dict(type='DistSamplerSeedHook'),
    timer=dict(type='IterTimerHook'),
    visualization=dict(type='DetVisualizationHook'))
default_scope = 'mmdet'
deterministic = True
env_cfg = dict(
    cudnn_benchmark=False,
    dist_cfg=dict(backend='nccl'),
    mp_cfg=dict(mp_start_method='fork', opencv_num_threads=0))
evaluation = dict(interval=1, metric='bbox')
experiment = 'RTMDet_m_30e_new1_custom'
img_scales = [
    (
        640,
        640,
    ),
    (
        320,
        320,
    ),
    (
        960,
        960,
    ),
]
interval = 10
launcher = 'none'
load_from = '/home/jaa/Work/Prog/BSU/Detectors/work_dirs/RTMDet/RTMDet_m_30e_new1_custom/epoch_5.pth'
log_level = 'INFO'
log_processor = dict(by_epoch=True, type='LogProcessor', window_size=50)
max_epochs = 300
metainfo = dict(
    classes=('cow', ), palette=[
        (
            220,
            20,
            60,
        ),
    ])
model = dict(
    backbone=dict(
        act_cfg=dict(inplace=True, type='SiLU'),
        arch='P5',
        channel_attention=True,
        deepen_factor=0.67,
        expand_ratio=0.5,
        norm_cfg=dict(type='SyncBN'),
        type='CSPNeXt',
        widen_factor=0.75),
    bbox_head=dict(
        act_cfg=dict(inplace=True, type='SiLU'),
        anchor_generator=dict(
            offset=0, strides=[
                8,
                16,
                32,
            ], type='MlvlPointGenerator'),
        bbox_coder=dict(type='DistancePointBBoxCoder'),
        exp_on_reg=True,
        feat_channels=192,
        in_channels=192,
        loss_bbox=dict(loss_weight=2.0, type='GIoULoss'),
        loss_cls=dict(
            beta=2.0,
            loss_weight=1.0,
            type='QualityFocalLoss',
            use_sigmoid=True),
        norm_cfg=dict(type='SyncBN'),
        num_classes=1,
        pred_kernel_size=1,
        share_conv=True,
        stacked_convs=2,
        type='RTMDetSepBNHead',
        with_objectness=False),
    data_preprocessor=dict(
        batch_augments=None,
        bgr_to_rgb=False,
        mean=[
            103.53,
            116.28,
            123.675,
        ],
        std=[
            57.375,
            57.12,
            58.395,
        ],
        type='DetDataPreprocessor'),
    neck=dict(
        act_cfg=dict(inplace=True, type='SiLU'),
        expand_ratio=0.5,
        in_channels=[
            192,
            384,
            768,
        ],
        norm_cfg=dict(type='SyncBN'),
        num_csp_blocks=2,
        out_channels=192,
        type='CSPNeXtPAFPN'),
    test_cfg=dict(
        max_per_img=300,
        min_bbox_size=0,
        nms=dict(iou_threshold=0.65, type='nms'),
        nms_pre=30000,
        score_thr=0.001),
    train_cfg=dict(
        allowed_border=-1,
        assigner=dict(topk=13, type='DynamicSoftLabelAssigner'),
        debug=False,
        pos_weight=-1),
    type='RTMDet')
num_classes = 1
num_epochs = 20
num_workers = 6
optim_wrapper = dict(
    optimizer=dict(lr=0.0025, momentum=0.9, type='SGD', weight_decay=0.0005),
    paramwise_cfg=dict(
        bias_decay_mult=0, bypass_duplicate=True, norm_decay_mult=0),
    type='OptimWrapper')
param_scheduler = [
    dict(
        begin=0, by_epoch=False, end=500, start_factor=0.001, type='LinearLR'),
    dict(
        begin=0,
        by_epoch=True,
        end=20,
        gamma=0.1,
        milestones=[
            7,
            14,
        ],
        type='MultiStepLR'),
    dict(T_max=20, begin=0, by_epoch=True, end=20, type='CosineAnnealingLR'),
]
resume = True
seed = 65
stage2_num_epochs = 20
test_cfg = dict(type='TestLoop')
test_dataloader = dict(
    batch_size=6,
    dataset=dict(
        ann_file=
        '/home/jaa/Work/Prog/BSU/Detectors/mmdetection/data/Padded_GroundingDINO.v1i.yolov5pytorch/test_coco.json',
        backend_args=None,
        data_prefix=dict(
            img=
            '/home/jaa/Work/Prog/BSU/Detectors/mmdetection/data/Padded_GroundingDINO.v1i.yolov5pytorch/test/images'
        ),
        data_root=
        '/home/jaa/Work/Prog/BSU/Detectors/mmdetection/data/Padded_GroundingDINO.v1i.yolov5pytorch/',
        pipeline=[
            dict(backend_args=None, type='LoadImageFromFile'),
            dict(type='LoadAnnotations', with_bbox=True),
            dict(
                keep_empty=False,
                min_gt_bbox_wh=(
                    16,
                    16,
                ),
                type='FilterAnnotations'),
            dict(keep_ratio=True, scale=(
                1280,
                1280,
            ), type='Resize'),
            dict(
                meta_keys=(
                    'img_id',
                    'img_path',
                    'ori_shape',
                    'img_shape',
                    'scale_factor',
                ),
                type='PackDetInputs'),
        ],
        test_mode=True,
        type='CocoDataset'),
    drop_last=False,
    num_workers=6,
    persistent_workers=True,
    sampler=dict(shuffle=False, type='DefaultSampler'))
test_evaluator = dict(
    ann_file=
    '/home/jaa/Work/Prog/BSU/Detectors/mmdetection/data/Padded_GroundingDINO.v1i.yolov5pytorch/test_coco.json',
    backend_args=None,
    format_only=True,
    metric='bbox',
    outfile_prefix=
    '/home/jaa/Work/Prog/BSU/Detectors/mmdetection/data/Padded_GroundingDINO.v1i.yolov5pytorch/test/images',
    proposal_nums=(
        100,
        1,
        10,
    ),
    type='CocoMetric')
test_pipeline = [
    dict(backend_args=None, type='LoadImageFromFile'),
    dict(type='LoadAnnotations', with_bbox=True),
    dict(
        keep_empty=False, min_gt_bbox_wh=(
            16,
            16,
        ), type='FilterAnnotations'),
    dict(keep_ratio=True, scale=(
        1280,
        1280,
    ), type='Resize'),
    dict(
        meta_keys=(
            'img_id',
            'img_path',
            'ori_shape',
            'img_shape',
            'scale_factor',
        ),
        type='PackDetInputs'),
]
train_cfg = dict(
    dynamic_intervals=[
        (
            280,
            1,
        ),
    ],
    max_epochs=30,
    type='EpochBasedTrainLoop',
    val_interval=1)
train_dataloader = dict(
    batch_sampler=None,
    batch_size=6,
    dataset=dict(
        ann_file=
        '/home/jaa/Work/Prog/BSU/Detectors/mmdetection/data/Padded_GroundingDINO.v1i.yolov5pytorch/train_coco.json',
        backend_args=None,
        data_prefix=dict(
            img=
            '/home/jaa/Work/Prog/BSU/Detectors/mmdetection/data/Padded_GroundingDINO.v1i.yolov5pytorch/train/images'
        ),
        data_root=
        '/home/jaa/Work/Prog/BSU/Detectors/mmdetection/data/Padded_GroundingDINO.v1i.yolov5pytorch/',
        filter_cfg=dict(filter_empty_gt=True, min_size=32),
        metainfo=dict(classes=('cow', ), palette=[
            (
                220,
                20,
                60,
            ),
        ]),
        pipeline=[
            dict(backend_args=None, type='LoadImageFromFile'),
            dict(type='LoadAnnotations', with_bbox=True),
            dict(prob=0.5, type='RandomFlip'),
            dict(level=2, prob=0.3, type='Rotate'),
            dict(
                keep_empty=False,
                min_gt_bbox_wh=(
                    16,
                    16,
                ),
                type='FilterAnnotations'),
            dict(keep_ratio=True, scale=(
                1280,
                1280,
            ), type='Resize'),
            dict(type='PackDetInputs'),
        ],
        type='CocoDataset'),
    num_workers=6,
    persistent_workers=True,
    pin_memory=True,
    sampler=dict(shuffle=True, type='DefaultSampler'))
train_pipeline = [
    dict(backend_args=None, type='LoadImageFromFile'),
    dict(type='LoadAnnotations', with_bbox=True),
    dict(prob=0.5, type='RandomFlip'),
    dict(level=2, prob=0.3, type='Rotate'),
    dict(
        keep_empty=False, min_gt_bbox_wh=(
            16,
            16,
        ), type='FilterAnnotations'),
    dict(keep_ratio=True, scale=(
        1280,
        1280,
    ), type='Resize'),
    dict(type='PackDetInputs'),
]
train_pipeline_stage2 = [
    dict(backend_args=None, type='LoadImageFromFile'),
    dict(type='LoadAnnotations', with_bbox=True),
    dict(
        keep_ratio=True,
        ratio_range=(
            0.1,
            2.0,
        ),
        scale=(
            640,
            640,
        ),
        type='RandomResize'),
    dict(crop_size=(
        640,
        640,
    ), type='RandomCrop'),
    dict(type='YOLOXHSVRandomAug'),
    dict(prob=0.5, type='RandomFlip'),
    dict(pad_val=dict(img=(
        114,
        114,
        114,
    )), size=(
        640,
        640,
    ), type='Pad'),
    dict(type='PackDetInputs'),
]
tta_model = dict(
    tta_cfg=dict(max_per_img=100, nms=dict(iou_threshold=0.6, type='nms')),
    type='DetTTAModel')
tta_pipeline = [
    dict(backend_args=None, type='LoadImageFromFile'),
    dict(
        transforms=[
            [
                dict(keep_ratio=True, scale=(
                    640,
                    640,
                ), type='Resize'),
                dict(keep_ratio=True, scale=(
                    320,
                    320,
                ), type='Resize'),
                dict(keep_ratio=True, scale=(
                    960,
                    960,
                ), type='Resize'),
            ],
            [
                dict(prob=1.0, type='RandomFlip'),
                dict(prob=0.0, type='RandomFlip'),
            ],
            [
                dict(
                    pad_val=dict(img=(
                        114,
                        114,
                        114,
                    )),
                    size=(
                        960,
                        960,
                    ),
                    type='Pad'),
            ],
            [
                dict(type='LoadAnnotations', with_bbox=True),
            ],
            [
                dict(
                    meta_keys=(
                        'img_id',
                        'img_path',
                        'ori_shape',
                        'img_shape',
                        'scale_factor',
                        'flip',
                        'flip_direction',
                    ),
                    type='PackDetInputs'),
            ],
        ],
        type='TestTimeAug'),
]
val_cfg = dict(type='ValLoop')
val_dataloader = dict(
    batch_size=5,
    dataset=dict(
        ann_file=
        '/home/jaa/Work/Prog/BSU/Detectors/mmdetection/data/Padded_GroundingDINO.v1i.yolov5pytorch/valid_coco.json',
        backend_args=None,
        data_prefix=dict(
            img=
            '/home/jaa/Work/Prog/BSU/Detectors/mmdetection/data/Padded_GroundingDINO.v1i.yolov5pytorch/valid/images'
        ),
        data_root=
        '/home/jaa/Work/Prog/BSU/Detectors/mmdetection/data/Padded_GroundingDINO.v1i.yolov5pytorch/',
        metainfo=dict(classes=('cow', ), palette=[
            (
                220,
                20,
                60,
            ),
        ]),
        pipeline=[
            dict(backend_args=None, type='LoadImageFromFile'),
            dict(type='LoadAnnotations', with_bbox=True),
            dict(
                keep_empty=False,
                min_gt_bbox_wh=(
                    16,
                    16,
                ),
                type='FilterAnnotations'),
            dict(keep_ratio=True, scale=(
                1280,
                1280,
            ), type='Resize'),
            dict(
                meta_keys=(
                    'img_id',
                    'img_path',
                    'ori_shape',
                    'img_shape',
                    'scale_factor',
                ),
                type='PackDetInputs'),
        ],
        test_mode=True,
        type='CocoDataset'),
    drop_last=False,
    num_workers=6,
    persistent_workers=True,
    sampler=dict(shuffle=False, type='DefaultSampler'))
val_evaluator = dict(
    ann_file=
    '/home/jaa/Work/Prog/BSU/Detectors/mmdetection/data/Padded_GroundingDINO.v1i.yolov5pytorch//valid_coco.json',
    backend_args=None,
    format_only=False,
    metric='bbox',
    proposal_nums=(
        100,
        1,
        10,
    ),
    type='CocoMetric')
vis_backends = [
    dict(
        init_kwargs=dict(
            group='yolo-like',
            name='RTMDet_m_30e_6b_new1',
            project='Сomparison of detectors'),
        type='WandbVisBackend'),
]
visualizer = dict(
    type='Visualizer',
    vis_backends=[
        dict(
            init_kwargs=dict(
                group='yolo-like',
                name='RTMDet_m_30e_6b_new1',
                project='Сomparison of detectors'),
            type='WandbVisBackend'),
    ])
weights = 'rtmdet_m_8xb32-300e_coco_20220719_112220-229f527c.pth'
work_dir = '/home/jaa/Work/Prog/BSU/Detectors/work_dirs/RTMDet/RTMDet_m_30e_new1_custom/'

2025/05/12 18:18:24 - mmengine - INFO - Distributed training is not used, all SyncBatchNorm (SyncBN) layers in the model will be automatically reverted to BatchNormXd layers if they are used.
2025/05/12 18:18:24 - mmengine - INFO - Hooks will be executed in the following order:
before_run:
(VERY_HIGH   ) RuntimeInfoHook                    
(BELOW_NORMAL) LoggerHook                         
(LOWEST      ) EarlyStoppingHook                  
 -------------------- 
before_train:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(NORMAL      ) CustomFreezeHook                   
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
before_train_epoch:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(NORMAL      ) DistSamplerSeedHook                
(NORMAL      ) CustomFreezeHook                   
 -------------------- 
before_train_iter:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
 -------------------- 
after_train_iter:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(BELOW_NORMAL) LoggerHook                         
(LOW         ) ParamSchedulerHook                 
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
after_train_epoch:
(NORMAL      ) IterTimerHook                      
(LOW         ) ParamSchedulerHook                 
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
before_val:
(VERY_HIGH   ) RuntimeInfoHook                    
 -------------------- 
before_val_epoch:
(NORMAL      ) IterTimerHook                      
 -------------------- 
before_val_iter:
(NORMAL      ) IterTimerHook                      
 -------------------- 
after_val_iter:
(NORMAL      ) IterTimerHook                      
(NORMAL      ) DetVisualizationHook               
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
after_val_epoch:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(BELOW_NORMAL) LoggerHook                         
(LOW         ) ParamSchedulerHook                 
(VERY_LOW    ) CheckpointHook                     
(LOWEST      ) EarlyStoppingHook                  
 -------------------- 
after_val:
(VERY_HIGH   ) RuntimeInfoHook                    
 -------------------- 
after_train:
(VERY_HIGH   ) RuntimeInfoHook                    
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
before_test:
(VERY_HIGH   ) RuntimeInfoHook                    
 -------------------- 
before_test_epoch:
(NORMAL      ) IterTimerHook                      
 -------------------- 
before_test_iter:
(NORMAL      ) IterTimerHook                      
 -------------------- 
after_test_iter:
(NORMAL      ) IterTimerHook                      
(NORMAL      ) DetVisualizationHook               
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
after_test_epoch:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
after_test:
(VERY_HIGH   ) RuntimeInfoHook                    
 -------------------- 
after_run:
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
2025/05/12 18:18:24 - mmengine - INFO - paramwise_options -- backbone.stem.0.bn.weight:weight_decay=0.0
2025/05/12 18:18:24 - mmengine - INFO - paramwise_options -- backbone.stem.0.bn.bias:weight_decay=0.0
2025/05/12 18:18:24 - mmengine - INFO - paramwise_options -- backbone.stem.1.bn.weight:weight_decay=0.0
2025/05/12 18:18:24 - mmengine - INFO - paramwise_options -- backbone.stem.1.bn.bias:weight_decay=0.0
2025/05/12 18:18:24 - mmengine - INFO - paramwise_options -- backbone.stem.2.bn.weight:weight_decay=0.0
2025/05/12 18:18:24 - mmengine - INFO - paramwise_options -- backbone.stem.2.bn.bias:weight_decay=0.0
2025/05/12 18:18:24 - mmengine - INFO - paramwise_options -- backbone.stage1.0.bn.weight:weight_decay=0.0
2025/05/12 18:18:24 - mmengine - INFO - paramwise_options -- backbone.stage1.0.bn.bias:weight_decay=0.0
2025/05/12 18:18:24 - mmengine - INFO - paramwise_options -- backbone.stage1.1.main_conv.bn.weight:weight_decay=0.0
2025/05/12 18:18:24 - mmengine - INFO - paramwise_options -- backbone.stage1.1.main_conv.bn.bias:weight_decay=0.0
2025/05/12 18:18:24 - mmengine - INFO - paramwise_options -- backbone.stage1.1.short_conv.bn.weight:weight_decay=0.0
2025/05/12 18:18:24 - mmengine - INFO - paramwise_options -- backbone.stage1.1.short_conv.bn.bias:weight_decay=0.0
2025/05/12 18:18:24 - mmengine - INFO - paramwise_options -- backbone.stage1.1.final_conv.bn.weight:weight_decay=0.0
2025/05/12 18:18:24 - mmengine - INFO - paramwise_options -- backbone.stage1.1.final_conv.bn.bias:weight_decay=0.0
2025/05/12 18:18:24 - mmengine - INFO - paramwise_options -- backbone.stage1.1.blocks.0.conv1.bn.weight:weight_decay=0.0
2025/05/12 18:18:24 - mmengine - INFO - paramwise_options -- backbone.stage1.1.blocks.0.conv1.bn.bias:weight_decay=0.0
2025/05/12 18:18:24 - mmengine - INFO - paramwise_options -- backbone.stage1.1.blocks.0.conv2.depthwise_conv.bn.weight:weight_decay=0.0
2025/05/12 18:18:24 - mmengine - INFO - paramwise_options -- backbone.stage1.1.blocks.0.conv2.depthwise_conv.bn.bias:weight_decay=0.0
2025/05/12 18:18:24 - mmengine - INFO - paramwise_options -- backbone.stage1.1.blocks.0.conv2.pointwise_conv.bn.weight:weight_decay=0.0
2025/05/12 18:18:24 - mmengine - INFO - paramwise_options -- backbone.stage1.1.blocks.0.conv2.pointwise_conv.bn.bias:weight_decay=0.0
2025/05/12 18:18:24 - mmengine - INFO - paramwise_options -- backbone.stage1.1.blocks.1.conv1.bn.weight:weight_decay=0.0
2025/05/12 18:18:24 - mmengine - INFO - paramwise_options -- backbone.stage1.1.blocks.1.conv1.bn.bias:weight_decay=0.0
2025/05/12 18:18:24 - mmengine - INFO - paramwise_options -- backbone.stage1.1.blocks.1.conv2.depthwise_conv.bn.weight:weight_decay=0.0
2025/05/12 18:18:24 - mmengine - INFO - paramwise_options -- backbone.stage1.1.blocks.1.conv2.depthwise_conv.bn.bias:weight_decay=0.0
2025/05/12 18:18:24 - mmengine - INFO - paramwise_options -- backbone.stage1.1.blocks.1.conv2.pointwise_conv.bn.weight:weight_decay=0.0
2025/05/12 18:18:24 - mmengine - INFO - paramwise_options -- backbone.stage1.1.blocks.1.conv2.pointwise_conv.bn.bias:weight_decay=0.0
2025/05/12 18:18:24 - mmengine - INFO - paramwise_options -- backbone.stage1.1.attention.fc.bias:weight_decay=0.0
2025/05/12 18:18:24 - mmengine - INFO - paramwise_options -- backbone.stage2.0.bn.weight:weight_decay=0.0
2025/05/12 18:18:24 - mmengine - INFO - paramwise_options -- backbone.stage2.0.bn.bias:weight_decay=0.0
2025/05/12 18:18:24 - mmengine - INFO - paramwise_options -- backbone.stage2.1.main_conv.bn.weight:weight_decay=0.0
2025/05/12 18:18:24 - mmengine - INFO - paramwise_options -- backbone.stage2.1.main_conv.bn.bias:weight_decay=0.0
2025/05/12 18:18:24 - mmengine - INFO - paramwise_options -- backbone.stage2.1.short_conv.bn.weight:weight_decay=0.0
2025/05/12 18:18:24 - mmengine - INFO - paramwise_options -- backbone.stage2.1.short_conv.bn.bias:weight_decay=0.0
2025/05/12 18:18:24 - mmengine - INFO - paramwise_options -- backbone.stage2.1.final_conv.bn.weight:weight_decay=0.0
2025/05/12 18:18:24 - mmengine - INFO - paramwise_options -- backbone.stage2.1.final_conv.bn.bias:weight_decay=0.0
2025/05/12 18:18:24 - mmengine - INFO - paramwise_options -- backbone.stage2.1.blocks.0.conv1.bn.weight:weight_decay=0.0
2025/05/12 18:18:24 - mmengine - INFO - paramwise_options -- backbone.stage2.1.blocks.0.conv1.bn.bias:weight_decay=0.0
2025/05/12 18:18:24 - mmengine - INFO - paramwise_options -- backbone.stage2.1.blocks.0.conv2.depthwise_conv.bn.weight:weight_decay=0.0
2025/05/12 18:18:24 - mmengine - INFO - paramwise_options -- backbone.stage2.1.blocks.0.conv2.depthwise_conv.bn.bias:weight_decay=0.0
2025/05/12 18:18:24 - mmengine - INFO - paramwise_options -- backbone.stage2.1.blocks.0.conv2.pointwise_conv.bn.weight:weight_decay=0.0
2025/05/12 18:18:24 - mmengine - INFO - paramwise_options -- backbone.stage2.1.blocks.0.conv2.pointwise_conv.bn.bias:weight_decay=0.0
2025/05/12 18:18:24 - mmengine - INFO - paramwise_options -- backbone.stage2.1.blocks.1.conv1.bn.weight:weight_decay=0.0
2025/05/12 18:18:24 - mmengine - INFO - paramwise_options -- backbone.stage2.1.blocks.1.conv1.bn.bias:weight_decay=0.0
2025/05/12 18:18:24 - mmengine - INFO - paramwise_options -- backbone.stage2.1.blocks.1.conv2.depthwise_conv.bn.weight:weight_decay=0.0
2025/05/12 18:18:24 - mmengine - INFO - paramwise_options -- backbone.stage2.1.blocks.1.conv2.depthwise_conv.bn.bias:weight_decay=0.0
2025/05/12 18:18:24 - mmengine - INFO - paramwise_options -- backbone.stage2.1.blocks.1.conv2.pointwise_conv.bn.weight:weight_decay=0.0
2025/05/12 18:18:24 - mmengine - INFO - paramwise_options -- backbone.stage2.1.blocks.1.conv2.pointwise_conv.bn.bias:weight_decay=0.0
2025/05/12 18:18:24 - mmengine - INFO - paramwise_options -- backbone.stage2.1.blocks.2.conv1.bn.weight:weight_decay=0.0
2025/05/12 18:18:24 - mmengine - INFO - paramwise_options -- backbone.stage2.1.blocks.2.conv1.bn.bias:weight_decay=0.0
2025/05/12 18:18:24 - mmengine - INFO - paramwise_options -- backbone.stage2.1.blocks.2.conv2.depthwise_conv.bn.weight:weight_decay=0.0
2025/05/12 18:18:24 - mmengine - INFO - paramwise_options -- backbone.stage2.1.blocks.2.conv2.depthwise_conv.bn.bias:weight_decay=0.0
2025/05/12 18:18:24 - mmengine - INFO - paramwise_options -- backbone.stage2.1.blocks.2.conv2.pointwise_conv.bn.weight:weight_decay=0.0
2025/05/12 18:18:24 - mmengine - INFO - paramwise_options -- backbone.stage2.1.blocks.2.conv2.pointwise_conv.bn.bias:weight_decay=0.0
2025/05/12 18:18:24 - mmengine - INFO - paramwise_options -- backbone.stage2.1.blocks.3.conv1.bn.weight:weight_decay=0.0
2025/05/12 18:18:24 - mmengine - INFO - paramwise_options -- backbone.stage2.1.blocks.3.conv1.bn.bias:weight_decay=0.0
2025/05/12 18:18:24 - mmengine - INFO - paramwise_options -- backbone.stage2.1.blocks.3.conv2.depthwise_conv.bn.weight:weight_decay=0.0
2025/05/12 18:18:24 - mmengine - INFO - paramwise_options -- backbone.stage2.1.blocks.3.conv2.depthwise_conv.bn.bias:weight_decay=0.0
2025/05/12 18:18:24 - mmengine - INFO - paramwise_options -- backbone.stage2.1.blocks.3.conv2.pointwise_conv.bn.weight:weight_decay=0.0
2025/05/12 18:18:24 - mmengine - INFO - paramwise_options -- backbone.stage2.1.blocks.3.conv2.pointwise_conv.bn.bias:weight_decay=0.0
2025/05/12 18:18:24 - mmengine - INFO - paramwise_options -- backbone.stage2.1.attention.fc.bias:weight_decay=0.0
2025/05/12 18:18:24 - mmengine - INFO - paramwise_options -- backbone.stage3.0.bn.weight:weight_decay=0.0
2025/05/12 18:18:24 - mmengine - INFO - paramwise_options -- backbone.stage3.0.bn.bias:weight_decay=0.0
2025/05/12 18:18:24 - mmengine - INFO - paramwise_options -- backbone.stage3.1.main_conv.bn.weight:weight_decay=0.0
2025/05/12 18:18:24 - mmengine - INFO - paramwise_options -- backbone.stage3.1.main_conv.bn.bias:weight_decay=0.0
2025/05/12 18:18:24 - mmengine - INFO - paramwise_options -- backbone.stage3.1.short_conv.bn.weight:weight_decay=0.0
2025/05/12 18:18:24 - mmengine - INFO - paramwise_options -- backbone.stage3.1.short_conv.bn.bias:weight_decay=0.0
2025/05/12 18:18:24 - mmengine - INFO - paramwise_options -- backbone.stage3.1.final_conv.bn.weight:weight_decay=0.0
2025/05/12 18:18:24 - mmengine - INFO - paramwise_options -- backbone.stage3.1.final_conv.bn.bias:weight_decay=0.0
2025/05/12 18:18:24 - mmengine - INFO - paramwise_options -- backbone.stage3.1.blocks.0.conv1.bn.weight:weight_decay=0.0
2025/05/12 18:18:24 - mmengine - INFO - paramwise_options -- backbone.stage3.1.blocks.0.conv1.bn.bias:weight_decay=0.0
2025/05/12 18:18:24 - mmengine - INFO - paramwise_options -- backbone.stage3.1.blocks.0.conv2.depthwise_conv.bn.weight:weight_decay=0.0
2025/05/12 18:18:24 - mmengine - INFO - paramwise_options -- backbone.stage3.1.blocks.0.conv2.depthwise_conv.bn.bias:weight_decay=0.0
2025/05/12 18:18:24 - mmengine - INFO - paramwise_options -- backbone.stage3.1.blocks.0.conv2.pointwise_conv.bn.weight:weight_decay=0.0
2025/05/12 18:18:24 - mmengine - INFO - paramwise_options -- backbone.stage3.1.blocks.0.conv2.pointwise_conv.bn.bias:weight_decay=0.0
2025/05/12 18:18:24 - mmengine - INFO - paramwise_options -- backbone.stage3.1.blocks.1.conv1.bn.weight:weight_decay=0.0
2025/05/12 18:18:24 - mmengine - INFO - paramwise_options -- backbone.stage3.1.blocks.1.conv1.bn.bias:weight_decay=0.0
2025/05/12 18:18:24 - mmengine - INFO - paramwise_options -- backbone.stage3.1.blocks.1.conv2.depthwise_conv.bn.weight:weight_decay=0.0
2025/05/12 18:18:24 - mmengine - INFO - paramwise_options -- backbone.stage3.1.blocks.1.conv2.depthwise_conv.bn.bias:weight_decay=0.0
2025/05/12 18:18:24 - mmengine - INFO - paramwise_options -- backbone.stage3.1.blocks.1.conv2.pointwise_conv.bn.weight:weight_decay=0.0
2025/05/12 18:18:24 - mmengine - INFO - paramwise_options -- backbone.stage3.1.blocks.1.conv2.pointwise_conv.bn.bias:weight_decay=0.0
2025/05/12 18:18:24 - mmengine - INFO - paramwise_options -- backbone.stage3.1.blocks.2.conv1.bn.weight:weight_decay=0.0
2025/05/12 18:18:24 - mmengine - INFO - paramwise_options -- backbone.stage3.1.blocks.2.conv1.bn.bias:weight_decay=0.0
2025/05/12 18:18:24 - mmengine - INFO - paramwise_options -- backbone.stage3.1.blocks.2.conv2.depthwise_conv.bn.weight:weight_decay=0.0
2025/05/12 18:18:24 - mmengine - INFO - paramwise_options -- backbone.stage3.1.blocks.2.conv2.depthwise_conv.bn.bias:weight_decay=0.0
2025/05/12 18:18:24 - mmengine - INFO - paramwise_options -- backbone.stage3.1.blocks.2.conv2.pointwise_conv.bn.weight:weight_decay=0.0
2025/05/12 18:18:24 - mmengine - INFO - paramwise_options -- backbone.stage3.1.blocks.2.conv2.pointwise_conv.bn.bias:weight_decay=0.0
2025/05/12 18:18:24 - mmengine - INFO - paramwise_options -- backbone.stage3.1.blocks.3.conv1.bn.weight:weight_decay=0.0
2025/05/12 18:18:24 - mmengine - INFO - paramwise_options -- backbone.stage3.1.blocks.3.conv1.bn.bias:weight_decay=0.0
2025/05/12 18:18:24 - mmengine - INFO - paramwise_options -- backbone.stage3.1.blocks.3.conv2.depthwise_conv.bn.weight:weight_decay=0.0
2025/05/12 18:18:24 - mmengine - INFO - paramwise_options -- backbone.stage3.1.blocks.3.conv2.depthwise_conv.bn.bias:weight_decay=0.0
2025/05/12 18:18:24 - mmengine - INFO - paramwise_options -- backbone.stage3.1.blocks.3.conv2.pointwise_conv.bn.weight:weight_decay=0.0
2025/05/12 18:18:24 - mmengine - INFO - paramwise_options -- backbone.stage3.1.blocks.3.conv2.pointwise_conv.bn.bias:weight_decay=0.0
2025/05/12 18:18:24 - mmengine - INFO - paramwise_options -- backbone.stage3.1.attention.fc.bias:weight_decay=0.0
2025/05/12 18:18:24 - mmengine - INFO - paramwise_options -- backbone.stage4.0.bn.weight:weight_decay=0.0
2025/05/12 18:18:24 - mmengine - INFO - paramwise_options -- backbone.stage4.0.bn.bias:weight_decay=0.0
2025/05/12 18:18:24 - mmengine - INFO - paramwise_options -- backbone.stage4.1.conv1.bn.weight:weight_decay=0.0
2025/05/12 18:18:24 - mmengine - INFO - paramwise_options -- backbone.stage4.1.conv1.bn.bias:weight_decay=0.0
2025/05/12 18:18:24 - mmengine - INFO - paramwise_options -- backbone.stage4.1.conv2.bn.weight:weight_decay=0.0
2025/05/12 18:18:24 - mmengine - INFO - paramwise_options -- backbone.stage4.1.conv2.bn.bias:weight_decay=0.0
2025/05/12 18:18:24 - mmengine - INFO - paramwise_options -- backbone.stage4.2.main_conv.bn.weight:weight_decay=0.0
2025/05/12 18:18:24 - mmengine - INFO - paramwise_options -- backbone.stage4.2.main_conv.bn.bias:weight_decay=0.0
2025/05/12 18:18:24 - mmengine - INFO - paramwise_options -- backbone.stage4.2.short_conv.bn.weight:weight_decay=0.0
2025/05/12 18:18:24 - mmengine - INFO - paramwise_options -- backbone.stage4.2.short_conv.bn.bias:weight_decay=0.0
2025/05/12 18:18:24 - mmengine - INFO - paramwise_options -- backbone.stage4.2.final_conv.bn.weight:weight_decay=0.0
2025/05/12 18:18:24 - mmengine - INFO - paramwise_options -- backbone.stage4.2.final_conv.bn.bias:weight_decay=0.0
2025/05/12 18:18:24 - mmengine - INFO - paramwise_options -- backbone.stage4.2.blocks.0.conv1.bn.weight:weight_decay=0.0
2025/05/12 18:18:24 - mmengine - INFO - paramwise_options -- backbone.stage4.2.blocks.0.conv1.bn.bias:weight_decay=0.0
2025/05/12 18:18:24 - mmengine - INFO - paramwise_options -- backbone.stage4.2.blocks.0.conv2.depthwise_conv.bn.weight:weight_decay=0.0
2025/05/12 18:18:24 - mmengine - INFO - paramwise_options -- backbone.stage4.2.blocks.0.conv2.depthwise_conv.bn.bias:weight_decay=0.0
2025/05/12 18:18:24 - mmengine - INFO - paramwise_options -- backbone.stage4.2.blocks.0.conv2.pointwise_conv.bn.weight:weight_decay=0.0
2025/05/12 18:18:24 - mmengine - INFO - paramwise_options -- backbone.stage4.2.blocks.0.conv2.pointwise_conv.bn.bias:weight_decay=0.0
2025/05/12 18:18:24 - mmengine - INFO - paramwise_options -- backbone.stage4.2.blocks.1.conv1.bn.weight:weight_decay=0.0
2025/05/12 18:18:24 - mmengine - INFO - paramwise_options -- backbone.stage4.2.blocks.1.conv1.bn.bias:weight_decay=0.0
2025/05/12 18:18:24 - mmengine - INFO - paramwise_options -- backbone.stage4.2.blocks.1.conv2.depthwise_conv.bn.weight:weight_decay=0.0
2025/05/12 18:18:24 - mmengine - INFO - paramwise_options -- backbone.stage4.2.blocks.1.conv2.depthwise_conv.bn.bias:weight_decay=0.0
2025/05/12 18:18:24 - mmengine - INFO - paramwise_options -- backbone.stage4.2.blocks.1.conv2.pointwise_conv.bn.weight:weight_decay=0.0
2025/05/12 18:18:24 - mmengine - INFO - paramwise_options -- backbone.stage4.2.blocks.1.conv2.pointwise_conv.bn.bias:weight_decay=0.0
2025/05/12 18:18:24 - mmengine - INFO - paramwise_options -- backbone.stage4.2.attention.fc.bias:weight_decay=0.0
2025/05/12 18:18:24 - mmengine - INFO - paramwise_options -- neck.reduce_layers.0.bn.weight:weight_decay=0.0
2025/05/12 18:18:24 - mmengine - INFO - paramwise_options -- neck.reduce_layers.0.bn.bias:weight_decay=0.0
2025/05/12 18:18:24 - mmengine - INFO - paramwise_options -- neck.reduce_layers.1.bn.weight:weight_decay=0.0
2025/05/12 18:18:24 - mmengine - INFO - paramwise_options -- neck.reduce_layers.1.bn.bias:weight_decay=0.0
2025/05/12 18:18:24 - mmengine - INFO - paramwise_options -- neck.top_down_blocks.0.main_conv.bn.weight:weight_decay=0.0
2025/05/12 18:18:24 - mmengine - INFO - paramwise_options -- neck.top_down_blocks.0.main_conv.bn.bias:weight_decay=0.0
2025/05/12 18:18:24 - mmengine - INFO - paramwise_options -- neck.top_down_blocks.0.short_conv.bn.weight:weight_decay=0.0
2025/05/12 18:18:24 - mmengine - INFO - paramwise_options -- neck.top_down_blocks.0.short_conv.bn.bias:weight_decay=0.0
2025/05/12 18:18:24 - mmengine - INFO - paramwise_options -- neck.top_down_blocks.0.final_conv.bn.weight:weight_decay=0.0
2025/05/12 18:18:24 - mmengine - INFO - paramwise_options -- neck.top_down_blocks.0.final_conv.bn.bias:weight_decay=0.0
2025/05/12 18:18:24 - mmengine - INFO - paramwise_options -- neck.top_down_blocks.0.blocks.0.conv1.bn.weight:weight_decay=0.0
2025/05/12 18:18:24 - mmengine - INFO - paramwise_options -- neck.top_down_blocks.0.blocks.0.conv1.bn.bias:weight_decay=0.0
2025/05/12 18:18:24 - mmengine - INFO - paramwise_options -- neck.top_down_blocks.0.blocks.0.conv2.depthwise_conv.bn.weight:weight_decay=0.0
2025/05/12 18:18:24 - mmengine - INFO - paramwise_options -- neck.top_down_blocks.0.blocks.0.conv2.depthwise_conv.bn.bias:weight_decay=0.0
2025/05/12 18:18:24 - mmengine - INFO - paramwise_options -- neck.top_down_blocks.0.blocks.0.conv2.pointwise_conv.bn.weight:weight_decay=0.0
2025/05/12 18:18:24 - mmengine - INFO - paramwise_options -- neck.top_down_blocks.0.blocks.0.conv2.pointwise_conv.bn.bias:weight_decay=0.0
2025/05/12 18:18:24 - mmengine - INFO - paramwise_options -- neck.top_down_blocks.0.blocks.1.conv1.bn.weight:weight_decay=0.0
2025/05/12 18:18:24 - mmengine - INFO - paramwise_options -- neck.top_down_blocks.0.blocks.1.conv1.bn.bias:weight_decay=0.0
2025/05/12 18:18:24 - mmengine - INFO - paramwise_options -- neck.top_down_blocks.0.blocks.1.conv2.depthwise_conv.bn.weight:weight_decay=0.0
2025/05/12 18:18:24 - mmengine - INFO - paramwise_options -- neck.top_down_blocks.0.blocks.1.conv2.depthwise_conv.bn.bias:weight_decay=0.0
2025/05/12 18:18:24 - mmengine - INFO - paramwise_options -- neck.top_down_blocks.0.blocks.1.conv2.pointwise_conv.bn.weight:weight_decay=0.0
2025/05/12 18:18:24 - mmengine - INFO - paramwise_options -- neck.top_down_blocks.0.blocks.1.conv2.pointwise_conv.bn.bias:weight_decay=0.0
2025/05/12 18:18:24 - mmengine - INFO - paramwise_options -- neck.top_down_blocks.1.main_conv.bn.weight:weight_decay=0.0
2025/05/12 18:18:24 - mmengine - INFO - paramwise_options -- neck.top_down_blocks.1.main_conv.bn.bias:weight_decay=0.0
2025/05/12 18:18:24 - mmengine - INFO - paramwise_options -- neck.top_down_blocks.1.short_conv.bn.weight:weight_decay=0.0
2025/05/12 18:18:24 - mmengine - INFO - paramwise_options -- neck.top_down_blocks.1.short_conv.bn.bias:weight_decay=0.0
2025/05/12 18:18:24 - mmengine - INFO - paramwise_options -- neck.top_down_blocks.1.final_conv.bn.weight:weight_decay=0.0
2025/05/12 18:18:24 - mmengine - INFO - paramwise_options -- neck.top_down_blocks.1.final_conv.bn.bias:weight_decay=0.0
2025/05/12 18:18:24 - mmengine - INFO - paramwise_options -- neck.top_down_blocks.1.blocks.0.conv1.bn.weight:weight_decay=0.0
2025/05/12 18:18:24 - mmengine - INFO - paramwise_options -- neck.top_down_blocks.1.blocks.0.conv1.bn.bias:weight_decay=0.0
2025/05/12 18:18:24 - mmengine - INFO - paramwise_options -- neck.top_down_blocks.1.blocks.0.conv2.depthwise_conv.bn.weight:weight_decay=0.0
2025/05/12 18:18:24 - mmengine - INFO - paramwise_options -- neck.top_down_blocks.1.blocks.0.conv2.depthwise_conv.bn.bias:weight_decay=0.0
2025/05/12 18:18:24 - mmengine - INFO - paramwise_options -- neck.top_down_blocks.1.blocks.0.conv2.pointwise_conv.bn.weight:weight_decay=0.0
2025/05/12 18:18:24 - mmengine - INFO - paramwise_options -- neck.top_down_blocks.1.blocks.0.conv2.pointwise_conv.bn.bias:weight_decay=0.0
2025/05/12 18:18:24 - mmengine - INFO - paramwise_options -- neck.top_down_blocks.1.blocks.1.conv1.bn.weight:weight_decay=0.0
2025/05/12 18:18:24 - mmengine - INFO - paramwise_options -- neck.top_down_blocks.1.blocks.1.conv1.bn.bias:weight_decay=0.0
2025/05/12 18:18:24 - mmengine - INFO - paramwise_options -- neck.top_down_blocks.1.blocks.1.conv2.depthwise_conv.bn.weight:weight_decay=0.0
2025/05/12 18:18:24 - mmengine - INFO - paramwise_options -- neck.top_down_blocks.1.blocks.1.conv2.depthwise_conv.bn.bias:weight_decay=0.0
2025/05/12 18:18:24 - mmengine - INFO - paramwise_options -- neck.top_down_blocks.1.blocks.1.conv2.pointwise_conv.bn.weight:weight_decay=0.0
2025/05/12 18:18:24 - mmengine - INFO - paramwise_options -- neck.top_down_blocks.1.blocks.1.conv2.pointwise_conv.bn.bias:weight_decay=0.0
2025/05/12 18:18:24 - mmengine - INFO - paramwise_options -- neck.downsamples.0.bn.weight:weight_decay=0.0
2025/05/12 18:18:24 - mmengine - INFO - paramwise_options -- neck.downsamples.0.bn.bias:weight_decay=0.0
2025/05/12 18:18:24 - mmengine - INFO - paramwise_options -- neck.downsamples.1.bn.weight:weight_decay=0.0
2025/05/12 18:18:24 - mmengine - INFO - paramwise_options -- neck.downsamples.1.bn.bias:weight_decay=0.0
2025/05/12 18:18:24 - mmengine - INFO - paramwise_options -- neck.bottom_up_blocks.0.main_conv.bn.weight:weight_decay=0.0
2025/05/12 18:18:24 - mmengine - INFO - paramwise_options -- neck.bottom_up_blocks.0.main_conv.bn.bias:weight_decay=0.0
2025/05/12 18:18:24 - mmengine - INFO - paramwise_options -- neck.bottom_up_blocks.0.short_conv.bn.weight:weight_decay=0.0
2025/05/12 18:18:24 - mmengine - INFO - paramwise_options -- neck.bottom_up_blocks.0.short_conv.bn.bias:weight_decay=0.0
2025/05/12 18:18:24 - mmengine - INFO - paramwise_options -- neck.bottom_up_blocks.0.final_conv.bn.weight:weight_decay=0.0
2025/05/12 18:18:24 - mmengine - INFO - paramwise_options -- neck.bottom_up_blocks.0.final_conv.bn.bias:weight_decay=0.0
2025/05/12 18:18:24 - mmengine - INFO - paramwise_options -- neck.bottom_up_blocks.0.blocks.0.conv1.bn.weight:weight_decay=0.0
2025/05/12 18:18:24 - mmengine - INFO - paramwise_options -- neck.bottom_up_blocks.0.blocks.0.conv1.bn.bias:weight_decay=0.0
2025/05/12 18:18:24 - mmengine - INFO - paramwise_options -- neck.bottom_up_blocks.0.blocks.0.conv2.depthwise_conv.bn.weight:weight_decay=0.0
2025/05/12 18:18:24 - mmengine - INFO - paramwise_options -- neck.bottom_up_blocks.0.blocks.0.conv2.depthwise_conv.bn.bias:weight_decay=0.0
2025/05/12 18:18:24 - mmengine - INFO - paramwise_options -- neck.bottom_up_blocks.0.blocks.0.conv2.pointwise_conv.bn.weight:weight_decay=0.0
2025/05/12 18:18:24 - mmengine - INFO - paramwise_options -- neck.bottom_up_blocks.0.blocks.0.conv2.pointwise_conv.bn.bias:weight_decay=0.0
2025/05/12 18:18:24 - mmengine - INFO - paramwise_options -- neck.bottom_up_blocks.0.blocks.1.conv1.bn.weight:weight_decay=0.0
2025/05/12 18:18:24 - mmengine - INFO - paramwise_options -- neck.bottom_up_blocks.0.blocks.1.conv1.bn.bias:weight_decay=0.0
2025/05/12 18:18:24 - mmengine - INFO - paramwise_options -- neck.bottom_up_blocks.0.blocks.1.conv2.depthwise_conv.bn.weight:weight_decay=0.0
2025/05/12 18:18:24 - mmengine - INFO - paramwise_options -- neck.bottom_up_blocks.0.blocks.1.conv2.depthwise_conv.bn.bias:weight_decay=0.0
2025/05/12 18:18:24 - mmengine - INFO - paramwise_options -- neck.bottom_up_blocks.0.blocks.1.conv2.pointwise_conv.bn.weight:weight_decay=0.0
2025/05/12 18:18:24 - mmengine - INFO - paramwise_options -- neck.bottom_up_blocks.0.blocks.1.conv2.pointwise_conv.bn.bias:weight_decay=0.0
2025/05/12 18:18:24 - mmengine - INFO - paramwise_options -- neck.bottom_up_blocks.1.main_conv.bn.weight:weight_decay=0.0
2025/05/12 18:18:24 - mmengine - INFO - paramwise_options -- neck.bottom_up_blocks.1.main_conv.bn.bias:weight_decay=0.0
2025/05/12 18:18:24 - mmengine - INFO - paramwise_options -- neck.bottom_up_blocks.1.short_conv.bn.weight:weight_decay=0.0
2025/05/12 18:18:24 - mmengine - INFO - paramwise_options -- neck.bottom_up_blocks.1.short_conv.bn.bias:weight_decay=0.0
2025/05/12 18:18:24 - mmengine - INFO - paramwise_options -- neck.bottom_up_blocks.1.final_conv.bn.weight:weight_decay=0.0
2025/05/12 18:18:24 - mmengine - INFO - paramwise_options -- neck.bottom_up_blocks.1.final_conv.bn.bias:weight_decay=0.0
2025/05/12 18:18:24 - mmengine - INFO - paramwise_options -- neck.bottom_up_blocks.1.blocks.0.conv1.bn.weight:weight_decay=0.0
2025/05/12 18:18:24 - mmengine - INFO - paramwise_options -- neck.bottom_up_blocks.1.blocks.0.conv1.bn.bias:weight_decay=0.0
2025/05/12 18:18:24 - mmengine - INFO - paramwise_options -- neck.bottom_up_blocks.1.blocks.0.conv2.depthwise_conv.bn.weight:weight_decay=0.0
2025/05/12 18:18:24 - mmengine - INFO - paramwise_options -- neck.bottom_up_blocks.1.blocks.0.conv2.depthwise_conv.bn.bias:weight_decay=0.0
2025/05/12 18:18:24 - mmengine - INFO - paramwise_options -- neck.bottom_up_blocks.1.blocks.0.conv2.pointwise_conv.bn.weight:weight_decay=0.0
2025/05/12 18:18:24 - mmengine - INFO - paramwise_options -- neck.bottom_up_blocks.1.blocks.0.conv2.pointwise_conv.bn.bias:weight_decay=0.0
2025/05/12 18:18:24 - mmengine - INFO - paramwise_options -- neck.bottom_up_blocks.1.blocks.1.conv1.bn.weight:weight_decay=0.0
2025/05/12 18:18:24 - mmengine - INFO - paramwise_options -- neck.bottom_up_blocks.1.blocks.1.conv1.bn.bias:weight_decay=0.0
2025/05/12 18:18:24 - mmengine - INFO - paramwise_options -- neck.bottom_up_blocks.1.blocks.1.conv2.depthwise_conv.bn.weight:weight_decay=0.0
2025/05/12 18:18:24 - mmengine - INFO - paramwise_options -- neck.bottom_up_blocks.1.blocks.1.conv2.depthwise_conv.bn.bias:weight_decay=0.0
2025/05/12 18:18:24 - mmengine - INFO - paramwise_options -- neck.bottom_up_blocks.1.blocks.1.conv2.pointwise_conv.bn.weight:weight_decay=0.0
2025/05/12 18:18:24 - mmengine - INFO - paramwise_options -- neck.bottom_up_blocks.1.blocks.1.conv2.pointwise_conv.bn.bias:weight_decay=0.0
2025/05/12 18:18:24 - mmengine - INFO - paramwise_options -- neck.out_convs.0.bn.weight:weight_decay=0.0
2025/05/12 18:18:24 - mmengine - INFO - paramwise_options -- neck.out_convs.0.bn.bias:weight_decay=0.0
2025/05/12 18:18:24 - mmengine - INFO - paramwise_options -- neck.out_convs.1.bn.weight:weight_decay=0.0
2025/05/12 18:18:24 - mmengine - INFO - paramwise_options -- neck.out_convs.1.bn.bias:weight_decay=0.0
2025/05/12 18:18:24 - mmengine - INFO - paramwise_options -- neck.out_convs.2.bn.weight:weight_decay=0.0
2025/05/12 18:18:24 - mmengine - INFO - paramwise_options -- neck.out_convs.2.bn.bias:weight_decay=0.0
2025/05/12 18:18:24 - mmengine - INFO - paramwise_options -- bbox_head.cls_convs.0.0.bn.weight:weight_decay=0.0
2025/05/12 18:18:24 - mmengine - INFO - paramwise_options -- bbox_head.cls_convs.0.0.bn.bias:weight_decay=0.0
2025/05/12 18:18:24 - mmengine - INFO - paramwise_options -- bbox_head.cls_convs.0.1.bn.weight:weight_decay=0.0
2025/05/12 18:18:24 - mmengine - INFO - paramwise_options -- bbox_head.cls_convs.0.1.bn.bias:weight_decay=0.0
2025/05/12 18:18:24 - mmengine - WARNING - bbox_head.cls_convs.1.0.conv is duplicate. It is skipped since bypass_duplicate=True
2025/05/12 18:18:24 - mmengine - INFO - paramwise_options -- bbox_head.cls_convs.1.0.bn.weight:weight_decay=0.0
2025/05/12 18:18:24 - mmengine - INFO - paramwise_options -- bbox_head.cls_convs.1.0.bn.bias:weight_decay=0.0
2025/05/12 18:18:24 - mmengine - WARNING - bbox_head.cls_convs.1.1.conv is duplicate. It is skipped since bypass_duplicate=True
2025/05/12 18:18:24 - mmengine - INFO - paramwise_options -- bbox_head.cls_convs.1.1.bn.weight:weight_decay=0.0
2025/05/12 18:18:24 - mmengine - INFO - paramwise_options -- bbox_head.cls_convs.1.1.bn.bias:weight_decay=0.0
2025/05/12 18:18:24 - mmengine - WARNING - bbox_head.cls_convs.2.0.conv is duplicate. It is skipped since bypass_duplicate=True
2025/05/12 18:18:24 - mmengine - INFO - paramwise_options -- bbox_head.cls_convs.2.0.bn.weight:weight_decay=0.0
2025/05/12 18:18:24 - mmengine - INFO - paramwise_options -- bbox_head.cls_convs.2.0.bn.bias:weight_decay=0.0
2025/05/12 18:18:24 - mmengine - WARNING - bbox_head.cls_convs.2.1.conv is duplicate. It is skipped since bypass_duplicate=True
2025/05/12 18:18:24 - mmengine - INFO - paramwise_options -- bbox_head.cls_convs.2.1.bn.weight:weight_decay=0.0
2025/05/12 18:18:24 - mmengine - INFO - paramwise_options -- bbox_head.cls_convs.2.1.bn.bias:weight_decay=0.0
2025/05/12 18:18:24 - mmengine - INFO - paramwise_options -- bbox_head.reg_convs.0.0.bn.weight:weight_decay=0.0
2025/05/12 18:18:24 - mmengine - INFO - paramwise_options -- bbox_head.reg_convs.0.0.bn.bias:weight_decay=0.0
2025/05/12 18:18:24 - mmengine - INFO - paramwise_options -- bbox_head.reg_convs.0.1.bn.weight:weight_decay=0.0
2025/05/12 18:18:24 - mmengine - INFO - paramwise_options -- bbox_head.reg_convs.0.1.bn.bias:weight_decay=0.0
2025/05/12 18:18:24 - mmengine - WARNING - bbox_head.reg_convs.1.0.conv is duplicate. It is skipped since bypass_duplicate=True
2025/05/12 18:18:24 - mmengine - INFO - paramwise_options -- bbox_head.reg_convs.1.0.bn.weight:weight_decay=0.0
2025/05/12 18:18:24 - mmengine - INFO - paramwise_options -- bbox_head.reg_convs.1.0.bn.bias:weight_decay=0.0
2025/05/12 18:18:24 - mmengine - WARNING - bbox_head.reg_convs.1.1.conv is duplicate. It is skipped since bypass_duplicate=True
2025/05/12 18:18:24 - mmengine - INFO - paramwise_options -- bbox_head.reg_convs.1.1.bn.weight:weight_decay=0.0
2025/05/12 18:18:24 - mmengine - INFO - paramwise_options -- bbox_head.reg_convs.1.1.bn.bias:weight_decay=0.0
2025/05/12 18:18:24 - mmengine - WARNING - bbox_head.reg_convs.2.0.conv is duplicate. It is skipped since bypass_duplicate=True
2025/05/12 18:18:24 - mmengine - INFO - paramwise_options -- bbox_head.reg_convs.2.0.bn.weight:weight_decay=0.0
2025/05/12 18:18:24 - mmengine - INFO - paramwise_options -- bbox_head.reg_convs.2.0.bn.bias:weight_decay=0.0
2025/05/12 18:18:24 - mmengine - WARNING - bbox_head.reg_convs.2.1.conv is duplicate. It is skipped since bypass_duplicate=True
2025/05/12 18:18:24 - mmengine - INFO - paramwise_options -- bbox_head.reg_convs.2.1.bn.weight:weight_decay=0.0
2025/05/12 18:18:24 - mmengine - INFO - paramwise_options -- bbox_head.reg_convs.2.1.bn.bias:weight_decay=0.0
2025/05/12 18:18:24 - mmengine - INFO - paramwise_options -- bbox_head.rtm_cls.0.bias:weight_decay=0.0
2025/05/12 18:18:24 - mmengine - INFO - paramwise_options -- bbox_head.rtm_cls.1.bias:weight_decay=0.0
2025/05/12 18:18:24 - mmengine - INFO - paramwise_options -- bbox_head.rtm_cls.2.bias:weight_decay=0.0
2025/05/12 18:18:24 - mmengine - INFO - paramwise_options -- bbox_head.rtm_reg.0.bias:weight_decay=0.0
2025/05/12 18:18:24 - mmengine - INFO - paramwise_options -- bbox_head.rtm_reg.1.bias:weight_decay=0.0
2025/05/12 18:18:24 - mmengine - INFO - paramwise_options -- bbox_head.rtm_reg.2.bias:weight_decay=0.0
Name of parameter - Initialization information

backbone.stem.0.conv.weight - torch.Size([24, 3, 3, 3]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stem.0.bn.weight - torch.Size([24]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stem.0.bn.bias - torch.Size([24]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stem.1.conv.weight - torch.Size([24, 24, 3, 3]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stem.1.bn.weight - torch.Size([24]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stem.1.bn.bias - torch.Size([24]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stem.2.conv.weight - torch.Size([48, 24, 3, 3]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stem.2.bn.weight - torch.Size([48]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stem.2.bn.bias - torch.Size([48]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage1.0.conv.weight - torch.Size([96, 48, 3, 3]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage1.0.bn.weight - torch.Size([96]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage1.0.bn.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage1.1.main_conv.conv.weight - torch.Size([48, 96, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage1.1.main_conv.bn.weight - torch.Size([48]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage1.1.main_conv.bn.bias - torch.Size([48]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage1.1.short_conv.conv.weight - torch.Size([48, 96, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage1.1.short_conv.bn.weight - torch.Size([48]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage1.1.short_conv.bn.bias - torch.Size([48]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage1.1.final_conv.conv.weight - torch.Size([96, 96, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage1.1.final_conv.bn.weight - torch.Size([96]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage1.1.final_conv.bn.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage1.1.blocks.0.conv1.conv.weight - torch.Size([48, 48, 3, 3]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage1.1.blocks.0.conv1.bn.weight - torch.Size([48]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage1.1.blocks.0.conv1.bn.bias - torch.Size([48]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage1.1.blocks.0.conv2.depthwise_conv.conv.weight - torch.Size([48, 1, 5, 5]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage1.1.blocks.0.conv2.depthwise_conv.bn.weight - torch.Size([48]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage1.1.blocks.0.conv2.depthwise_conv.bn.bias - torch.Size([48]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage1.1.blocks.0.conv2.pointwise_conv.conv.weight - torch.Size([48, 48, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage1.1.blocks.0.conv2.pointwise_conv.bn.weight - torch.Size([48]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage1.1.blocks.0.conv2.pointwise_conv.bn.bias - torch.Size([48]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage1.1.blocks.1.conv1.conv.weight - torch.Size([48, 48, 3, 3]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage1.1.blocks.1.conv1.bn.weight - torch.Size([48]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage1.1.blocks.1.conv1.bn.bias - torch.Size([48]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage1.1.blocks.1.conv2.depthwise_conv.conv.weight - torch.Size([48, 1, 5, 5]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage1.1.blocks.1.conv2.depthwise_conv.bn.weight - torch.Size([48]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage1.1.blocks.1.conv2.depthwise_conv.bn.bias - torch.Size([48]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage1.1.blocks.1.conv2.pointwise_conv.conv.weight - torch.Size([48, 48, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage1.1.blocks.1.conv2.pointwise_conv.bn.weight - torch.Size([48]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage1.1.blocks.1.conv2.pointwise_conv.bn.bias - torch.Size([48]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage1.1.attention.fc.weight - torch.Size([96, 96, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage1.1.attention.fc.bias - torch.Size([96]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage2.0.conv.weight - torch.Size([192, 96, 3, 3]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage2.0.bn.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage2.0.bn.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage2.1.main_conv.conv.weight - torch.Size([96, 192, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage2.1.main_conv.bn.weight - torch.Size([96]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage2.1.main_conv.bn.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage2.1.short_conv.conv.weight - torch.Size([96, 192, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage2.1.short_conv.bn.weight - torch.Size([96]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage2.1.short_conv.bn.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage2.1.final_conv.conv.weight - torch.Size([192, 192, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage2.1.final_conv.bn.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage2.1.final_conv.bn.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage2.1.blocks.0.conv1.conv.weight - torch.Size([96, 96, 3, 3]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage2.1.blocks.0.conv1.bn.weight - torch.Size([96]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage2.1.blocks.0.conv1.bn.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage2.1.blocks.0.conv2.depthwise_conv.conv.weight - torch.Size([96, 1, 5, 5]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage2.1.blocks.0.conv2.depthwise_conv.bn.weight - torch.Size([96]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage2.1.blocks.0.conv2.depthwise_conv.bn.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage2.1.blocks.0.conv2.pointwise_conv.conv.weight - torch.Size([96, 96, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage2.1.blocks.0.conv2.pointwise_conv.bn.weight - torch.Size([96]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage2.1.blocks.0.conv2.pointwise_conv.bn.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage2.1.blocks.1.conv1.conv.weight - torch.Size([96, 96, 3, 3]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage2.1.blocks.1.conv1.bn.weight - torch.Size([96]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage2.1.blocks.1.conv1.bn.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage2.1.blocks.1.conv2.depthwise_conv.conv.weight - torch.Size([96, 1, 5, 5]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage2.1.blocks.1.conv2.depthwise_conv.bn.weight - torch.Size([96]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage2.1.blocks.1.conv2.depthwise_conv.bn.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage2.1.blocks.1.conv2.pointwise_conv.conv.weight - torch.Size([96, 96, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage2.1.blocks.1.conv2.pointwise_conv.bn.weight - torch.Size([96]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage2.1.blocks.1.conv2.pointwise_conv.bn.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage2.1.blocks.2.conv1.conv.weight - torch.Size([96, 96, 3, 3]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage2.1.blocks.2.conv1.bn.weight - torch.Size([96]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage2.1.blocks.2.conv1.bn.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage2.1.blocks.2.conv2.depthwise_conv.conv.weight - torch.Size([96, 1, 5, 5]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage2.1.blocks.2.conv2.depthwise_conv.bn.weight - torch.Size([96]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage2.1.blocks.2.conv2.depthwise_conv.bn.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage2.1.blocks.2.conv2.pointwise_conv.conv.weight - torch.Size([96, 96, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage2.1.blocks.2.conv2.pointwise_conv.bn.weight - torch.Size([96]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage2.1.blocks.2.conv2.pointwise_conv.bn.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage2.1.blocks.3.conv1.conv.weight - torch.Size([96, 96, 3, 3]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage2.1.blocks.3.conv1.bn.weight - torch.Size([96]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage2.1.blocks.3.conv1.bn.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage2.1.blocks.3.conv2.depthwise_conv.conv.weight - torch.Size([96, 1, 5, 5]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage2.1.blocks.3.conv2.depthwise_conv.bn.weight - torch.Size([96]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage2.1.blocks.3.conv2.depthwise_conv.bn.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage2.1.blocks.3.conv2.pointwise_conv.conv.weight - torch.Size([96, 96, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage2.1.blocks.3.conv2.pointwise_conv.bn.weight - torch.Size([96]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage2.1.blocks.3.conv2.pointwise_conv.bn.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage2.1.attention.fc.weight - torch.Size([192, 192, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage2.1.attention.fc.bias - torch.Size([192]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage3.0.conv.weight - torch.Size([384, 192, 3, 3]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage3.0.bn.weight - torch.Size([384]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage3.0.bn.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage3.1.main_conv.conv.weight - torch.Size([192, 384, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage3.1.main_conv.bn.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage3.1.main_conv.bn.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage3.1.short_conv.conv.weight - torch.Size([192, 384, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage3.1.short_conv.bn.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage3.1.short_conv.bn.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage3.1.final_conv.conv.weight - torch.Size([384, 384, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage3.1.final_conv.bn.weight - torch.Size([384]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage3.1.final_conv.bn.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage3.1.blocks.0.conv1.conv.weight - torch.Size([192, 192, 3, 3]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage3.1.blocks.0.conv1.bn.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage3.1.blocks.0.conv1.bn.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage3.1.blocks.0.conv2.depthwise_conv.conv.weight - torch.Size([192, 1, 5, 5]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage3.1.blocks.0.conv2.depthwise_conv.bn.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage3.1.blocks.0.conv2.depthwise_conv.bn.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage3.1.blocks.0.conv2.pointwise_conv.conv.weight - torch.Size([192, 192, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage3.1.blocks.0.conv2.pointwise_conv.bn.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage3.1.blocks.0.conv2.pointwise_conv.bn.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage3.1.blocks.1.conv1.conv.weight - torch.Size([192, 192, 3, 3]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage3.1.blocks.1.conv1.bn.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage3.1.blocks.1.conv1.bn.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage3.1.blocks.1.conv2.depthwise_conv.conv.weight - torch.Size([192, 1, 5, 5]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage3.1.blocks.1.conv2.depthwise_conv.bn.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage3.1.blocks.1.conv2.depthwise_conv.bn.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage3.1.blocks.1.conv2.pointwise_conv.conv.weight - torch.Size([192, 192, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage3.1.blocks.1.conv2.pointwise_conv.bn.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage3.1.blocks.1.conv2.pointwise_conv.bn.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage3.1.blocks.2.conv1.conv.weight - torch.Size([192, 192, 3, 3]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage3.1.blocks.2.conv1.bn.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage3.1.blocks.2.conv1.bn.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage3.1.blocks.2.conv2.depthwise_conv.conv.weight - torch.Size([192, 1, 5, 5]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage3.1.blocks.2.conv2.depthwise_conv.bn.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage3.1.blocks.2.conv2.depthwise_conv.bn.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage3.1.blocks.2.conv2.pointwise_conv.conv.weight - torch.Size([192, 192, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage3.1.blocks.2.conv2.pointwise_conv.bn.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage3.1.blocks.2.conv2.pointwise_conv.bn.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage3.1.blocks.3.conv1.conv.weight - torch.Size([192, 192, 3, 3]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage3.1.blocks.3.conv1.bn.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage3.1.blocks.3.conv1.bn.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage3.1.blocks.3.conv2.depthwise_conv.conv.weight - torch.Size([192, 1, 5, 5]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage3.1.blocks.3.conv2.depthwise_conv.bn.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage3.1.blocks.3.conv2.depthwise_conv.bn.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage3.1.blocks.3.conv2.pointwise_conv.conv.weight - torch.Size([192, 192, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage3.1.blocks.3.conv2.pointwise_conv.bn.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage3.1.blocks.3.conv2.pointwise_conv.bn.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage3.1.attention.fc.weight - torch.Size([384, 384, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage3.1.attention.fc.bias - torch.Size([384]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage4.0.conv.weight - torch.Size([768, 384, 3, 3]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage4.0.bn.weight - torch.Size([768]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage4.0.bn.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage4.1.conv1.conv.weight - torch.Size([384, 768, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage4.1.conv1.bn.weight - torch.Size([384]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage4.1.conv1.bn.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage4.1.conv2.conv.weight - torch.Size([768, 1536, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage4.1.conv2.bn.weight - torch.Size([768]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage4.1.conv2.bn.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage4.2.main_conv.conv.weight - torch.Size([384, 768, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage4.2.main_conv.bn.weight - torch.Size([384]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage4.2.main_conv.bn.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage4.2.short_conv.conv.weight - torch.Size([384, 768, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage4.2.short_conv.bn.weight - torch.Size([384]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage4.2.short_conv.bn.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage4.2.final_conv.conv.weight - torch.Size([768, 768, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage4.2.final_conv.bn.weight - torch.Size([768]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage4.2.final_conv.bn.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage4.2.blocks.0.conv1.conv.weight - torch.Size([384, 384, 3, 3]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage4.2.blocks.0.conv1.bn.weight - torch.Size([384]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage4.2.blocks.0.conv1.bn.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage4.2.blocks.0.conv2.depthwise_conv.conv.weight - torch.Size([384, 1, 5, 5]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage4.2.blocks.0.conv2.depthwise_conv.bn.weight - torch.Size([384]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage4.2.blocks.0.conv2.depthwise_conv.bn.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage4.2.blocks.0.conv2.pointwise_conv.conv.weight - torch.Size([384, 384, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage4.2.blocks.0.conv2.pointwise_conv.bn.weight - torch.Size([384]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage4.2.blocks.0.conv2.pointwise_conv.bn.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage4.2.blocks.1.conv1.conv.weight - torch.Size([384, 384, 3, 3]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage4.2.blocks.1.conv1.bn.weight - torch.Size([384]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage4.2.blocks.1.conv1.bn.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage4.2.blocks.1.conv2.depthwise_conv.conv.weight - torch.Size([384, 1, 5, 5]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage4.2.blocks.1.conv2.depthwise_conv.bn.weight - torch.Size([384]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage4.2.blocks.1.conv2.depthwise_conv.bn.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage4.2.blocks.1.conv2.pointwise_conv.conv.weight - torch.Size([384, 384, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage4.2.blocks.1.conv2.pointwise_conv.bn.weight - torch.Size([384]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage4.2.blocks.1.conv2.pointwise_conv.bn.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of RTMDet  

backbone.stage4.2.attention.fc.weight - torch.Size([768, 768, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage4.2.attention.fc.bias - torch.Size([768]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

neck.reduce_layers.0.conv.weight - torch.Size([384, 768, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

neck.reduce_layers.0.bn.weight - torch.Size([384]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.reduce_layers.0.bn.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.reduce_layers.1.conv.weight - torch.Size([192, 384, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

neck.reduce_layers.1.bn.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.reduce_layers.1.bn.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.top_down_blocks.0.main_conv.conv.weight - torch.Size([192, 768, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

neck.top_down_blocks.0.main_conv.bn.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.top_down_blocks.0.main_conv.bn.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.top_down_blocks.0.short_conv.conv.weight - torch.Size([192, 768, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

neck.top_down_blocks.0.short_conv.bn.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.top_down_blocks.0.short_conv.bn.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.top_down_blocks.0.final_conv.conv.weight - torch.Size([384, 384, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

neck.top_down_blocks.0.final_conv.bn.weight - torch.Size([384]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.top_down_blocks.0.final_conv.bn.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.top_down_blocks.0.blocks.0.conv1.conv.weight - torch.Size([192, 192, 3, 3]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

neck.top_down_blocks.0.blocks.0.conv1.bn.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.top_down_blocks.0.blocks.0.conv1.bn.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.top_down_blocks.0.blocks.0.conv2.depthwise_conv.conv.weight - torch.Size([192, 1, 5, 5]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

neck.top_down_blocks.0.blocks.0.conv2.depthwise_conv.bn.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.top_down_blocks.0.blocks.0.conv2.depthwise_conv.bn.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.top_down_blocks.0.blocks.0.conv2.pointwise_conv.conv.weight - torch.Size([192, 192, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

neck.top_down_blocks.0.blocks.0.conv2.pointwise_conv.bn.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.top_down_blocks.0.blocks.0.conv2.pointwise_conv.bn.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.top_down_blocks.0.blocks.1.conv1.conv.weight - torch.Size([192, 192, 3, 3]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

neck.top_down_blocks.0.blocks.1.conv1.bn.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.top_down_blocks.0.blocks.1.conv1.bn.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.top_down_blocks.0.blocks.1.conv2.depthwise_conv.conv.weight - torch.Size([192, 1, 5, 5]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

neck.top_down_blocks.0.blocks.1.conv2.depthwise_conv.bn.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.top_down_blocks.0.blocks.1.conv2.depthwise_conv.bn.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.top_down_blocks.0.blocks.1.conv2.pointwise_conv.conv.weight - torch.Size([192, 192, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

neck.top_down_blocks.0.blocks.1.conv2.pointwise_conv.bn.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.top_down_blocks.0.blocks.1.conv2.pointwise_conv.bn.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.top_down_blocks.1.main_conv.conv.weight - torch.Size([96, 384, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

neck.top_down_blocks.1.main_conv.bn.weight - torch.Size([96]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.top_down_blocks.1.main_conv.bn.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.top_down_blocks.1.short_conv.conv.weight - torch.Size([96, 384, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

neck.top_down_blocks.1.short_conv.bn.weight - torch.Size([96]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.top_down_blocks.1.short_conv.bn.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.top_down_blocks.1.final_conv.conv.weight - torch.Size([192, 192, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

neck.top_down_blocks.1.final_conv.bn.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.top_down_blocks.1.final_conv.bn.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.top_down_blocks.1.blocks.0.conv1.conv.weight - torch.Size([96, 96, 3, 3]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

neck.top_down_blocks.1.blocks.0.conv1.bn.weight - torch.Size([96]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.top_down_blocks.1.blocks.0.conv1.bn.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.top_down_blocks.1.blocks.0.conv2.depthwise_conv.conv.weight - torch.Size([96, 1, 5, 5]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

neck.top_down_blocks.1.blocks.0.conv2.depthwise_conv.bn.weight - torch.Size([96]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.top_down_blocks.1.blocks.0.conv2.depthwise_conv.bn.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.top_down_blocks.1.blocks.0.conv2.pointwise_conv.conv.weight - torch.Size([96, 96, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

neck.top_down_blocks.1.blocks.0.conv2.pointwise_conv.bn.weight - torch.Size([96]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.top_down_blocks.1.blocks.0.conv2.pointwise_conv.bn.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.top_down_blocks.1.blocks.1.conv1.conv.weight - torch.Size([96, 96, 3, 3]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

neck.top_down_blocks.1.blocks.1.conv1.bn.weight - torch.Size([96]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.top_down_blocks.1.blocks.1.conv1.bn.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.top_down_blocks.1.blocks.1.conv2.depthwise_conv.conv.weight - torch.Size([96, 1, 5, 5]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

neck.top_down_blocks.1.blocks.1.conv2.depthwise_conv.bn.weight - torch.Size([96]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.top_down_blocks.1.blocks.1.conv2.depthwise_conv.bn.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.top_down_blocks.1.blocks.1.conv2.pointwise_conv.conv.weight - torch.Size([96, 96, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

neck.top_down_blocks.1.blocks.1.conv2.pointwise_conv.bn.weight - torch.Size([96]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.top_down_blocks.1.blocks.1.conv2.pointwise_conv.bn.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.downsamples.0.conv.weight - torch.Size([192, 192, 3, 3]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

neck.downsamples.0.bn.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.downsamples.0.bn.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.downsamples.1.conv.weight - torch.Size([384, 384, 3, 3]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

neck.downsamples.1.bn.weight - torch.Size([384]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.downsamples.1.bn.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.bottom_up_blocks.0.main_conv.conv.weight - torch.Size([192, 384, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

neck.bottom_up_blocks.0.main_conv.bn.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.bottom_up_blocks.0.main_conv.bn.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.bottom_up_blocks.0.short_conv.conv.weight - torch.Size([192, 384, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

neck.bottom_up_blocks.0.short_conv.bn.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.bottom_up_blocks.0.short_conv.bn.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.bottom_up_blocks.0.final_conv.conv.weight - torch.Size([384, 384, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

neck.bottom_up_blocks.0.final_conv.bn.weight - torch.Size([384]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.bottom_up_blocks.0.final_conv.bn.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.bottom_up_blocks.0.blocks.0.conv1.conv.weight - torch.Size([192, 192, 3, 3]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

neck.bottom_up_blocks.0.blocks.0.conv1.bn.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.bottom_up_blocks.0.blocks.0.conv1.bn.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.bottom_up_blocks.0.blocks.0.conv2.depthwise_conv.conv.weight - torch.Size([192, 1, 5, 5]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

neck.bottom_up_blocks.0.blocks.0.conv2.depthwise_conv.bn.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.bottom_up_blocks.0.blocks.0.conv2.depthwise_conv.bn.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.bottom_up_blocks.0.blocks.0.conv2.pointwise_conv.conv.weight - torch.Size([192, 192, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

neck.bottom_up_blocks.0.blocks.0.conv2.pointwise_conv.bn.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.bottom_up_blocks.0.blocks.0.conv2.pointwise_conv.bn.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.bottom_up_blocks.0.blocks.1.conv1.conv.weight - torch.Size([192, 192, 3, 3]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

neck.bottom_up_blocks.0.blocks.1.conv1.bn.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.bottom_up_blocks.0.blocks.1.conv1.bn.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.bottom_up_blocks.0.blocks.1.conv2.depthwise_conv.conv.weight - torch.Size([192, 1, 5, 5]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

neck.bottom_up_blocks.0.blocks.1.conv2.depthwise_conv.bn.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.bottom_up_blocks.0.blocks.1.conv2.depthwise_conv.bn.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.bottom_up_blocks.0.blocks.1.conv2.pointwise_conv.conv.weight - torch.Size([192, 192, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

neck.bottom_up_blocks.0.blocks.1.conv2.pointwise_conv.bn.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.bottom_up_blocks.0.blocks.1.conv2.pointwise_conv.bn.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.bottom_up_blocks.1.main_conv.conv.weight - torch.Size([384, 768, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

neck.bottom_up_blocks.1.main_conv.bn.weight - torch.Size([384]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.bottom_up_blocks.1.main_conv.bn.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.bottom_up_blocks.1.short_conv.conv.weight - torch.Size([384, 768, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

neck.bottom_up_blocks.1.short_conv.bn.weight - torch.Size([384]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.bottom_up_blocks.1.short_conv.bn.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.bottom_up_blocks.1.final_conv.conv.weight - torch.Size([768, 768, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

neck.bottom_up_blocks.1.final_conv.bn.weight - torch.Size([768]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.bottom_up_blocks.1.final_conv.bn.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.bottom_up_blocks.1.blocks.0.conv1.conv.weight - torch.Size([384, 384, 3, 3]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

neck.bottom_up_blocks.1.blocks.0.conv1.bn.weight - torch.Size([384]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.bottom_up_blocks.1.blocks.0.conv1.bn.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.bottom_up_blocks.1.blocks.0.conv2.depthwise_conv.conv.weight - torch.Size([384, 1, 5, 5]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

neck.bottom_up_blocks.1.blocks.0.conv2.depthwise_conv.bn.weight - torch.Size([384]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.bottom_up_blocks.1.blocks.0.conv2.depthwise_conv.bn.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.bottom_up_blocks.1.blocks.0.conv2.pointwise_conv.conv.weight - torch.Size([384, 384, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

neck.bottom_up_blocks.1.blocks.0.conv2.pointwise_conv.bn.weight - torch.Size([384]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.bottom_up_blocks.1.blocks.0.conv2.pointwise_conv.bn.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.bottom_up_blocks.1.blocks.1.conv1.conv.weight - torch.Size([384, 384, 3, 3]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

neck.bottom_up_blocks.1.blocks.1.conv1.bn.weight - torch.Size([384]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.bottom_up_blocks.1.blocks.1.conv1.bn.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.bottom_up_blocks.1.blocks.1.conv2.depthwise_conv.conv.weight - torch.Size([384, 1, 5, 5]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

neck.bottom_up_blocks.1.blocks.1.conv2.depthwise_conv.bn.weight - torch.Size([384]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.bottom_up_blocks.1.blocks.1.conv2.depthwise_conv.bn.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.bottom_up_blocks.1.blocks.1.conv2.pointwise_conv.conv.weight - torch.Size([384, 384, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

neck.bottom_up_blocks.1.blocks.1.conv2.pointwise_conv.bn.weight - torch.Size([384]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.bottom_up_blocks.1.blocks.1.conv2.pointwise_conv.bn.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.out_convs.0.conv.weight - torch.Size([192, 192, 3, 3]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

neck.out_convs.0.bn.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.out_convs.0.bn.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.out_convs.1.conv.weight - torch.Size([192, 384, 3, 3]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

neck.out_convs.1.bn.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.out_convs.1.bn.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.out_convs.2.conv.weight - torch.Size([192, 768, 3, 3]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

neck.out_convs.2.bn.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

neck.out_convs.2.bn.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

bbox_head.cls_convs.0.0.conv.weight - torch.Size([192, 192, 3, 3]): 
Initialized by user-defined `init_weights` in RTMDetSepBNHead  

bbox_head.cls_convs.0.0.bn.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

bbox_head.cls_convs.0.0.bn.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

bbox_head.cls_convs.0.1.conv.weight - torch.Size([192, 192, 3, 3]): 
Initialized by user-defined `init_weights` in RTMDetSepBNHead  

bbox_head.cls_convs.0.1.bn.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

bbox_head.cls_convs.0.1.bn.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

bbox_head.cls_convs.1.0.bn.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

bbox_head.cls_convs.1.0.bn.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

bbox_head.cls_convs.1.1.bn.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

bbox_head.cls_convs.1.1.bn.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

bbox_head.cls_convs.2.0.bn.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

bbox_head.cls_convs.2.0.bn.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

bbox_head.cls_convs.2.1.bn.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

bbox_head.cls_convs.2.1.bn.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

bbox_head.reg_convs.0.0.conv.weight - torch.Size([192, 192, 3, 3]): 
Initialized by user-defined `init_weights` in RTMDetSepBNHead  

bbox_head.reg_convs.0.0.bn.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

bbox_head.reg_convs.0.0.bn.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

bbox_head.reg_convs.0.1.conv.weight - torch.Size([192, 192, 3, 3]): 
Initialized by user-defined `init_weights` in RTMDetSepBNHead  

bbox_head.reg_convs.0.1.bn.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

bbox_head.reg_convs.0.1.bn.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

bbox_head.reg_convs.1.0.bn.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

bbox_head.reg_convs.1.0.bn.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

bbox_head.reg_convs.1.1.bn.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

bbox_head.reg_convs.1.1.bn.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

bbox_head.reg_convs.2.0.bn.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

bbox_head.reg_convs.2.0.bn.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

bbox_head.reg_convs.2.1.bn.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

bbox_head.reg_convs.2.1.bn.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of RTMDet  

bbox_head.rtm_cls.0.weight - torch.Size([1, 192, 1, 1]): 
Initialized by user-defined `init_weights` in RTMDetSepBNHead  

bbox_head.rtm_cls.0.bias - torch.Size([1]): 
Initialized by user-defined `init_weights` in RTMDetSepBNHead  

bbox_head.rtm_cls.1.weight - torch.Size([1, 192, 1, 1]): 
Initialized by user-defined `init_weights` in RTMDetSepBNHead  

bbox_head.rtm_cls.1.bias - torch.Size([1]): 
Initialized by user-defined `init_weights` in RTMDetSepBNHead  

bbox_head.rtm_cls.2.weight - torch.Size([1, 192, 1, 1]): 
Initialized by user-defined `init_weights` in RTMDetSepBNHead  

bbox_head.rtm_cls.2.bias - torch.Size([1]): 
Initialized by user-defined `init_weights` in RTMDetSepBNHead  

bbox_head.rtm_reg.0.weight - torch.Size([4, 192, 1, 1]): 
Initialized by user-defined `init_weights` in RTMDetSepBNHead  

bbox_head.rtm_reg.0.bias - torch.Size([4]): 
Initialized by user-defined `init_weights` in RTMDetSepBNHead  

bbox_head.rtm_reg.1.weight - torch.Size([4, 192, 1, 1]): 
Initialized by user-defined `init_weights` in RTMDetSepBNHead  

bbox_head.rtm_reg.1.bias - torch.Size([4]): 
Initialized by user-defined `init_weights` in RTMDetSepBNHead  

bbox_head.rtm_reg.2.weight - torch.Size([4, 192, 1, 1]): 
Initialized by user-defined `init_weights` in RTMDetSepBNHead  

bbox_head.rtm_reg.2.bias - torch.Size([4]): 
Initialized by user-defined `init_weights` in RTMDetSepBNHead  
2025/05/12 18:18:25 - mmengine - INFO - Load checkpoint from /home/jaa/Work/Prog/BSU/Detectors/work_dirs/RTMDet/RTMDet_m_30e_new1_custom/epoch_5.pth
2025/05/12 18:18:25 - mmengine - INFO - resumed epoch: 5, iter: 5730
2025/05/12 18:18:25 - mmengine - INFO - Backbone frozen before training.
2025/05/12 18:18:25 - mmengine - WARNING - "FileClient" will be deprecated in future. Please use io functions in https://mmengine.readthedocs.io/en/latest/api/fileio.html#file-io
2025/05/12 18:18:25 - mmengine - WARNING - "HardDiskBackend" is the alias of "LocalBackend" and the former will be deprecated in future.
2025/05/12 18:18:25 - mmengine - INFO - Checkpoints will be saved to /home/jaa/Work/Prog/BSU/Detectors/work_dirs/RTMDet/RTMDet_m_30e_new1_custom.
2025/05/12 18:18:25 - mmengine - INFO - Backbone was unfrozen at epoch 5
2025/05/12 18:18:40 - mmengine - INFO - Epoch(train)  [6][  50/1528]  base_lr: 1.2500e-03 lr: 1.2500e-03  eta: 3:27:21  time: 0.3106  data_time: 0.0043  memory: 19491  loss: 0.6179  loss_cls: 0.3316  loss_bbox: 0.2863
2025/05/12 18:18:56 - mmengine - INFO - Epoch(train)  [6][ 100/1528]  base_lr: 1.2500e-03 lr: 1.2500e-03  eta: 3:29:55  time: 0.3190  data_time: 0.0006  memory: 19515  loss: 0.5816  loss_cls: 0.2937  loss_bbox: 0.2879
2025/05/12 18:19:12 - mmengine - INFO - Epoch(train)  [6][ 150/1528]  base_lr: 1.2500e-03 lr: 1.2500e-03  eta: 3:30:31  time: 0.3187  data_time: 0.0006  memory: 19489  loss: 0.5382  loss_cls: 0.2723  loss_bbox: 0.2659
2025/05/12 18:19:28 - mmengine - INFO - Epoch(train)  [6][ 200/1528]  base_lr: 1.2500e-03 lr: 1.2500e-03  eta: 3:29:57  time: 0.3143  data_time: 0.0006  memory: 19477  loss: 0.5607  loss_cls: 0.2878  loss_bbox: 0.2729
2025/05/12 18:19:43 - mmengine - INFO - Epoch(train)  [6][ 250/1528]  base_lr: 1.2500e-03 lr: 1.2500e-03  eta: 3:28:12  time: 0.3045  data_time: 0.0006  memory: 19489  loss: 0.5609  loss_cls: 0.2862  loss_bbox: 0.2747
2025/05/12 18:19:49 - mmengine - INFO - Exp name: rtmdet_m_1x_custom_resume_20250512_181820
2025/05/12 18:19:58 - mmengine - INFO - Epoch(train)  [6][ 300/1528]  base_lr: 1.2500e-03 lr: 1.2500e-03  eta: 3:26:57  time: 0.3045  data_time: 0.0007  memory: 19508  loss: 0.6472  loss_cls: 0.3279  loss_bbox: 0.3193
2025/05/12 18:20:13 - mmengine - INFO - Epoch(train)  [6][ 350/1528]  base_lr: 1.2500e-03 lr: 1.2500e-03  eta: 3:25:39  time: 0.3009  data_time: 0.0007  memory: 19492  loss: 0.5405  loss_cls: 0.2627  loss_bbox: 0.2779
2025/05/12 18:20:29 - mmengine - INFO - Epoch(train)  [6][ 400/1528]  base_lr: 1.2500e-03 lr: 1.2500e-03  eta: 3:24:49  time: 0.3033  data_time: 0.0006  memory: 19510  loss: 0.5519  loss_cls: 0.2784  loss_bbox: 0.2735
2025/05/12 18:20:44 - mmengine - INFO - Epoch(train)  [6][ 450/1528]  base_lr: 1.2500e-03 lr: 1.2500e-03  eta: 3:23:53  time: 0.3002  data_time: 0.0006  memory: 19497  loss: 0.5037  loss_cls: 0.2470  loss_bbox: 0.2567
2025/05/12 18:20:59 - mmengine - INFO - Epoch(train)  [6][ 500/1528]  base_lr: 1.2500e-03 lr: 1.2500e-03  eta: 3:23:17  time: 0.3033  data_time: 0.0005  memory: 19505  loss: 0.5502  loss_cls: 0.2757  loss_bbox: 0.2744
2025/05/12 18:21:14 - mmengine - INFO - Epoch(train)  [6][ 550/1528]  base_lr: 1.2500e-03 lr: 1.2500e-03  eta: 3:22:32  time: 0.2998  data_time: 0.0004  memory: 19500  loss: 0.6525  loss_cls: 0.3408  loss_bbox: 0.3117
2025/05/12 18:21:29 - mmengine - INFO - Epoch(train)  [6][ 600/1528]  base_lr: 1.2500e-03 lr: 1.2500e-03  eta: 3:22:02  time: 0.3028  data_time: 0.0005  memory: 19496  loss: 0.5701  loss_cls: 0.2859  loss_bbox: 0.2842
2025/05/12 18:21:44 - mmengine - INFO - Epoch(train)  [6][ 650/1528]  base_lr: 1.2500e-03 lr: 1.2500e-03  eta: 3:21:29  time: 0.3010  data_time: 0.0006  memory: 19504  loss: 0.6516  loss_cls: 0.3474  loss_bbox: 0.3042
2025/05/12 18:21:59 - mmengine - INFO - Epoch(train)  [6][ 700/1528]  base_lr: 1.2500e-03 lr: 1.2500e-03  eta: 3:21:03  time: 0.3027  data_time: 0.0005  memory: 19509  loss: 0.5433  loss_cls: 0.2757  loss_bbox: 0.2676
2025/05/12 18:22:14 - mmengine - INFO - Epoch(train)  [6][ 750/1528]  base_lr: 1.2500e-03 lr: 1.2500e-03  eta: 3:20:33  time: 0.3005  data_time: 0.0005  memory: 19491  loss: 0.5817  loss_cls: 0.3001  loss_bbox: 0.2816
2025/05/12 18:22:29 - mmengine - INFO - Epoch(train)  [6][ 800/1528]  base_lr: 1.2500e-03 lr: 1.2500e-03  eta: 3:20:09  time: 0.3019  data_time: 0.0005  memory: 19507  loss: 0.5245  loss_cls: 0.2579  loss_bbox: 0.2666
2025/05/12 18:22:44 - mmengine - INFO - Epoch(train)  [6][ 850/1528]  base_lr: 1.2500e-03 lr: 1.2500e-03  eta: 3:19:49  time: 0.3037  data_time: 0.0006  memory: 19485  loss: 0.5356  loss_cls: 0.2680  loss_bbox: 0.2676
2025/05/12 18:22:59 - mmengine - INFO - Epoch(train)  [6][ 900/1528]  base_lr: 1.2500e-03 lr: 1.2500e-03  eta: 3:19:21  time: 0.2992  data_time: 0.0005  memory: 19481  loss: 0.5292  loss_cls: 0.2662  loss_bbox: 0.2630
2025/05/12 18:23:14 - mmengine - INFO - Epoch(train)  [6][ 950/1528]  base_lr: 1.2500e-03 lr: 1.2500e-03  eta: 3:19:02  time: 0.3034  data_time: 0.0006  memory: 19517  loss: 0.5634  loss_cls: 0.2910  loss_bbox: 0.2724
2025/05/12 18:23:30 - mmengine - INFO - Epoch(train)  [6][1000/1528]  base_lr: 1.2500e-03 lr: 1.2500e-03  eta: 3:18:44  time: 0.3035  data_time: 0.0005  memory: 19500  loss: 0.6403  loss_cls: 0.3404  loss_bbox: 0.3000
2025/05/12 18:23:45 - mmengine - INFO - Epoch(train)  [6][1050/1528]  base_lr: 1.2500e-03 lr: 1.2500e-03  eta: 3:18:26  time: 0.3035  data_time: 0.0006  memory: 19483  loss: 0.6396  loss_cls: 0.3468  loss_bbox: 0.2928
2025/05/12 18:24:00 - mmengine - INFO - Epoch(train)  [6][1100/1528]  base_lr: 1.2500e-03 lr: 1.2500e-03  eta: 3:18:02  time: 0.2997  data_time: 0.0006  memory: 19506  loss: 0.5426  loss_cls: 0.2692  loss_bbox: 0.2734
2025/05/12 18:24:15 - mmengine - INFO - Epoch(train)  [6][1150/1528]  base_lr: 1.2500e-03 lr: 1.2500e-03  eta: 3:17:45  time: 0.3036  data_time: 0.0006  memory: 19476  loss: 0.5434  loss_cls: 0.2677  loss_bbox: 0.2757
2025/05/12 18:24:30 - mmengine - INFO - Epoch(train)  [6][1200/1528]  base_lr: 1.2500e-03 lr: 1.2500e-03  eta: 3:17:23  time: 0.3003  data_time: 0.0006  memory: 19500  loss: 0.5928  loss_cls: 0.3024  loss_bbox: 0.2904
2025/05/12 18:24:45 - mmengine - INFO - Epoch(train)  [6][1250/1528]  base_lr: 1.2500e-03 lr: 1.2500e-03  eta: 3:17:07  time: 0.3040  data_time: 0.0006  memory: 19480  loss: 0.5218  loss_cls: 0.2627  loss_bbox: 0.2590
2025/05/12 18:24:51 - mmengine - INFO - Exp name: rtmdet_m_1x_custom_resume_20250512_181820
2025/05/12 18:25:00 - mmengine - INFO - Epoch(train)  [6][1300/1528]  base_lr: 1.2500e-03 lr: 1.2500e-03  eta: 3:16:50  time: 0.3032  data_time: 0.0006  memory: 19511  loss: 0.5548  loss_cls: 0.2680  loss_bbox: 0.2868
2025/05/12 18:25:15 - mmengine - INFO - Epoch(train)  [6][1350/1528]  base_lr: 1.2500e-03 lr: 1.2500e-03  eta: 3:16:32  time: 0.3024  data_time: 0.0006  memory: 19487  loss: 0.5535  loss_cls: 0.2764  loss_bbox: 0.2771
2025/05/12 18:25:31 - mmengine - INFO - Epoch(train)  [6][1400/1528]  base_lr: 1.2500e-03 lr: 1.2500e-03  eta: 3:16:15  time: 0.3032  data_time: 0.0006  memory: 19483  loss: 0.5370  loss_cls: 0.2650  loss_bbox: 0.2720
2025/05/12 18:25:46 - mmengine - INFO - Epoch(train)  [6][1450/1528]  base_lr: 1.2500e-03 lr: 1.2500e-03  eta: 3:15:59  time: 0.3031  data_time: 0.0006  memory: 19483  loss: 0.5258  loss_cls: 0.2441  loss_bbox: 0.2816
2025/05/12 18:26:01 - mmengine - INFO - Epoch(train)  [6][1500/1528]  base_lr: 1.2500e-03 lr: 1.2500e-03  eta: 3:15:44  time: 0.3043  data_time: 0.0006  memory: 19495  loss: 0.5490  loss_cls: 0.2779  loss_bbox: 0.2711
2025/05/12 18:26:09 - mmengine - INFO - Exp name: rtmdet_m_1x_custom_resume_20250512_181820
2025/05/12 18:26:09 - mmengine - INFO - Saving checkpoint at 6 epochs
2025/05/12 18:26:14 - mmengine - INFO - Epoch(val)  [6][ 50/149]    eta: 0:00:08  time: 0.0886  data_time: 0.0065  memory: 19479  
2025/05/12 18:26:19 - mmengine - INFO - Epoch(val)  [6][100/149]    eta: 0:00:04  time: 0.0862  data_time: 0.0028  memory: 1598  
2025/05/12 18:26:24 - mmengine - INFO - Evaluating bbox...
2025/05/12 18:26:27 - mmengine - INFO - bbox_mAP_copypaste: 0.640 0.921 0.778 0.402 0.620 0.662
2025/05/12 18:26:27 - mmengine - INFO - Epoch(val) [6][149/149]    coco/bbox_mAP: 0.6400  coco/bbox_mAP_50: 0.9210  coco/bbox_mAP_75: 0.7780  coco/bbox_mAP_s: 0.4020  coco/bbox_mAP_m: 0.6200  coco/bbox_mAP_l: 0.6620  data_time: 0.0039  time: 0.0861
2025/05/12 18:26:42 - mmengine - INFO - Epoch(train)  [7][  50/1528]  base_lr: 8.6373e-04 lr: 8.6373e-04  eta: 3:15:14  time: 0.3047  data_time: 0.0069  memory: 19509  loss: 0.5049  loss_cls: 0.2372  loss_bbox: 0.2677
2025/05/12 18:26:57 - mmengine - INFO - Epoch(train)  [7][ 100/1528]  base_lr: 8.6373e-04 lr: 8.6373e-04  eta: 3:14:53  time: 0.2990  data_time: 0.0006  memory: 19509  loss: 0.5057  loss_cls: 0.2463  loss_bbox: 0.2594
2025/05/12 18:27:12 - mmengine - INFO - Epoch(train)  [7][ 150/1528]  base_lr: 8.6373e-04 lr: 8.6373e-04  eta: 3:14:32  time: 0.2987  data_time: 0.0006  memory: 19481  loss: 0.5235  loss_cls: 0.2598  loss_bbox: 0.2637
2025/05/12 18:27:27 - mmengine - INFO - Epoch(train)  [7][ 200/1528]  base_lr: 8.6373e-04 lr: 8.6373e-04  eta: 3:14:10  time: 0.2978  data_time: 0.0005  memory: 19507  loss: 0.4733  loss_cls: 0.2218  loss_bbox: 0.2515
2025/05/12 18:27:42 - mmengine - INFO - Epoch(train)  [7][ 250/1528]  base_lr: 8.6373e-04 lr: 8.6373e-04  eta: 3:13:48  time: 0.2976  data_time: 0.0005  memory: 19498  loss: 0.5101  loss_cls: 0.2525  loss_bbox: 0.2576
2025/05/12 18:27:57 - mmengine - INFO - Epoch(train)  [7][ 300/1528]  base_lr: 8.6373e-04 lr: 8.6373e-04  eta: 3:13:28  time: 0.2984  data_time: 0.0004  memory: 19513  loss: 0.5051  loss_cls: 0.2430  loss_bbox: 0.2621
2025/05/12 18:28:11 - mmengine - INFO - Epoch(train)  [7][ 350/1528]  base_lr: 8.6373e-04 lr: 8.6373e-04  eta: 3:13:09  time: 0.2992  data_time: 0.0005  memory: 19483  loss: 0.4926  loss_cls: 0.2362  loss_bbox: 0.2564
2025/05/12 18:28:26 - mmengine - INFO - Epoch(train)  [7][ 400/1528]  base_lr: 8.6373e-04 lr: 8.6373e-04  eta: 3:12:49  time: 0.2980  data_time: 0.0004  memory: 19501  loss: 0.4736  loss_cls: 0.2241  loss_bbox: 0.2496
2025/05/12 18:28:41 - mmengine - INFO - Epoch(train)  [7][ 450/1528]  base_lr: 8.6373e-04 lr: 8.6373e-04  eta: 3:12:29  time: 0.2981  data_time: 0.0004  memory: 19485  loss: 0.4813  loss_cls: 0.2324  loss_bbox: 0.2489
2025/05/12 18:28:56 - mmengine - INFO - Epoch(train)  [7][ 500/1528]  base_lr: 8.6373e-04 lr: 8.6373e-04  eta: 3:12:09  time: 0.2976  data_time: 0.0004  memory: 19507  loss: 0.4737  loss_cls: 0.2295  loss_bbox: 0.2442
2025/05/12 18:29:11 - mmengine - INFO - Epoch(train)  [7][ 550/1528]  base_lr: 8.6373e-04 lr: 8.6373e-04  eta: 3:11:49  time: 0.2979  data_time: 0.0005  memory: 19492  loss: 0.5336  loss_cls: 0.2594  loss_bbox: 0.2742
2025/05/12 18:29:26 - mmengine - INFO - Epoch(train)  [7][ 600/1528]  base_lr: 8.6373e-04 lr: 8.6373e-04  eta: 3:11:30  time: 0.2981  data_time: 0.0004  memory: 19487  loss: 0.5355  loss_cls: 0.2712  loss_bbox: 0.2643
2025/05/12 18:29:41 - mmengine - INFO - Epoch(train)  [7][ 650/1528]  base_lr: 8.6373e-04 lr: 8.6373e-04  eta: 3:11:11  time: 0.2978  data_time: 0.0004  memory: 19485  loss: 0.5069  loss_cls: 0.2499  loss_bbox: 0.2570
2025/05/12 18:29:56 - mmengine - INFO - Epoch(train)  [7][ 700/1528]  base_lr: 8.6373e-04 lr: 8.6373e-04  eta: 3:10:52  time: 0.2979  data_time: 0.0004  memory: 19507  loss: 0.4924  loss_cls: 0.2464  loss_bbox: 0.2461
2025/05/12 18:30:08 - mmengine - INFO - Exp name: rtmdet_m_1x_custom_resume_20250512_181820
2025/05/12 18:30:11 - mmengine - INFO - Epoch(train)  [7][ 750/1528]  base_lr: 8.6373e-04 lr: 8.6373e-04  eta: 3:10:33  time: 0.2981  data_time: 0.0004  memory: 19507  loss: 0.4746  loss_cls: 0.2225  loss_bbox: 0.2521
2025/05/12 18:30:26 - mmengine - INFO - Epoch(train)  [7][ 800/1528]  base_lr: 8.6373e-04 lr: 8.6373e-04  eta: 3:10:18  time: 0.3021  data_time: 0.0005  memory: 19480  loss: 0.5000  loss_cls: 0.2457  loss_bbox: 0.2543
2025/05/12 18:30:41 - mmengine - INFO - Epoch(train)  [7][ 850/1528]  base_lr: 8.6373e-04 lr: 8.6373e-04  eta: 3:09:59  time: 0.2978  data_time: 0.0004  memory: 19485  loss: 0.4993  loss_cls: 0.2444  loss_bbox: 0.2549
2025/05/12 18:30:56 - mmengine - INFO - Epoch(train)  [7][ 900/1528]  base_lr: 8.6373e-04 lr: 8.6373e-04  eta: 3:09:41  time: 0.2980  data_time: 0.0005  memory: 19492  loss: 0.4912  loss_cls: 0.2298  loss_bbox: 0.2614
2025/05/12 18:31:10 - mmengine - INFO - Epoch(train)  [7][ 950/1528]  base_lr: 8.6373e-04 lr: 8.6373e-04  eta: 3:09:23  time: 0.2979  data_time: 0.0004  memory: 19510  loss: 0.4657  loss_cls: 0.2269  loss_bbox: 0.2388
2025/05/12 18:31:25 - mmengine - INFO - Epoch(train)  [7][1000/1528]  base_lr: 8.6373e-04 lr: 8.6373e-04  eta: 3:09:05  time: 0.2981  data_time: 0.0004  memory: 19513  loss: 0.4983  loss_cls: 0.2436  loss_bbox: 0.2547
2025/05/12 18:31:40 - mmengine - INFO - Epoch(train)  [7][1050/1528]  base_lr: 8.6373e-04 lr: 8.6373e-04  eta: 3:08:47  time: 0.2981  data_time: 0.0004  memory: 19503  loss: 0.4760  loss_cls: 0.2240  loss_bbox: 0.2520
2025/05/12 18:31:55 - mmengine - INFO - Epoch(train)  [7][1100/1528]  base_lr: 8.6373e-04 lr: 8.6373e-04  eta: 3:08:29  time: 0.2983  data_time: 0.0004  memory: 19483  loss: 0.4743  loss_cls: 0.2191  loss_bbox: 0.2552
2025/05/12 18:32:10 - mmengine - INFO - Epoch(train)  [7][1150/1528]  base_lr: 8.6373e-04 lr: 8.6373e-04  eta: 3:08:11  time: 0.2974  data_time: 0.0004  memory: 19497  loss: 0.4893  loss_cls: 0.2305  loss_bbox: 0.2588
2025/05/12 18:32:25 - mmengine - INFO - Epoch(train)  [7][1200/1528]  base_lr: 8.6373e-04 lr: 8.6373e-04  eta: 3:07:53  time: 0.2979  data_time: 0.0005  memory: 19488  loss: 0.4521  loss_cls: 0.2149  loss_bbox: 0.2372
2025/05/12 18:32:40 - mmengine - INFO - Epoch(train)  [7][1250/1528]  base_lr: 8.6373e-04 lr: 8.6373e-04  eta: 3:07:36  time: 0.2979  data_time: 0.0004  memory: 19513  loss: 0.4659  loss_cls: 0.2235  loss_bbox: 0.2424
2025/05/12 18:32:55 - mmengine - INFO - Epoch(train)  [7][1300/1528]  base_lr: 8.6373e-04 lr: 8.6373e-04  eta: 3:07:18  time: 0.2979  data_time: 0.0004  memory: 19510  loss: 0.4734  loss_cls: 0.2227  loss_bbox: 0.2507
2025/05/12 18:33:10 - mmengine - INFO - Epoch(train)  [7][1350/1528]  base_lr: 8.6373e-04 lr: 8.6373e-04  eta: 3:07:01  time: 0.2980  data_time: 0.0005  memory: 19479  loss: 0.4553  loss_cls: 0.2162  loss_bbox: 0.2392
2025/05/12 18:33:25 - mmengine - INFO - Epoch(train)  [7][1400/1528]  base_lr: 8.6373e-04 lr: 8.6373e-04  eta: 3:06:44  time: 0.2977  data_time: 0.0004  memory: 19500  loss: 0.4666  loss_cls: 0.2246  loss_bbox: 0.2420
2025/05/12 18:33:39 - mmengine - INFO - Epoch(train)  [7][1450/1528]  base_lr: 8.6373e-04 lr: 8.6373e-04  eta: 3:06:27  time: 0.2987  data_time: 0.0005  memory: 19489  loss: 0.4547  loss_cls: 0.2153  loss_bbox: 0.2394
2025/05/12 18:33:54 - mmengine - INFO - Epoch(train)  [7][1500/1528]  base_lr: 8.6373e-04 lr: 8.6373e-04  eta: 3:06:10  time: 0.2986  data_time: 0.0005  memory: 19485  loss: 0.4802  loss_cls: 0.2263  loss_bbox: 0.2540
2025/05/12 18:34:03 - mmengine - INFO - Exp name: rtmdet_m_1x_custom_resume_20250512_181820
2025/05/12 18:34:03 - mmengine - INFO - Saving checkpoint at 7 epochs
2025/05/12 18:34:08 - mmengine - INFO - Epoch(val)  [7][ 50/149]    eta: 0:00:08  time: 0.0875  data_time: 0.0036  memory: 19493  
2025/05/12 18:34:12 - mmengine - INFO - Epoch(val)  [7][100/149]    eta: 0:00:04  time: 0.0854  data_time: 0.0025  memory: 1598  
2025/05/12 18:34:17 - mmengine - INFO - Evaluating bbox...
2025/05/12 18:34:20 - mmengine - INFO - bbox_mAP_copypaste: 0.740 0.925 0.836 0.364 0.631 0.788
2025/05/12 18:34:20 - mmengine - INFO - Epoch(val) [7][149/149]    coco/bbox_mAP: 0.7400  coco/bbox_mAP_50: 0.9250  coco/bbox_mAP_75: 0.8360  coco/bbox_mAP_s: 0.3640  coco/bbox_mAP_m: 0.6310  coco/bbox_mAP_l: 0.7880  data_time: 0.0029  time: 0.0861
2025/05/12 18:34:35 - mmengine - INFO - Epoch(train)  [8][  50/1528]  base_lr: 5.1527e-05 lr: 5.1527e-05  eta: 3:05:44  time: 0.3010  data_time: 0.0028  memory: 19479  loss: 0.4828  loss_cls: 0.2340  loss_bbox: 0.2487
2025/05/12 18:34:50 - mmengine - INFO - Epoch(train)  [8][ 100/1528]  base_lr: 5.1527e-05 lr: 5.1527e-05  eta: 3:05:27  time: 0.2977  data_time: 0.0004  memory: 19510  loss: 0.4506  loss_cls: 0.2185  loss_bbox: 0.2321
2025/05/12 18:35:05 - mmengine - INFO - Epoch(train)  [8][ 150/1528]  base_lr: 5.1527e-05 lr: 5.1527e-05  eta: 3:05:10  time: 0.2982  data_time: 0.0005  memory: 19486  loss: 0.4438  loss_cls: 0.2077  loss_bbox: 0.2361
2025/05/12 18:35:20 - mmengine - INFO - Epoch(train)  [8][ 200/1528]  base_lr: 5.1527e-05 lr: 5.1527e-05  eta: 3:04:54  time: 0.2981  data_time: 0.0004  memory: 19507  loss: 0.4725  loss_cls: 0.2279  loss_bbox: 0.2446
2025/05/12 18:35:24 - mmengine - INFO - Exp name: rtmdet_m_1x_custom_resume_20250512_181820
2025/05/12 18:35:35 - mmengine - INFO - Epoch(train)  [8][ 250/1528]  base_lr: 5.1527e-05 lr: 5.1527e-05  eta: 3:04:37  time: 0.2982  data_time: 0.0005  memory: 19472  loss: 0.4735  loss_cls: 0.2374  loss_bbox: 0.2361
2025/05/12 18:35:50 - mmengine - INFO - Epoch(train)  [8][ 300/1528]  base_lr: 5.1527e-05 lr: 5.1527e-05  eta: 3:04:21  time: 0.2983  data_time: 0.0005  memory: 19479  loss: 0.4266  loss_cls: 0.2016  loss_bbox: 0.2250
2025/05/12 18:36:05 - mmengine - INFO - Epoch(train)  [8][ 350/1528]  base_lr: 5.1527e-05 lr: 5.1527e-05  eta: 3:04:04  time: 0.2990  data_time: 0.0006  memory: 19504  loss: 0.4109  loss_cls: 0.1914  loss_bbox: 0.2195
2025/05/12 18:36:20 - mmengine - INFO - Epoch(train)  [8][ 400/1528]  base_lr: 5.1527e-05 lr: 5.1527e-05  eta: 3:03:48  time: 0.2992  data_time: 0.0006  memory: 19504  loss: 0.4500  loss_cls: 0.2050  loss_bbox: 0.2450
2025/05/12 18:36:35 - mmengine - INFO - Epoch(train)  [8][ 450/1528]  base_lr: 5.1527e-05 lr: 5.1527e-05  eta: 3:03:33  time: 0.2992  data_time: 0.0006  memory: 19492  loss: 0.4666  loss_cls: 0.2329  loss_bbox: 0.2337
2025/05/12 18:36:50 - mmengine - INFO - Epoch(train)  [8][ 500/1528]  base_lr: 5.1527e-05 lr: 5.1527e-05  eta: 3:03:17  time: 0.2995  data_time: 0.0006  memory: 19476  loss: 0.4340  loss_cls: 0.2003  loss_bbox: 0.2336
2025/05/12 18:37:05 - mmengine - INFO - Epoch(train)  [8][ 550/1528]  base_lr: 5.1527e-05 lr: 5.1527e-05  eta: 3:03:01  time: 0.2990  data_time: 0.0006  memory: 19510  loss: 0.4883  loss_cls: 0.2516  loss_bbox: 0.2366
2025/05/12 18:37:20 - mmengine - INFO - Epoch(train)  [8][ 600/1528]  base_lr: 5.1527e-05 lr: 5.1527e-05  eta: 3:02:45  time: 0.2990  data_time: 0.0006  memory: 19488  loss: 0.4361  loss_cls: 0.2057  loss_bbox: 0.2304
2025/05/12 18:37:34 - mmengine - INFO - Epoch(train)  [8][ 650/1528]  base_lr: 5.1527e-05 lr: 5.1527e-05  eta: 3:02:29  time: 0.2992  data_time: 0.0006  memory: 19502  loss: 0.4666  loss_cls: 0.2184  loss_bbox: 0.2482
2025/05/12 18:37:49 - mmengine - INFO - Epoch(train)  [8][ 700/1528]  base_lr: 5.1527e-05 lr: 5.1527e-05  eta: 3:02:13  time: 0.2989  data_time: 0.0005  memory: 19511  loss: 0.4495  loss_cls: 0.2076  loss_bbox: 0.2420
2025/05/12 18:38:04 - mmengine - INFO - Epoch(train)  [8][ 750/1528]  base_lr: 5.1527e-05 lr: 5.1527e-05  eta: 3:01:57  time: 0.2991  data_time: 0.0006  memory: 19503  loss: 0.4592  loss_cls: 0.2255  loss_bbox: 0.2337
2025/05/12 18:38:19 - mmengine - INFO - Epoch(train)  [8][ 800/1528]  base_lr: 5.1527e-05 lr: 5.1527e-05  eta: 3:01:41  time: 0.2991  data_time: 0.0005  memory: 19485  loss: 0.4402  loss_cls: 0.2121  loss_bbox: 0.2281
2025/05/12 18:38:34 - mmengine - INFO - Epoch(train)  [8][ 850/1528]  base_lr: 5.1527e-05 lr: 5.1527e-05  eta: 3:01:27  time: 0.3025  data_time: 0.0005  memory: 19491  loss: 0.4393  loss_cls: 0.2106  loss_bbox: 0.2287
2025/05/12 18:38:49 - mmengine - INFO - Epoch(train)  [8][ 900/1528]  base_lr: 5.1527e-05 lr: 5.1527e-05  eta: 3:01:11  time: 0.2984  data_time: 0.0005  memory: 19482  loss: 0.4301  loss_cls: 0.2054  loss_bbox: 0.2247
2025/05/12 18:39:04 - mmengine - INFO - Epoch(train)  [8][ 950/1528]  base_lr: 5.1527e-05 lr: 5.1527e-05  eta: 3:00:55  time: 0.2976  data_time: 0.0004  memory: 19490  loss: 0.4535  loss_cls: 0.2192  loss_bbox: 0.2344
2025/05/12 18:39:19 - mmengine - INFO - Epoch(train)  [8][1000/1528]  base_lr: 5.1527e-05 lr: 5.1527e-05  eta: 3:00:38  time: 0.2976  data_time: 0.0005  memory: 19492  loss: 0.4493  loss_cls: 0.2185  loss_bbox: 0.2308
2025/05/12 18:39:34 - mmengine - INFO - Epoch(train)  [8][1050/1528]  base_lr: 5.1527e-05 lr: 5.1527e-05  eta: 3:00:23  time: 0.2990  data_time: 0.0005  memory: 19519  loss: 0.4375  loss_cls: 0.2113  loss_bbox: 0.2262
2025/05/12 18:39:49 - mmengine - INFO - Epoch(train)  [8][1100/1528]  base_lr: 5.1527e-05 lr: 5.1527e-05  eta: 3:00:07  time: 0.2982  data_time: 0.0005  memory: 19495  loss: 0.4140  loss_cls: 0.1888  loss_bbox: 0.2252
2025/05/12 18:40:04 - mmengine - INFO - Epoch(train)  [8][1150/1528]  base_lr: 5.1527e-05 lr: 5.1527e-05  eta: 2:59:50  time: 0.2979  data_time: 0.0004  memory: 19508  loss: 0.4132  loss_cls: 0.1903  loss_bbox: 0.2229
2025/05/12 18:40:19 - mmengine - INFO - Epoch(train)  [8][1200/1528]  base_lr: 5.1527e-05 lr: 5.1527e-05  eta: 2:59:34  time: 0.2980  data_time: 0.0005  memory: 19477  loss: 0.4320  loss_cls: 0.2065  loss_bbox: 0.2256
2025/05/12 18:40:23 - mmengine - INFO - Exp name: rtmdet_m_1x_custom_resume_20250512_181820
2025/05/12 18:40:34 - mmengine - INFO - Epoch(train)  [8][1250/1528]  base_lr: 5.1527e-05 lr: 5.1527e-05  eta: 2:59:18  time: 0.2984  data_time: 0.0005  memory: 19513  loss: 0.4303  loss_cls: 0.1983  loss_bbox: 0.2320
2025/05/12 18:40:49 - mmengine - INFO - Epoch(train)  [8][1300/1528]  base_lr: 5.1527e-05 lr: 5.1527e-05  eta: 2:59:02  time: 0.2975  data_time: 0.0005  memory: 19479  loss: 0.4192  loss_cls: 0.1937  loss_bbox: 0.2255
2025/05/12 18:41:04 - mmengine - INFO - Epoch(train)  [8][1350/1528]  base_lr: 5.1527e-05 lr: 5.1527e-05  eta: 2:58:46  time: 0.2986  data_time: 0.0004  memory: 19481  loss: 0.4414  loss_cls: 0.2118  loss_bbox: 0.2297
2025/05/12 18:41:18 - mmengine - INFO - Epoch(train)  [8][1400/1528]  base_lr: 5.1527e-05 lr: 5.1527e-05  eta: 2:58:30  time: 0.2976  data_time: 0.0005  memory: 19499  loss: 0.4519  loss_cls: 0.2205  loss_bbox: 0.2314
2025/05/12 18:41:33 - mmengine - INFO - Epoch(train)  [8][1450/1528]  base_lr: 5.1527e-05 lr: 5.1527e-05  eta: 2:58:15  time: 0.2988  data_time: 0.0005  memory: 19507  loss: 0.4589  loss_cls: 0.2229  loss_bbox: 0.2361
2025/05/12 18:41:48 - mmengine - INFO - Epoch(train)  [8][1500/1528]  base_lr: 5.1527e-05 lr: 5.1527e-05  eta: 2:57:59  time: 0.2983  data_time: 0.0004  memory: 19496  loss: 0.4469  loss_cls: 0.2128  loss_bbox: 0.2341
2025/05/12 18:41:56 - mmengine - INFO - Exp name: rtmdet_m_1x_custom_resume_20250512_181820
2025/05/12 18:41:56 - mmengine - INFO - Saving checkpoint at 8 epochs
2025/05/12 18:42:01 - mmengine - INFO - Epoch(val)  [8][ 50/149]    eta: 0:00:08  time: 0.0833  data_time: 0.0037  memory: 19476  
2025/05/12 18:42:05 - mmengine - INFO - Epoch(val)  [8][100/149]    eta: 0:00:04  time: 0.0802  data_time: 0.0025  memory: 1598  
2025/05/12 18:42:10 - mmengine - INFO - Evaluating bbox...
2025/05/12 18:42:13 - mmengine - INFO - bbox_mAP_copypaste: 0.762 0.936 0.851 0.414 0.662 0.805
2025/05/12 18:42:13 - mmengine - INFO - Epoch(val) [8][149/149]    coco/bbox_mAP: 0.7620  coco/bbox_mAP_50: 0.9360  coco/bbox_mAP_75: 0.8510  coco/bbox_mAP_s: 0.4140  coco/bbox_mAP_m: 0.6620  coco/bbox_mAP_l: 0.8050  data_time: 0.0029  time: 0.0805
2025/05/12 18:42:28 - mmengine - INFO - Epoch(train)  [9][  50/1528]  base_lr: 2.3873e-05 lr: 2.3873e-05  eta: 2:57:33  time: 0.3005  data_time: 0.0030  memory: 19508  loss: 0.4680  loss_cls: 0.2249  loss_bbox: 0.2432
2025/05/12 18:42:43 - mmengine - INFO - Epoch(train)  [9][ 100/1528]  base_lr: 2.3873e-05 lr: 2.3873e-05  eta: 2:57:18  time: 0.2990  data_time: 0.0005  memory: 19517  loss: 0.4316  loss_cls: 0.2014  loss_bbox: 0.2301
2025/05/12 18:42:58 - mmengine - INFO - Epoch(train)  [9][ 150/1528]  base_lr: 2.3873e-05 lr: 2.3873e-05  eta: 2:57:02  time: 0.2983  data_time: 0.0005  memory: 19504  loss: 0.4422  loss_cls: 0.2107  loss_bbox: 0.2314
2025/05/12 18:43:13 - mmengine - INFO - Epoch(train)  [9][ 200/1528]  base_lr: 2.3873e-05 lr: 2.3873e-05  eta: 2:56:47  time: 0.2993  data_time: 0.0006  memory: 19496  loss: 0.4299  loss_cls: 0.2030  loss_bbox: 0.2269
2025/05/12 18:43:28 - mmengine - INFO - Epoch(train)  [9][ 250/1528]  base_lr: 2.3873e-05 lr: 2.3873e-05  eta: 2:56:31  time: 0.2987  data_time: 0.0006  memory: 19492  loss: 0.4247  loss_cls: 0.1966  loss_bbox: 0.2281
2025/05/12 18:43:43 - mmengine - INFO - Epoch(train)  [9][ 300/1528]  base_lr: 2.3873e-05 lr: 2.3873e-05  eta: 2:56:16  time: 0.2991  data_time: 0.0006  memory: 19502  loss: 0.4367  loss_cls: 0.2081  loss_bbox: 0.2286
2025/05/12 18:43:58 - mmengine - INFO - Epoch(train)  [9][ 350/1528]  base_lr: 2.3873e-05 lr: 2.3873e-05  eta: 2:56:03  time: 0.3062  data_time: 0.0006  memory: 19500  loss: 0.4078  loss_cls: 0.1891  loss_bbox: 0.2187
2025/05/12 18:44:13 - mmengine - INFO - Epoch(train)  [9][ 400/1528]  base_lr: 2.3873e-05 lr: 2.3873e-05  eta: 2:55:50  time: 0.3052  data_time: 0.0006  memory: 19507  loss: 0.4480  loss_cls: 0.2231  loss_bbox: 0.2249
2025/05/12 18:44:29 - mmengine - INFO - Epoch(train)  [9][ 450/1528]  base_lr: 2.3873e-05 lr: 2.3873e-05  eta: 2:55:39  time: 0.3126  data_time: 0.0006  memory: 19494  loss: 0.4188  loss_cls: 0.1993  loss_bbox: 0.2195
2025/05/12 18:44:45 - mmengine - INFO - Epoch(train)  [9][ 500/1528]  base_lr: 2.3873e-05 lr: 2.3873e-05  eta: 2:55:27  time: 0.3083  data_time: 0.0006  memory: 19509  loss: 0.4524  loss_cls: 0.2218  loss_bbox: 0.2305
2025/05/12 18:45:00 - mmengine - INFO - Epoch(train)  [9][ 550/1528]  base_lr: 2.3873e-05 lr: 2.3873e-05  eta: 2:55:12  time: 0.3016  data_time: 0.0005  memory: 19515  loss: 0.4577  loss_cls: 0.2160  loss_bbox: 0.2417
2025/05/12 18:45:15 - mmengine - INFO - Epoch(train)  [9][ 600/1528]  base_lr: 2.3873e-05 lr: 2.3873e-05  eta: 2:54:58  time: 0.3053  data_time: 0.0005  memory: 19498  loss: 0.4216  loss_cls: 0.1973  loss_bbox: 0.2244
2025/05/12 18:45:31 - mmengine - INFO - Epoch(train)  [9][ 650/1528]  base_lr: 2.3873e-05 lr: 2.3873e-05  eta: 2:54:48  time: 0.3154  data_time: 0.0007  memory: 19504  loss: 0.4432  loss_cls: 0.2116  loss_bbox: 0.2316
2025/05/12 18:45:42 - mmengine - INFO - Exp name: rtmdet_m_1x_custom_resume_20250512_181820
2025/05/12 18:45:46 - mmengine - INFO - Epoch(train)  [9][ 700/1528]  base_lr: 2.3873e-05 lr: 2.3873e-05  eta: 2:54:35  time: 0.3063  data_time: 0.0006  memory: 19507  loss: 0.4230  loss_cls: 0.2019  loss_bbox: 0.2211
2025/05/12 18:46:02 - mmengine - INFO - Epoch(train)  [9][ 750/1528]  base_lr: 2.3873e-05 lr: 2.3873e-05  eta: 2:54:27  time: 0.3206  data_time: 0.0006  memory: 19494  loss: 0.4464  loss_cls: 0.2143  loss_bbox: 0.2320
2025/05/12 18:46:18 - mmengine - INFO - Epoch(train)  [9][ 800/1528]  base_lr: 2.3873e-05 lr: 2.3873e-05  eta: 2:54:16  time: 0.3155  data_time: 0.0006  memory: 19502  loss: 0.4295  loss_cls: 0.2060  loss_bbox: 0.2235
2025/05/12 18:46:33 - mmengine - INFO - Epoch(train)  [9][ 850/1528]  base_lr: 2.3873e-05 lr: 2.3873e-05  eta: 2:54:05  time: 0.3133  data_time: 0.0006  memory: 19490  loss: 0.4264  loss_cls: 0.2024  loss_bbox: 0.2240
2025/05/12 18:46:49 - mmengine - INFO - Epoch(train)  [9][ 900/1528]  base_lr: 2.3873e-05 lr: 2.3873e-05  eta: 2:53:53  time: 0.3097  data_time: 0.0006  memory: 19483  loss: 0.4394  loss_cls: 0.2008  loss_bbox: 0.2386
