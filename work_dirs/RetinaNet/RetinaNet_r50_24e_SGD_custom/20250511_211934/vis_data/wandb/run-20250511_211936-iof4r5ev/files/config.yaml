_wandb:
    value:
        cli_version: 0.19.9
        m: []
        python_version: 3.11.11
        t:
            "1":
                - 1
                - 5
                - 11
                - 37
                - 38
                - 41
                - 49
                - 53
                - 55
                - 71
                - 82
            "2":
                - 1
                - 5
                - 11
                - 37
                - 38
                - 41
                - 49
                - 53
                - 55
                - 71
                - 82
            "3":
                - 2
                - 13
                - 23
                - 55
            "4": 3.11.11
            "5": 0.19.9
            "6": 4.51.2
            "8":
                - 5
            "12": 0.19.9
            "13": linux-x86_64
HOME:
    value: /home/jaa/Work/Prog/BSU/Detectors
MODEL_GROUP:
    value: 1stage
MODEL_TYPE:
    value: RetinaNet
WEIGHT_SIZE:
    value: r50
additions:
    value: SGD
auto_scale_lr:
    value:
        base_batch_size: 10
        enable: false
backend_args:
    value: null
batch_size:
    value: 10
checkpoint_config:
    value:
        interval: 1
data_root:
    value: /home/jaa/Work/Prog/BSU/Detectors/mmdetection/data/Padded_GroundingDINO.v1i.yolov5pytorch/
dataset_type:
    value: CocoDataset
default_hooks:
    value:
        checkpoint:
            interval: 1
            type: CheckpointHook
        early_stopping:
            min_delta: 0.001
            monitor: coco/bbox_mAP
            patience: 3
            type: EarlyStoppingHook
        logger:
            interval: 50
            log_metric_by_epoch: true
            type: LoggerHook
        param_scheduler:
            type: ParamSchedulerHook
        sampler_seed:
            type: DistSamplerSeedHook
        timer:
            type: IterTimerHook
        visualization:
            type: DetVisualizationHook
default_scope:
    value: mmdet
deterministic:
    value: true
env_cfg:
    value:
        cudnn_benchmark: false
        dist_cfg:
            backend: nccl
        mp_cfg:
            mp_start_method: fork
            opencv_num_threads: 0
evaluation:
    value:
        interval: 1
        metric: bbox
experiment:
    value: RetinaNet_r50_24e_SGD_custom
img_norm_cfg:
    value:
        mean:
            - 123.675
            - 116.28
            - 103.53
        std:
            - 58.395
            - 57.12
            - 57.375
        to_rgb: true
launcher:
    value: none
load_from:
    value: /home/jaa/Work/Prog/BSU/Detectors/models/RetinaNet/retinanet_r50_fpn_mstrain_3x_coco_20210718_220633-88476508.pth
log_level:
    value: INFO
log_processor:
    value:
        by_epoch: true
        type: LogProcessor
        window_size: 50
metainfo:
    value:
        classes:
            - cow
        palette:
            - - 220
              - 20
              - 60
model:
    value:
        backbone:
            depth: 50
            frozen_stages: 2
            init_cfg:
                checkpoint: torchvision://resnet50
                type: Pretrained
            norm_cfg:
                requires_grad: true
                type: BN
            norm_eval: true
            num_stages: 4
            out_indices:
                - 0
                - 1
                - 2
                - 3
            style: pytorch
            type: ResNet
        bbox_head:
            anchor_generator:
                octave_base_scale: 4
                ratios:
                    - 0.5
                    - 1
                    - 2
                scales_per_octave: 3
                strides:
                    - 8
                    - 16
                    - 32
                    - 64
                    - 128
                type: AnchorGenerator
            bbox_coder:
                target_means:
                    - 0
                    - 0
                    - 0
                    - 0
                target_stds:
                    - 1
                    - 1
                    - 1
                    - 1
                type: DeltaXYWHBBoxCoder
            feat_channels: 256
            in_channels: 256
            loss_bbox:
                loss_weight: 1
                type: L1Loss
            loss_cls:
                alpha: 0.25
                gamma: 2
                loss_weight: 1
                type: FocalLoss
                use_sigmoid: true
            num_classes: 1
            stacked_convs: 4
            type: RetinaHead
        data_preprocessor:
            bgr_to_rgb: true
            mean:
                - 123.675
                - 116.28
                - 103.53
            pad_size_divisor: 32
            std:
                - 58.395
                - 57.12
                - 57.375
            type: DetDataPreprocessor
        neck:
            add_extra_convs: on_input
            in_channels:
                - 256
                - 512
                - 1024
                - 2048
            num_outs: 5
            out_channels: 256
            start_level: 1
            type: FPN
        test_cfg:
            max_per_img: 100
            min_bbox_size: 0
            nms:
                iou_threshold: 0.5
                type: nms
            nms_pre: 1000
            score_thr: 0.05
        train_cfg:
            allowed_border: -1
            assigner:
                ignore_iof_thr: -1
                min_pos_iou: 0
                neg_iou_thr: 0.4
                pos_iou_thr: 0.5
                type: MaxIoUAssigner
            debug: false
            pos_weight: -1
            sampler:
                type: PseudoSampler
        type: RetinaNet
num_classes:
    value: 1
num_epochs:
    value: 24
num_workers:
    value: 6
optim_wrapper:
    value:
        optimizer:
            lr: 0.001
            momentum: 0.9
            type: SGD
            weight_decay: 0.0001
param_scheduler:
    value:
        - begin: 0
          by_epoch: false
          end: 500
          start_factor: 0.0001
          type: LinearLR
        - begin: 0
          by_epoch: true
          end: 24
          gamma: 0.1
          milestones:
            - 8
            - 11
          type: MultiStepLR
resume:
    value: false
seed:
    value: 42
test_cfg:
    value:
        type: TestLoop
test_dataloader:
    value:
        batch_size: 10
        dataset:
            ann_file: /home/jaa/Work/Prog/BSU/Detectors/mmdetection/data/Padded_GroundingDINO.v1i.yolov5pytorch/test_coco.json
            data_prefix:
                img: /home/jaa/Work/Prog/BSU/Detectors/mmdetection/data/Padded_GroundingDINO.v1i.yolov5pytorch/test/images
            data_root: /home/jaa/Work/Prog/BSU/Detectors/mmdetection/data/Padded_GroundingDINO.v1i.yolov5pytorch/
            pipeline:
                - backend_args: null
                  type: LoadImageFromFile
                - type: LoadAnnotations
                  with_bbox: true
                - keep_empty: false
                  min_gt_bbox_wh:
                    - 16
                    - 16
                  type: FilterAnnotations
                - keep_ratio: true
                  scale:
                    - 1280
                    - 1280
                  type: Resize
                - meta_keys:
                    - img_id
                    - img_path
                    - ori_shape
                    - img_shape
                    - scale_factor
                  type: PackDetInputs
            test_mode: true
            type: CocoDataset
        drop_last: false
        num_workers: 6
        persistent_workers: true
        sampler:
            shuffle: false
            type: DefaultSampler
test_evaluator:
    value:
        ann_file: /home/jaa/Work/Prog/BSU/Detectors/mmdetection/data/Padded_GroundingDINO.v1i.yolov5pytorch/test_coco.json
        format_only: true
        metric: bbox
        outfile_prefix: /home/jaa/Work/Prog/BSU/Detectors/mmdetection/data/Padded_GroundingDINO.v1i.yolov5pytorch/test/images
        type: CocoMetric
test_pipeline:
    value:
        - backend_args: null
          type: LoadImageFromFile
        - type: LoadAnnotations
          with_bbox: true
        - keep_empty: false
          min_gt_bbox_wh:
            - 16
            - 16
          type: FilterAnnotations
        - keep_ratio: true
          scale:
            - 1280
            - 1280
          type: Resize
        - meta_keys:
            - img_id
            - img_path
            - ori_shape
            - img_shape
            - scale_factor
          type: PackDetInputs
train_cfg:
    value:
        max_epochs: 24
        type: EpochBasedTrainLoop
        val_interval: 1
train_dataloader:
    value:
        batch_size: 10
        dataset:
            ann_file: /home/jaa/Work/Prog/BSU/Detectors/mmdetection/data/Padded_GroundingDINO.v1i.yolov5pytorch/train_coco.json
            data_prefix:
                img: /home/jaa/Work/Prog/BSU/Detectors/mmdetection/data/Padded_GroundingDINO.v1i.yolov5pytorch/train/images
            data_root: /home/jaa/Work/Prog/BSU/Detectors/mmdetection/data/Padded_GroundingDINO.v1i.yolov5pytorch/
            metainfo:
                classes:
                    - cow
                palette:
                    - - 220
                      - 20
                      - 60
            pipeline:
                - backend_args: null
                  type: LoadImageFromFile
                - type: LoadAnnotations
                  with_bbox: true
                - prob: 0.5
                  type: RandomFlip
                - level: 2
                  prob: 0.3
                  type: Rotate
                - keep_empty: false
                  min_gt_bbox_wh:
                    - 16
                    - 16
                  type: FilterAnnotations
                - keep_ratio: true
                  scale:
                    - 1280
                    - 1280
                  type: Resize
                - type: PackDetInputs
            type: CocoDataset
        num_workers: 6
train_pipeline:
    value:
        - backend_args: null
          type: LoadImageFromFile
        - type: LoadAnnotations
          with_bbox: true
        - prob: 0.5
          type: RandomFlip
        - level: 2
          prob: 0.3
          type: Rotate
        - keep_empty: false
          min_gt_bbox_wh:
            - 16
            - 16
          type: FilterAnnotations
        - keep_ratio: true
          scale:
            - 1280
            - 1280
          type: Resize
        - type: PackDetInputs
val_cfg:
    value:
        type: ValLoop
val_dataloader:
    value:
        batch_size: 10
        dataset:
            ann_file: /home/jaa/Work/Prog/BSU/Detectors/mmdetection/data/Padded_GroundingDINO.v1i.yolov5pytorch/valid_coco.json
            data_prefix:
                img: /home/jaa/Work/Prog/BSU/Detectors/mmdetection/data/Padded_GroundingDINO.v1i.yolov5pytorch/valid/images
            data_root: /home/jaa/Work/Prog/BSU/Detectors/mmdetection/data/Padded_GroundingDINO.v1i.yolov5pytorch/
            metainfo:
                classes:
                    - cow
                palette:
                    - - 220
                      - 20
                      - 60
            pipeline:
                - backend_args: null
                  type: LoadImageFromFile
                - type: LoadAnnotations
                  with_bbox: true
                - keep_empty: false
                  min_gt_bbox_wh:
                    - 16
                    - 16
                  type: FilterAnnotations
                - keep_ratio: true
                  scale:
                    - 1280
                    - 1280
                  type: Resize
                - meta_keys:
                    - img_id
                    - img_path
                    - ori_shape
                    - img_shape
                    - scale_factor
                  type: PackDetInputs
            test_mode: true
            type: CocoDataset
        num_workers: 6
val_evaluator:
    value:
        ann_file: /home/jaa/Work/Prog/BSU/Detectors/mmdetection/data/Padded_GroundingDINO.v1i.yolov5pytorch//valid_coco.json
        format_only: false
        metric: bbox
        type: CocoMetric
vis_backends:
    value:
        - init_kwargs:
            group: 1stage
            name: RetinaNet_r50_24e_10b_SGD
            project: Сomparison of detectors
          type: WandbVisBackend
visualizer:
    value:
        name: visualizer
        type: Visualizer
        vis_backends:
            - init_kwargs:
                group: 1stage
                name: RetinaNet_r50_24e_10b_SGD
                project: Сomparison of detectors
              type: WandbVisBackend
weights:
    value: retinanet_r50_fpn_mstrain_3x_coco_20210718_220633-88476508.pth
work_dir:
    value: /home/jaa/Work/Prog/BSU/Detectors/work_dirs/RetinaNet/RetinaNet_r50_24e_SGD_custom/
